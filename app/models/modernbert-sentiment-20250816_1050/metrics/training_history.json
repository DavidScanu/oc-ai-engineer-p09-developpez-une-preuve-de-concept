{
  "log_history": [
    {
      "loss": 1.418,
      "grad_norm": 5.410682201385498,
      "learning_rate": 7.463823305407464e-07,
      "epoch": 0.045714285714285714,
      "step": 100
    },
    {
      "loss": 1.4274,
      "grad_norm": 4.511997699737549,
      "learning_rate": 1.5079969535415082e-06,
      "epoch": 0.09142857142857143,
      "step": 200
    },
    {
      "loss": 1.4036,
      "grad_norm": 3.6567201614379883,
      "learning_rate": 2.26961157654227e-06,
      "epoch": 0.13714285714285715,
      "step": 300
    },
    {
      "loss": 1.4154,
      "grad_norm": 2.941347122192383,
      "learning_rate": 3.0312261995430313e-06,
      "epoch": 0.18285714285714286,
      "step": 400
    },
    {
      "loss": 1.3955,
      "grad_norm": 3.7591052055358887,
      "learning_rate": 3.792840822543793e-06,
      "epoch": 0.22857142857142856,
      "step": 500
    },
    {
      "loss": 1.3909,
      "grad_norm": 3.598510503768921,
      "learning_rate": 4.554455445544555e-06,
      "epoch": 0.2742857142857143,
      "step": 600
    },
    {
      "loss": 1.3919,
      "grad_norm": 3.232015371322632,
      "learning_rate": 5.316070068545317e-06,
      "epoch": 0.32,
      "step": 700
    },
    {
      "loss": 1.3747,
      "grad_norm": 2.802905797958374,
      "learning_rate": 6.077684691546079e-06,
      "epoch": 0.3657142857142857,
      "step": 800
    },
    {
      "loss": 1.3638,
      "grad_norm": 2.7372193336486816,
      "learning_rate": 6.83929931454684e-06,
      "epoch": 0.4114285714285714,
      "step": 900
    },
    {
      "loss": 1.3424,
      "grad_norm": 3.123020648956299,
      "learning_rate": 7.600913937547601e-06,
      "epoch": 0.45714285714285713,
      "step": 1000
    },
    {
      "loss": 1.3539,
      "grad_norm": 5.272641181945801,
      "learning_rate": 8.362528560548363e-06,
      "epoch": 0.5028571428571429,
      "step": 1100
    },
    {
      "loss": 1.3386,
      "grad_norm": 2.474614381790161,
      "learning_rate": 9.124143183549125e-06,
      "epoch": 0.5485714285714286,
      "step": 1200
    },
    {
      "loss": 1.3206,
      "grad_norm": 2.4323480129241943,
      "learning_rate": 9.885757806549885e-06,
      "epoch": 0.5942857142857143,
      "step": 1300
    },
    {
      "loss": 1.3189,
      "grad_norm": 2.8935489654541016,
      "learning_rate": 1.0647372429550649e-05,
      "epoch": 0.64,
      "step": 1400
    },
    {
      "loss": 1.3182,
      "grad_norm": 3.270723342895508,
      "learning_rate": 1.140898705255141e-05,
      "epoch": 0.6857142857142857,
      "step": 1500
    },
    {
      "loss": 1.3034,
      "grad_norm": 2.6170501708984375,
      "learning_rate": 1.2170601675552172e-05,
      "epoch": 0.7314285714285714,
      "step": 1600
    },
    {
      "loss": 1.3042,
      "grad_norm": 2.2843708992004395,
      "learning_rate": 1.2932216298552934e-05,
      "epoch": 0.7771428571428571,
      "step": 1700
    },
    {
      "loss": 1.274,
      "grad_norm": 2.0040671825408936,
      "learning_rate": 1.3693830921553694e-05,
      "epoch": 0.8228571428571428,
      "step": 1800
    },
    {
      "loss": 1.286,
      "grad_norm": 3.9378998279571533,
      "learning_rate": 1.4455445544554456e-05,
      "epoch": 0.8685714285714285,
      "step": 1900
    },
    {
      "loss": 1.2851,
      "grad_norm": 2.6136741638183594,
      "learning_rate": 1.5217060167555217e-05,
      "epoch": 0.9142857142857143,
      "step": 2000
    },
    {
      "loss": 1.2633,
      "grad_norm": 2.4365978240966797,
      "learning_rate": 1.597867479055598e-05,
      "epoch": 0.96,
      "step": 2100
    },
    {
      "eval_loss": 0.6277092695236206,
      "eval_roc_auc": 0.6300704799999999,
      "eval_accuracy": 0.6392666666666666,
      "eval_f1": 0.6391656314397615,
      "eval_precision": 0.6394228227067261,
      "eval_recall": 0.6392666666666666,
      "eval_runtime": 28.2125,
      "eval_samples_per_second": 531.679,
      "eval_steps_per_second": 16.624,
      "epoch": 1.0,
      "step": 2188
    },
    {
      "loss": 1.2636,
      "grad_norm": 5.566766738891602,
      "learning_rate": 1.674028941355674e-05,
      "epoch": 1.0054857142857143,
      "step": 2200
    },
    {
      "loss": 1.2563,
      "grad_norm": 4.19782829284668,
      "learning_rate": 1.7501904036557505e-05,
      "epoch": 1.0512,
      "step": 2300
    },
    {
      "loss": 1.2555,
      "grad_norm": 4.3503899574279785,
      "learning_rate": 1.8263518659558266e-05,
      "epoch": 1.0969142857142857,
      "step": 2400
    },
    {
      "loss": 1.24,
      "grad_norm": 2.5583314895629883,
      "learning_rate": 1.9025133282559026e-05,
      "epoch": 1.1426285714285713,
      "step": 2500
    },
    {
      "loss": 1.2302,
      "grad_norm": 3.824119806289673,
      "learning_rate": 1.978674790555979e-05,
      "epoch": 1.1883428571428571,
      "step": 2600
    },
    {
      "loss": 1.2306,
      "grad_norm": 3.075376033782959,
      "learning_rate": 1.993906051629285e-05,
      "epoch": 1.234057142857143,
      "step": 2700
    },
    {
      "loss": 1.2181,
      "grad_norm": 5.746200084686279,
      "learning_rate": 1.985442234447736e-05,
      "epoch": 1.2797714285714286,
      "step": 2800
    },
    {
      "loss": 1.2157,
      "grad_norm": 7.310083389282227,
      "learning_rate": 1.9769784172661874e-05,
      "epoch": 1.3254857142857142,
      "step": 2900
    },
    {
      "loss": 1.2219,
      "grad_norm": 3.074613094329834,
      "learning_rate": 1.9685146000846384e-05,
      "epoch": 1.3712,
      "step": 3000
    },
    {
      "loss": 1.205,
      "grad_norm": 3.286736488342285,
      "learning_rate": 1.9600507829030894e-05,
      "epoch": 1.4169142857142858,
      "step": 3100
    },
    {
      "loss": 1.1862,
      "grad_norm": 2.402303695678711,
      "learning_rate": 1.9515869657215404e-05,
      "epoch": 1.4626285714285714,
      "step": 3200
    },
    {
      "loss": 1.1939,
      "grad_norm": 2.5872726440429688,
      "learning_rate": 1.9431231485399917e-05,
      "epoch": 1.508342857142857,
      "step": 3300
    },
    {
      "loss": 1.1824,
      "grad_norm": 3.480146646499634,
      "learning_rate": 1.9346593313584428e-05,
      "epoch": 1.5540571428571428,
      "step": 3400
    },
    {
      "loss": 1.1928,
      "grad_norm": 2.6969127655029297,
      "learning_rate": 1.926195514176894e-05,
      "epoch": 1.5997714285714286,
      "step": 3500
    },
    {
      "loss": 1.171,
      "grad_norm": 3.764449119567871,
      "learning_rate": 1.917731696995345e-05,
      "epoch": 1.6454857142857144,
      "step": 3600
    },
    {
      "loss": 1.1949,
      "grad_norm": 5.114624500274658,
      "learning_rate": 1.909267879813796e-05,
      "epoch": 1.6912,
      "step": 3700
    },
    {
      "loss": 1.1767,
      "grad_norm": 2.2049367427825928,
      "learning_rate": 1.900804062632247e-05,
      "epoch": 1.7369142857142856,
      "step": 3800
    },
    {
      "loss": 1.1843,
      "grad_norm": 3.0838875770568848,
      "learning_rate": 1.8923402454506985e-05,
      "epoch": 1.7826285714285715,
      "step": 3900
    },
    {
      "loss": 1.1632,
      "grad_norm": 3.5423424243927,
      "learning_rate": 1.8838764282691495e-05,
      "epoch": 1.8283428571428573,
      "step": 4000
    },
    {
      "loss": 1.1556,
      "grad_norm": 2.7210240364074707,
      "learning_rate": 1.875497249259416e-05,
      "epoch": 1.8740571428571429,
      "step": 4100
    },
    {
      "loss": 1.137,
      "grad_norm": 2.780639886856079,
      "learning_rate": 1.8670334320778675e-05,
      "epoch": 1.9197714285714285,
      "step": 4200
    },
    {
      "loss": 1.1518,
      "grad_norm": 2.3375139236450195,
      "learning_rate": 1.8585696148963185e-05,
      "epoch": 1.9654857142857143,
      "step": 4300
    },
    {
      "eval_loss": 0.5768149495124817,
      "eval_roc_auc": 0.7218457155555555,
      "eval_accuracy": 0.6942,
      "eval_f1": 0.6941800999593045,
      "eval_precision": 0.6942505603991965,
      "eval_recall": 0.6942,
      "eval_runtime": 28.2274,
      "eval_samples_per_second": 531.399,
      "eval_steps_per_second": 16.615,
      "epoch": 2.0,
      "step": 4376
    },
    {
      "loss": 1.1412,
      "grad_norm": 2.4639906883239746,
      "learning_rate": 1.8501057977147695e-05,
      "epoch": 2.0109714285714286,
      "step": 4400
    },
    {
      "loss": 1.1487,
      "grad_norm": 2.351379156112671,
      "learning_rate": 1.8416419805332205e-05,
      "epoch": 2.0566857142857145,
      "step": 4500
    },
    {
      "loss": 1.1608,
      "grad_norm": 2.436990976333618,
      "learning_rate": 1.8331781633516715e-05,
      "epoch": 2.1024,
      "step": 4600
    },
    {
      "loss": 1.1517,
      "grad_norm": 6.140105247497559,
      "learning_rate": 1.8247143461701228e-05,
      "epoch": 2.1481142857142856,
      "step": 4700
    },
    {
      "loss": 1.136,
      "grad_norm": 5.8305745124816895,
      "learning_rate": 1.816250528988574e-05,
      "epoch": 2.1938285714285715,
      "step": 4800
    },
    {
      "loss": 1.1501,
      "grad_norm": 3.87811541557312,
      "learning_rate": 1.8077867118070252e-05,
      "epoch": 2.2395428571428573,
      "step": 4900
    },
    {
      "loss": 1.1341,
      "grad_norm": 4.250223636627197,
      "learning_rate": 1.7993228946254762e-05,
      "epoch": 2.2852571428571427,
      "step": 5000
    },
    {
      "loss": 1.1315,
      "grad_norm": 5.11482048034668,
      "learning_rate": 1.7908590774439275e-05,
      "epoch": 2.3309714285714285,
      "step": 5100
    },
    {
      "loss": 1.1455,
      "grad_norm": 2.254321575164795,
      "learning_rate": 1.7823952602623785e-05,
      "epoch": 2.3766857142857143,
      "step": 5200
    },
    {
      "loss": 1.1212,
      "grad_norm": 3.6660964488983154,
      "learning_rate": 1.7739314430808295e-05,
      "epoch": 2.4224,
      "step": 5300
    },
    {
      "loss": 1.1217,
      "grad_norm": 1.8891973495483398,
      "learning_rate": 1.7654676258992805e-05,
      "epoch": 2.468114285714286,
      "step": 5400
    },
    {
      "loss": 1.1361,
      "grad_norm": 2.591413974761963,
      "learning_rate": 1.757003808717732e-05,
      "epoch": 2.5138285714285713,
      "step": 5500
    },
    {
      "loss": 1.1293,
      "grad_norm": 2.1967742443084717,
      "learning_rate": 1.748539991536183e-05,
      "epoch": 2.559542857142857,
      "step": 5600
    },
    {
      "loss": 1.1135,
      "grad_norm": 2.5738112926483154,
      "learning_rate": 1.7400761743546342e-05,
      "epoch": 2.605257142857143,
      "step": 5700
    },
    {
      "loss": 1.1165,
      "grad_norm": 3.2481353282928467,
      "learning_rate": 1.7316123571730852e-05,
      "epoch": 2.6509714285714283,
      "step": 5800
    },
    {
      "loss": 1.1345,
      "grad_norm": 5.428750038146973,
      "learning_rate": 1.7231485399915366e-05,
      "epoch": 2.696685714285714,
      "step": 5900
    },
    {
      "loss": 1.1229,
      "grad_norm": 2.44612717628479,
      "learning_rate": 1.7146847228099876e-05,
      "epoch": 2.7424,
      "step": 6000
    },
    {
      "loss": 1.1033,
      "grad_norm": 2.7300498485565186,
      "learning_rate": 1.706305543800254e-05,
      "epoch": 2.7881142857142858,
      "step": 6100
    },
    {
      "loss": 1.1104,
      "grad_norm": 2.592597007751465,
      "learning_rate": 1.6978417266187053e-05,
      "epoch": 2.8338285714285716,
      "step": 6200
    },
    {
      "loss": 1.1099,
      "grad_norm": 2.5738418102264404,
      "learning_rate": 1.6893779094371563e-05,
      "epoch": 2.879542857142857,
      "step": 6300
    },
    {
      "loss": 1.0974,
      "grad_norm": 2.189939498901367,
      "learning_rate": 1.6809140922556073e-05,
      "epoch": 2.925257142857143,
      "step": 6400
    },
    {
      "loss": 1.1137,
      "grad_norm": 2.874805450439453,
      "learning_rate": 1.6724502750740586e-05,
      "epoch": 2.9709714285714286,
      "step": 6500
    },
    {
      "eval_loss": 0.5550716519355774,
      "eval_roc_auc": 0.7552190488888889,
      "eval_accuracy": 0.7133333333333334,
      "eval_f1": 0.713261146508368,
      "eval_precision": 0.7135483774985784,
      "eval_recall": 0.7133333333333334,
      "eval_runtime": 28.1896,
      "eval_samples_per_second": 532.111,
      "eval_steps_per_second": 16.637,
      "epoch": 3.0,
      "step": 6564
    },
    {
      "loss": 1.0774,
      "grad_norm": 2.022076368331909,
      "learning_rate": 1.6639864578925096e-05,
      "epoch": 3.016457142857143,
      "step": 6600
    },
    {
      "loss": 1.1218,
      "grad_norm": 3.0629351139068604,
      "learning_rate": 1.655522640710961e-05,
      "epoch": 3.0621714285714288,
      "step": 6700
    },
    {
      "loss": 1.0891,
      "grad_norm": 3.0015599727630615,
      "learning_rate": 1.647058823529412e-05,
      "epoch": 3.107885714285714,
      "step": 6800
    },
    {
      "loss": 1.0862,
      "grad_norm": 2.68135666847229,
      "learning_rate": 1.638595006347863e-05,
      "epoch": 3.1536,
      "step": 6900
    },
    {
      "loss": 1.1029,
      "grad_norm": 2.9879980087280273,
      "learning_rate": 1.630131189166314e-05,
      "epoch": 3.1993142857142858,
      "step": 7000
    },
    {
      "loss": 1.1098,
      "grad_norm": 3.20455002784729,
      "learning_rate": 1.6216673719847653e-05,
      "epoch": 3.2450285714285716,
      "step": 7100
    },
    {
      "loss": 1.0813,
      "grad_norm": 3.616806983947754,
      "learning_rate": 1.6132035548032163e-05,
      "epoch": 3.290742857142857,
      "step": 7200
    },
    {
      "loss": 1.0721,
      "grad_norm": 3.251325845718384,
      "learning_rate": 1.6047397376216677e-05,
      "epoch": 3.336457142857143,
      "step": 7300
    },
    {
      "loss": 1.1037,
      "grad_norm": 2.242323398590088,
      "learning_rate": 1.5962759204401187e-05,
      "epoch": 3.3821714285714286,
      "step": 7400
    },
    {
      "loss": 1.0914,
      "grad_norm": 2.4099881649017334,
      "learning_rate": 1.5878121032585697e-05,
      "epoch": 3.4278857142857144,
      "step": 7500
    },
    {
      "loss": 1.0931,
      "grad_norm": 2.988238573074341,
      "learning_rate": 1.5793482860770207e-05,
      "epoch": 3.4736000000000002,
      "step": 7600
    },
    {
      "loss": 1.1117,
      "grad_norm": 2.6578078269958496,
      "learning_rate": 1.570884468895472e-05,
      "epoch": 3.5193142857142856,
      "step": 7700
    },
    {
      "loss": 1.107,
      "grad_norm": 3.8206582069396973,
      "learning_rate": 1.562420651713923e-05,
      "epoch": 3.5650285714285714,
      "step": 7800
    },
    {
      "loss": 1.1094,
      "grad_norm": 2.297891616821289,
      "learning_rate": 1.5539568345323744e-05,
      "epoch": 3.6107428571428573,
      "step": 7900
    },
    {
      "loss": 1.0639,
      "grad_norm": 3.59529185295105,
      "learning_rate": 1.5454930173508254e-05,
      "epoch": 3.6564571428571426,
      "step": 8000
    },
    {
      "loss": 1.06,
      "grad_norm": 3.0749807357788086,
      "learning_rate": 1.537113838341092e-05,
      "epoch": 3.7021714285714284,
      "step": 8100
    },
    {
      "loss": 1.0999,
      "grad_norm": 3.064379930496216,
      "learning_rate": 1.528650021159543e-05,
      "epoch": 3.7478857142857143,
      "step": 8200
    },
    {
      "loss": 1.0996,
      "grad_norm": 1.9706110954284668,
      "learning_rate": 1.5201862039779942e-05,
      "epoch": 3.7936,
      "step": 8300
    },
    {
      "loss": 1.0998,
      "grad_norm": 2.0985164642333984,
      "learning_rate": 1.5117223867964452e-05,
      "epoch": 3.839314285714286,
      "step": 8400
    },
    {
      "loss": 1.0849,
      "grad_norm": 2.750965118408203,
      "learning_rate": 1.5032585696148964e-05,
      "epoch": 3.8850285714285713,
      "step": 8500
    },
    {
      "loss": 1.1017,
      "grad_norm": 2.161780834197998,
      "learning_rate": 1.4947947524333476e-05,
      "epoch": 3.930742857142857,
      "step": 8600
    },
    {
      "loss": 1.078,
      "grad_norm": 2.7176437377929688,
      "learning_rate": 1.4863309352517987e-05,
      "epoch": 3.976457142857143,
      "step": 8700
    },
    {
      "eval_loss": 0.5425540208816528,
      "eval_roc_auc": 0.7714781066666666,
      "eval_accuracy": 0.7237333333333333,
      "eval_f1": 0.7237332547507924,
      "eval_precision": 0.7237335878924378,
      "eval_recall": 0.7237333333333333,
      "eval_runtime": 28.2456,
      "eval_samples_per_second": 531.057,
      "eval_steps_per_second": 16.604,
      "epoch": 4.0,
      "step": 8752
    },
    {
      "loss": 1.0925,
      "grad_norm": 2.5468039512634277,
      "learning_rate": 1.4778671180702497e-05,
      "epoch": 4.021942857142857,
      "step": 8800
    },
    {
      "loss": 1.0782,
      "grad_norm": 5.56525993347168,
      "learning_rate": 1.469403300888701e-05,
      "epoch": 4.067657142857143,
      "step": 8900
    },
    {
      "loss": 1.0898,
      "grad_norm": 3.0967485904693604,
      "learning_rate": 1.460939483707152e-05,
      "epoch": 4.113371428571429,
      "step": 9000
    },
    {
      "loss": 1.0835,
      "grad_norm": 1.7864575386047363,
      "learning_rate": 1.4524756665256033e-05,
      "epoch": 4.159085714285714,
      "step": 9100
    },
    {
      "loss": 1.0707,
      "grad_norm": 4.882108211517334,
      "learning_rate": 1.4440118493440543e-05,
      "epoch": 4.2048,
      "step": 9200
    },
    {
      "loss": 1.0766,
      "grad_norm": 4.31033992767334,
      "learning_rate": 1.4355480321625055e-05,
      "epoch": 4.250514285714286,
      "step": 9300
    },
    {
      "loss": 1.0558,
      "grad_norm": 1.8325711488723755,
      "learning_rate": 1.4270842149809565e-05,
      "epoch": 4.296228571428571,
      "step": 9400
    },
    {
      "loss": 1.1039,
      "grad_norm": 3.7884440422058105,
      "learning_rate": 1.4186203977994078e-05,
      "epoch": 4.3419428571428575,
      "step": 9500
    },
    {
      "loss": 1.0763,
      "grad_norm": 2.997083902359009,
      "learning_rate": 1.4101565806178588e-05,
      "epoch": 4.387657142857143,
      "step": 9600
    },
    {
      "loss": 1.0661,
      "grad_norm": 1.7960858345031738,
      "learning_rate": 1.40169276343631e-05,
      "epoch": 4.433371428571428,
      "step": 9700
    },
    {
      "loss": 1.0632,
      "grad_norm": 2.647756338119507,
      "learning_rate": 1.393228946254761e-05,
      "epoch": 4.479085714285715,
      "step": 9800
    },
    {
      "loss": 1.0666,
      "grad_norm": 2.0534932613372803,
      "learning_rate": 1.384765129073212e-05,
      "epoch": 4.5248,
      "step": 9900
    },
    {
      "loss": 1.066,
      "grad_norm": 3.8212778568267822,
      "learning_rate": 1.3763013118916633e-05,
      "epoch": 4.570514285714285,
      "step": 10000
    },
    {
      "loss": 1.0972,
      "grad_norm": 2.248082160949707,
      "learning_rate": 1.3679221328819298e-05,
      "epoch": 4.616228571428572,
      "step": 10100
    },
    {
      "loss": 1.0537,
      "grad_norm": 3.510117292404175,
      "learning_rate": 1.3594583157003808e-05,
      "epoch": 4.661942857142857,
      "step": 10200
    },
    {
      "loss": 1.0625,
      "grad_norm": 2.213491439819336,
      "learning_rate": 1.3509944985188322e-05,
      "epoch": 4.707657142857143,
      "step": 10300
    },
    {
      "loss": 1.0735,
      "grad_norm": 2.295426368713379,
      "learning_rate": 1.3425306813372832e-05,
      "epoch": 4.753371428571429,
      "step": 10400
    },
    {
      "loss": 1.0666,
      "grad_norm": 3.0206286907196045,
      "learning_rate": 1.3340668641557344e-05,
      "epoch": 4.799085714285714,
      "step": 10500
    },
    {
      "loss": 1.0824,
      "grad_norm": 2.7984910011291504,
      "learning_rate": 1.3256030469741854e-05,
      "epoch": 4.8448,
      "step": 10600
    },
    {
      "loss": 1.0588,
      "grad_norm": 2.679558038711548,
      "learning_rate": 1.3171392297926367e-05,
      "epoch": 4.890514285714286,
      "step": 10700
    },
    {
      "loss": 1.0714,
      "grad_norm": 3.138462781906128,
      "learning_rate": 1.3086754126110877e-05,
      "epoch": 4.936228571428572,
      "step": 10800
    },
    {
      "loss": 1.0501,
      "grad_norm": 3.3057310581207275,
      "learning_rate": 1.3002115954295389e-05,
      "epoch": 4.981942857142857,
      "step": 10900
    },
    {
      "eval_loss": 0.5346777439117432,
      "eval_roc_auc": 0.7817812177777778,
      "eval_accuracy": 0.7291333333333333,
      "eval_f1": 0.7290045454535147,
      "eval_precision": 0.7295697362190964,
      "eval_recall": 0.7291333333333333,
      "eval_runtime": 28.2089,
      "eval_samples_per_second": 531.746,
      "eval_steps_per_second": 16.626,
      "epoch": 5.0,
      "step": 10940
    },
    {
      "loss": 1.0535,
      "grad_norm": 2.5200769901275635,
      "learning_rate": 1.2917477782479899e-05,
      "epoch": 5.027428571428572,
      "step": 11000
    },
    {
      "loss": 1.0658,
      "grad_norm": 3.8393290042877197,
      "learning_rate": 1.2832839610664412e-05,
      "epoch": 5.073142857142857,
      "step": 11100
    },
    {
      "loss": 1.0408,
      "grad_norm": 2.0775043964385986,
      "learning_rate": 1.2748201438848922e-05,
      "epoch": 5.118857142857143,
      "step": 11200
    },
    {
      "loss": 1.0876,
      "grad_norm": 2.496626377105713,
      "learning_rate": 1.2663563267033434e-05,
      "epoch": 5.164571428571429,
      "step": 11300
    },
    {
      "loss": 1.0764,
      "grad_norm": 2.993399143218994,
      "learning_rate": 1.2578925095217944e-05,
      "epoch": 5.210285714285714,
      "step": 11400
    },
    {
      "loss": 1.0593,
      "grad_norm": 2.0654854774475098,
      "learning_rate": 1.2494286923402456e-05,
      "epoch": 5.256,
      "step": 11500
    },
    {
      "loss": 1.0539,
      "grad_norm": 3.7345566749572754,
      "learning_rate": 1.2409648751586966e-05,
      "epoch": 5.301714285714286,
      "step": 11600
    },
    {
      "loss": 1.0585,
      "grad_norm": 4.395417213439941,
      "learning_rate": 1.2325010579771478e-05,
      "epoch": 5.347428571428571,
      "step": 11700
    },
    {
      "loss": 1.0242,
      "grad_norm": 3.3627185821533203,
      "learning_rate": 1.224037240795599e-05,
      "epoch": 5.393142857142857,
      "step": 11800
    },
    {
      "loss": 1.0494,
      "grad_norm": 2.075676202774048,
      "learning_rate": 1.21557342361405e-05,
      "epoch": 5.438857142857143,
      "step": 11900
    },
    {
      "loss": 1.0679,
      "grad_norm": 2.683265209197998,
      "learning_rate": 1.2071096064325011e-05,
      "epoch": 5.484571428571429,
      "step": 12000
    },
    {
      "loss": 1.0423,
      "grad_norm": 3.2651352882385254,
      "learning_rate": 1.1987304274227678e-05,
      "epoch": 5.530285714285714,
      "step": 12100
    },
    {
      "loss": 1.0629,
      "grad_norm": 2.787752628326416,
      "learning_rate": 1.1903512484130344e-05,
      "epoch": 5.576,
      "step": 12200
    },
    {
      "loss": 1.0576,
      "grad_norm": 1.8952878713607788,
      "learning_rate": 1.1818874312314854e-05,
      "epoch": 5.621714285714286,
      "step": 12300
    },
    {
      "loss": 1.0786,
      "grad_norm": 1.9395020008087158,
      "learning_rate": 1.1734236140499366e-05,
      "epoch": 5.667428571428571,
      "step": 12400
    },
    {
      "loss": 1.0537,
      "grad_norm": 3.4739198684692383,
      "learning_rate": 1.1649597968683876e-05,
      "epoch": 5.7131428571428575,
      "step": 12500
    },
    {
      "loss": 1.0648,
      "grad_norm": 2.2938437461853027,
      "learning_rate": 1.156495979686839e-05,
      "epoch": 5.758857142857143,
      "step": 12600
    },
    {
      "loss": 1.0396,
      "grad_norm": 2.3512332439422607,
      "learning_rate": 1.14803216250529e-05,
      "epoch": 5.804571428571428,
      "step": 12700
    },
    {
      "loss": 1.0449,
      "grad_norm": 3.401822566986084,
      "learning_rate": 1.1395683453237411e-05,
      "epoch": 5.8502857142857145,
      "step": 12800
    },
    {
      "loss": 1.0746,
      "grad_norm": 4.732837677001953,
      "learning_rate": 1.1311045281421922e-05,
      "epoch": 5.896,
      "step": 12900
    },
    {
      "loss": 1.0393,
      "grad_norm": 1.786755919456482,
      "learning_rate": 1.1226407109606435e-05,
      "epoch": 5.941714285714285,
      "step": 13000
    },
    {
      "loss": 1.0701,
      "grad_norm": 1.6625937223434448,
      "learning_rate": 1.1141768937790945e-05,
      "epoch": 5.9874285714285715,
      "step": 13100
    },
    {
      "eval_loss": 0.5289385318756104,
      "eval_roc_auc": 0.7879840977777779,
      "eval_accuracy": 0.7348,
      "eval_f1": 0.7347987930398404,
      "eval_precision": 0.7348042744813702,
      "eval_recall": 0.7348,
      "eval_runtime": 28.2406,
      "eval_samples_per_second": 531.15,
      "eval_steps_per_second": 16.607,
      "epoch": 6.0,
      "step": 13128
    },
    {
      "loss": 1.0779,
      "grad_norm": 3.3363611698150635,
      "learning_rate": 1.1057130765975457e-05,
      "epoch": 6.032914285714286,
      "step": 13200
    },
    {
      "loss": 1.0654,
      "grad_norm": 4.253229141235352,
      "learning_rate": 1.0972492594159967e-05,
      "epoch": 6.078628571428571,
      "step": 13300
    },
    {
      "loss": 1.0394,
      "grad_norm": 4.918392658233643,
      "learning_rate": 1.0887854422344479e-05,
      "epoch": 6.1243428571428575,
      "step": 13400
    },
    {
      "loss": 1.0777,
      "grad_norm": 3.322295665740967,
      "learning_rate": 1.0803216250528989e-05,
      "epoch": 6.170057142857143,
      "step": 13500
    },
    {
      "loss": 1.0712,
      "grad_norm": 3.829596757888794,
      "learning_rate": 1.07185780787135e-05,
      "epoch": 6.215771428571428,
      "step": 13600
    },
    {
      "loss": 1.0442,
      "grad_norm": 2.5870349407196045,
      "learning_rate": 1.0633939906898012e-05,
      "epoch": 6.2614857142857145,
      "step": 13700
    },
    {
      "loss": 1.0693,
      "grad_norm": 2.6161630153656006,
      "learning_rate": 1.0549301735082522e-05,
      "epoch": 6.3072,
      "step": 13800
    },
    {
      "loss": 1.0489,
      "grad_norm": 4.918415546417236,
      "learning_rate": 1.0464663563267034e-05,
      "epoch": 6.352914285714286,
      "step": 13900
    },
    {
      "loss": 1.0371,
      "grad_norm": 1.9484889507293701,
      "learning_rate": 1.0380025391451544e-05,
      "epoch": 6.3986285714285716,
      "step": 14000
    },
    {
      "loss": 1.0358,
      "grad_norm": 2.084273099899292,
      "learning_rate": 1.0295387219636057e-05,
      "epoch": 6.444342857142857,
      "step": 14100
    },
    {
      "loss": 1.0387,
      "grad_norm": 2.904745578765869,
      "learning_rate": 1.0210749047820567e-05,
      "epoch": 6.490057142857143,
      "step": 14200
    },
    {
      "loss": 1.0591,
      "grad_norm": 2.3881189823150635,
      "learning_rate": 1.012611087600508e-05,
      "epoch": 6.535771428571429,
      "step": 14300
    },
    {
      "loss": 1.0197,
      "grad_norm": 3.0563039779663086,
      "learning_rate": 1.004147270418959e-05,
      "epoch": 6.581485714285714,
      "step": 14400
    },
    {
      "loss": 1.0387,
      "grad_norm": 4.116768836975098,
      "learning_rate": 9.956834532374101e-06,
      "epoch": 6.6272,
      "step": 14500
    },
    {
      "loss": 1.0665,
      "grad_norm": 3.8220458030700684,
      "learning_rate": 9.872196360558613e-06,
      "epoch": 6.672914285714286,
      "step": 14600
    },
    {
      "loss": 1.0351,
      "grad_norm": 3.283000946044922,
      "learning_rate": 9.787558188743125e-06,
      "epoch": 6.718628571428571,
      "step": 14700
    },
    {
      "loss": 1.0535,
      "grad_norm": 2.812973737716675,
      "learning_rate": 9.702920016927635e-06,
      "epoch": 6.764342857142857,
      "step": 14800
    },
    {
      "loss": 1.0319,
      "grad_norm": 2.6810946464538574,
      "learning_rate": 9.618281845112146e-06,
      "epoch": 6.810057142857143,
      "step": 14900
    },
    {
      "loss": 1.0362,
      "grad_norm": 3.3740077018737793,
      "learning_rate": 9.533643673296658e-06,
      "epoch": 6.855771428571429,
      "step": 15000
    },
    {
      "loss": 1.0322,
      "grad_norm": 1.89678156375885,
      "learning_rate": 9.449005501481168e-06,
      "epoch": 6.901485714285714,
      "step": 15100
    },
    {
      "loss": 1.0531,
      "grad_norm": 3.1787633895874023,
      "learning_rate": 9.36436732966568e-06,
      "epoch": 6.9472000000000005,
      "step": 15200
    },
    {
      "loss": 1.0445,
      "grad_norm": 1.8233259916305542,
      "learning_rate": 9.279729157850192e-06,
      "epoch": 6.992914285714286,
      "step": 15300
    },
    {
      "eval_loss": 0.5249713063240051,
      "eval_roc_auc": 0.7925681155555555,
      "eval_accuracy": 0.7377333333333334,
      "eval_f1": 0.7376988448116663,
      "eval_precision": 0.7378584320685212,
      "eval_recall": 0.7377333333333334,
      "eval_runtime": 28.2123,
      "eval_samples_per_second": 531.683,
      "eval_steps_per_second": 16.624,
      "epoch": 7.0,
      "step": 15316
    },
    {
      "loss": 1.0365,
      "grad_norm": 3.2562289237976074,
      "learning_rate": 9.195090986034703e-06,
      "epoch": 7.0384,
      "step": 15400
    },
    {
      "loss": 1.0506,
      "grad_norm": 2.12943959236145,
      "learning_rate": 9.110452814219213e-06,
      "epoch": 7.084114285714286,
      "step": 15500
    },
    {
      "loss": 1.0464,
      "grad_norm": 2.2059431076049805,
      "learning_rate": 9.025814642403725e-06,
      "epoch": 7.129828571428572,
      "step": 15600
    },
    {
      "loss": 1.0376,
      "grad_norm": 3.4006187915802,
      "learning_rate": 8.941176470588237e-06,
      "epoch": 7.175542857142857,
      "step": 15700
    },
    {
      "loss": 1.0356,
      "grad_norm": 2.8028383255004883,
      "learning_rate": 8.856538298772747e-06,
      "epoch": 7.221257142857143,
      "step": 15800
    },
    {
      "loss": 1.0414,
      "grad_norm": 3.4444243907928467,
      "learning_rate": 8.771900126957259e-06,
      "epoch": 7.266971428571429,
      "step": 15900
    },
    {
      "loss": 1.0454,
      "grad_norm": 4.4680256843566895,
      "learning_rate": 8.687261955141769e-06,
      "epoch": 7.312685714285714,
      "step": 16000
    },
    {
      "loss": 1.0493,
      "grad_norm": 2.953122138977051,
      "learning_rate": 8.60262378332628e-06,
      "epoch": 7.3584,
      "step": 16100
    },
    {
      "loss": 1.0549,
      "grad_norm": 3.0098698139190674,
      "learning_rate": 8.518831993228947e-06,
      "epoch": 7.404114285714286,
      "step": 16200
    },
    {
      "loss": 1.0148,
      "grad_norm": 2.387369394302368,
      "learning_rate": 8.434193821413457e-06,
      "epoch": 7.449828571428571,
      "step": 16300
    },
    {
      "loss": 1.0425,
      "grad_norm": 2.8163042068481445,
      "learning_rate": 8.349555649597969e-06,
      "epoch": 7.4955428571428575,
      "step": 16400
    },
    {
      "loss": 1.07,
      "grad_norm": 2.67495059967041,
      "learning_rate": 8.26491747778248e-06,
      "epoch": 7.541257142857143,
      "step": 16500
    },
    {
      "loss": 1.0458,
      "grad_norm": 2.172104835510254,
      "learning_rate": 8.180279305966992e-06,
      "epoch": 7.586971428571428,
      "step": 16600
    },
    {
      "loss": 1.0297,
      "grad_norm": 2.841111421585083,
      "learning_rate": 8.095641134151502e-06,
      "epoch": 7.6326857142857145,
      "step": 16700
    },
    {
      "loss": 1.0375,
      "grad_norm": 2.6500184535980225,
      "learning_rate": 8.011002962336014e-06,
      "epoch": 7.6784,
      "step": 16800
    },
    {
      "loss": 1.0581,
      "grad_norm": 2.30375075340271,
      "learning_rate": 7.926364790520526e-06,
      "epoch": 7.724114285714286,
      "step": 16900
    },
    {
      "loss": 1.0384,
      "grad_norm": 1.7935961484909058,
      "learning_rate": 7.841726618705036e-06,
      "epoch": 7.7698285714285715,
      "step": 17000
    },
    {
      "loss": 1.0344,
      "grad_norm": 2.2292675971984863,
      "learning_rate": 7.757088446889548e-06,
      "epoch": 7.815542857142857,
      "step": 17100
    },
    {
      "loss": 1.0439,
      "grad_norm": 2.5222327709198,
      "learning_rate": 7.67245027507406e-06,
      "epoch": 7.861257142857143,
      "step": 17200
    },
    {
      "loss": 1.04,
      "grad_norm": 2.919337749481201,
      "learning_rate": 7.58781210325857e-06,
      "epoch": 7.9069714285714285,
      "step": 17300
    },
    {
      "loss": 1.0732,
      "grad_norm": 2.6951756477355957,
      "learning_rate": 7.503173931443082e-06,
      "epoch": 7.952685714285714,
      "step": 17400
    },
    {
      "loss": 1.003,
      "grad_norm": 2.984421491622925,
      "learning_rate": 7.418535759627593e-06,
      "epoch": 7.9984,
      "step": 17500
    },
    {
      "eval_loss": 0.5222762823104858,
      "eval_roc_auc": 0.7961498666666667,
      "eval_accuracy": 0.7395333333333334,
      "eval_f1": 0.739461539355118,
      "eval_precision": 0.7397976478927466,
      "eval_recall": 0.7395333333333334,
      "eval_runtime": 28.2632,
      "eval_samples_per_second": 530.725,
      "eval_steps_per_second": 16.594,
      "epoch": 8.0,
      "step": 17504
    },
    {
      "loss": 1.0384,
      "grad_norm": 3.852160930633545,
      "learning_rate": 7.333897587812105e-06,
      "epoch": 8.043885714285715,
      "step": 17600
    },
    {
      "loss": 1.0147,
      "grad_norm": 2.277650833129883,
      "learning_rate": 7.249259415996615e-06,
      "epoch": 8.0896,
      "step": 17700
    },
    {
      "loss": 1.0497,
      "grad_norm": 2.5195627212524414,
      "learning_rate": 7.164621244181126e-06,
      "epoch": 8.135314285714285,
      "step": 17800
    },
    {
      "loss": 1.041,
      "grad_norm": 3.215784788131714,
      "learning_rate": 7.079983072365637e-06,
      "epoch": 8.181028571428572,
      "step": 17900
    },
    {
      "loss": 1.0325,
      "grad_norm": 2.3365869522094727,
      "learning_rate": 6.995344900550148e-06,
      "epoch": 8.226742857142858,
      "step": 18000
    },
    {
      "loss": 1.0277,
      "grad_norm": 4.623519420623779,
      "learning_rate": 6.910706728734659e-06,
      "epoch": 8.272457142857142,
      "step": 18100
    },
    {
      "loss": 1.0444,
      "grad_norm": 2.5615642070770264,
      "learning_rate": 6.826914938637326e-06,
      "epoch": 8.318171428571429,
      "step": 18200
    },
    {
      "loss": 1.0066,
      "grad_norm": 4.050950050354004,
      "learning_rate": 6.742276766821837e-06,
      "epoch": 8.363885714285715,
      "step": 18300
    },
    {
      "loss": 1.0443,
      "grad_norm": 3.3197457790374756,
      "learning_rate": 6.6576385950063484e-06,
      "epoch": 8.4096,
      "step": 18400
    },
    {
      "loss": 1.0409,
      "grad_norm": 2.53240966796875,
      "learning_rate": 6.573000423190859e-06,
      "epoch": 8.455314285714286,
      "step": 18500
    },
    {
      "loss": 1.0362,
      "grad_norm": 2.257459878921509,
      "learning_rate": 6.488362251375371e-06,
      "epoch": 8.501028571428572,
      "step": 18600
    },
    {
      "loss": 1.0358,
      "grad_norm": 2.402024269104004,
      "learning_rate": 6.403724079559882e-06,
      "epoch": 8.546742857142856,
      "step": 18700
    },
    {
      "loss": 1.0308,
      "grad_norm": 1.959402322769165,
      "learning_rate": 6.319085907744394e-06,
      "epoch": 8.592457142857143,
      "step": 18800
    },
    {
      "loss": 1.0318,
      "grad_norm": 3.221799850463867,
      "learning_rate": 6.234447735928905e-06,
      "epoch": 8.638171428571429,
      "step": 18900
    },
    {
      "loss": 1.0191,
      "grad_norm": 3.4853873252868652,
      "learning_rate": 6.1498095641134155e-06,
      "epoch": 8.683885714285715,
      "step": 19000
    },
    {
      "loss": 1.0671,
      "grad_norm": 2.0372581481933594,
      "learning_rate": 6.065171392297927e-06,
      "epoch": 8.7296,
      "step": 19100
    },
    {
      "loss": 1.0165,
      "grad_norm": 4.889004707336426,
      "learning_rate": 5.980533220482438e-06,
      "epoch": 8.775314285714286,
      "step": 19200
    },
    {
      "loss": 1.0523,
      "grad_norm": 2.651747226715088,
      "learning_rate": 5.89589504866695e-06,
      "epoch": 8.821028571428572,
      "step": 19300
    },
    {
      "loss": 1.0342,
      "grad_norm": 3.879922389984131,
      "learning_rate": 5.812103258569616e-06,
      "epoch": 8.866742857142857,
      "step": 19400
    },
    {
      "loss": 1.0571,
      "grad_norm": 2.225872755050659,
      "learning_rate": 5.727465086754127e-06,
      "epoch": 8.912457142857143,
      "step": 19500
    },
    {
      "loss": 1.0683,
      "grad_norm": 3.1777846813201904,
      "learning_rate": 5.642826914938638e-06,
      "epoch": 8.95817142857143,
      "step": 19600
    },
    {
      "eval_loss": 0.5202010869979858,
      "eval_roc_auc": 0.7976663822222222,
      "eval_accuracy": 0.7398,
      "eval_f1": 0.7397978617166504,
      "eval_precision": 0.7398078827515594,
      "eval_recall": 0.7398,
      "eval_runtime": 28.187,
      "eval_samples_per_second": 532.159,
      "eval_steps_per_second": 16.639,
      "epoch": 9.0,
      "step": 19692
    },
    {
      "loss": 1.0153,
      "grad_norm": 1.5259387493133545,
      "learning_rate": 5.558188743123148e-06,
      "epoch": 9.003657142857143,
      "step": 19700
    },
    {
      "loss": 1.0118,
      "grad_norm": 1.8462964296340942,
      "learning_rate": 5.47355057130766e-06,
      "epoch": 9.049371428571428,
      "step": 19800
    },
    {
      "loss": 1.0243,
      "grad_norm": 2.3064095973968506,
      "learning_rate": 5.388912399492171e-06,
      "epoch": 9.095085714285714,
      "step": 19900
    },
    {
      "loss": 1.0312,
      "grad_norm": 2.0267434120178223,
      "learning_rate": 5.304274227676683e-06,
      "epoch": 9.1408,
      "step": 20000
    },
    {
      "loss": 1.0458,
      "grad_norm": 2.761554002761841,
      "learning_rate": 5.219636055861194e-06,
      "epoch": 9.186514285714285,
      "step": 20100
    },
    {
      "loss": 1.0451,
      "grad_norm": 2.4380552768707275,
      "learning_rate": 5.1349978840457045e-06,
      "epoch": 9.232228571428571,
      "step": 20200
    },
    {
      "loss": 1.011,
      "grad_norm": 1.90725839138031,
      "learning_rate": 5.050359712230216e-06,
      "epoch": 9.277942857142857,
      "step": 20300
    },
    {
      "loss": 1.0483,
      "grad_norm": 2.1785504817962646,
      "learning_rate": 4.965721540414727e-06,
      "epoch": 9.323657142857144,
      "step": 20400
    },
    {
      "loss": 1.0545,
      "grad_norm": 2.8370683193206787,
      "learning_rate": 4.881083368599239e-06,
      "epoch": 9.369371428571428,
      "step": 20500
    },
    {
      "loss": 1.0416,
      "grad_norm": 3.6831798553466797,
      "learning_rate": 4.79644519678375e-06,
      "epoch": 9.415085714285715,
      "step": 20600
    },
    {
      "loss": 1.0594,
      "grad_norm": 2.6617748737335205,
      "learning_rate": 4.7118070249682616e-06,
      "epoch": 9.4608,
      "step": 20700
    },
    {
      "loss": 1.0173,
      "grad_norm": 3.1955950260162354,
      "learning_rate": 4.6271688531527725e-06,
      "epoch": 9.506514285714285,
      "step": 20800
    },
    {
      "loss": 1.0079,
      "grad_norm": 1.976574420928955,
      "learning_rate": 4.542530681337283e-06,
      "epoch": 9.552228571428572,
      "step": 20900
    },
    {
      "loss": 1.0489,
      "grad_norm": 3.1433088779449463,
      "learning_rate": 4.457892509521794e-06,
      "epoch": 9.597942857142858,
      "step": 21000
    },
    {
      "loss": 1.0377,
      "grad_norm": 1.577391266822815,
      "learning_rate": 4.373254337706306e-06,
      "epoch": 9.643657142857142,
      "step": 21100
    },
    {
      "loss": 1.0167,
      "grad_norm": 2.2028253078460693,
      "learning_rate": 4.288616165890817e-06,
      "epoch": 9.689371428571429,
      "step": 21200
    },
    {
      "loss": 1.0199,
      "grad_norm": 2.3195695877075195,
      "learning_rate": 4.203977994075329e-06,
      "epoch": 9.735085714285715,
      "step": 21300
    },
    {
      "loss": 1.0823,
      "grad_norm": 1.9786627292633057,
      "learning_rate": 4.1193398222598396e-06,
      "epoch": 9.7808,
      "step": 21400
    },
    {
      "loss": 1.0448,
      "grad_norm": 2.5387625694274902,
      "learning_rate": 4.034701650444351e-06,
      "epoch": 9.826514285714286,
      "step": 21500
    },
    {
      "loss": 1.0353,
      "grad_norm": 1.8414298295974731,
      "learning_rate": 3.950063478628862e-06,
      "epoch": 9.872228571428572,
      "step": 21600
    },
    {
      "loss": 1.0504,
      "grad_norm": 3.1948933601379395,
      "learning_rate": 3.865425306813373e-06,
      "epoch": 9.917942857142858,
      "step": 21700
    },
    {
      "loss": 1.0046,
      "grad_norm": 2.432068109512329,
      "learning_rate": 3.780787134997884e-06,
      "epoch": 9.963657142857143,
      "step": 21800
    },
    {
      "eval_loss": 0.5188549757003784,
      "eval_roc_auc": 0.7994366133333333,
      "eval_accuracy": 0.7410666666666667,
      "eval_f1": 0.7410517098134255,
      "eval_precision": 0.7411223755803208,
      "eval_recall": 0.7410666666666667,
      "eval_runtime": 28.2263,
      "eval_samples_per_second": 531.42,
      "eval_steps_per_second": 16.616,
      "epoch": 10.0,
      "step": 21880
    },
    {
      "loss": 0.9968,
      "grad_norm": 2.887176752090454,
      "learning_rate": 3.6961489631823953e-06,
      "epoch": 10.009142857142857,
      "step": 21900
    },
    {
      "loss": 1.0357,
      "grad_norm": 5.005754470825195,
      "learning_rate": 3.6115107913669066e-06,
      "epoch": 10.054857142857143,
      "step": 22000
    },
    {
      "loss": 1.0335,
      "grad_norm": 2.9234700202941895,
      "learning_rate": 3.526872619551418e-06,
      "epoch": 10.10057142857143,
      "step": 22100
    },
    {
      "loss": 1.034,
      "grad_norm": 2.794260263442993,
      "learning_rate": 3.4422344477359293e-06,
      "epoch": 10.146285714285714,
      "step": 22200
    },
    {
      "loss": 1.0429,
      "grad_norm": 3.5723068714141846,
      "learning_rate": 3.3575962759204406e-06,
      "epoch": 10.192,
      "step": 22300
    },
    {
      "loss": 1.0494,
      "grad_norm": 3.523909568786621,
      "learning_rate": 3.272958104104952e-06,
      "epoch": 10.237714285714286,
      "step": 22400
    },
    {
      "loss": 1.0411,
      "grad_norm": 2.2991909980773926,
      "learning_rate": 3.1883199322894624e-06,
      "epoch": 10.283428571428571,
      "step": 22500
    },
    {
      "loss": 1.0216,
      "grad_norm": 3.7603254318237305,
      "learning_rate": 3.1036817604739737e-06,
      "epoch": 10.329142857142857,
      "step": 22600
    },
    {
      "loss": 1.032,
      "grad_norm": 1.7662538290023804,
      "learning_rate": 3.019043588658485e-06,
      "epoch": 10.374857142857143,
      "step": 22700
    },
    {
      "loss": 1.0156,
      "grad_norm": 2.639531135559082,
      "learning_rate": 2.9344054168429964e-06,
      "epoch": 10.420571428571428,
      "step": 22800
    },
    {
      "loss": 1.0084,
      "grad_norm": 3.2149858474731445,
      "learning_rate": 2.8497672450275077e-06,
      "epoch": 10.466285714285714,
      "step": 22900
    },
    {
      "loss": 1.0422,
      "grad_norm": 3.6069250106811523,
      "learning_rate": 2.765129073212019e-06,
      "epoch": 10.512,
      "step": 23000
    },
    {
      "loss": 1.0432,
      "grad_norm": 2.1471199989318848,
      "learning_rate": 2.6804909013965304e-06,
      "epoch": 10.557714285714285,
      "step": 23100
    },
    {
      "loss": 1.0551,
      "grad_norm": 2.13470196723938,
      "learning_rate": 2.5958527295810417e-06,
      "epoch": 10.603428571428571,
      "step": 23200
    },
    {
      "loss": 1.038,
      "grad_norm": 3.874000072479248,
      "learning_rate": 2.511214557765552e-06,
      "epoch": 10.649142857142857,
      "step": 23300
    },
    {
      "loss": 1.028,
      "grad_norm": 4.057952880859375,
      "learning_rate": 2.4274227676682187e-06,
      "epoch": 10.694857142857142,
      "step": 23400
    },
    {
      "loss": 1.0115,
      "grad_norm": 2.1222774982452393,
      "learning_rate": 2.3427845958527296e-06,
      "epoch": 10.740571428571428,
      "step": 23500
    },
    {
      "loss": 1.043,
      "grad_norm": 2.842752695083618,
      "learning_rate": 2.258146424037241e-06,
      "epoch": 10.786285714285714,
      "step": 23600
    },
    {
      "loss": 1.0513,
      "grad_norm": 3.359088182449341,
      "learning_rate": 2.1735082522217523e-06,
      "epoch": 10.832,
      "step": 23700
    },
    {
      "loss": 1.0191,
      "grad_norm": 2.360805034637451,
      "learning_rate": 2.088870080406263e-06,
      "epoch": 10.877714285714285,
      "step": 23800
    },
    {
      "loss": 1.0183,
      "grad_norm": 2.2785420417785645,
      "learning_rate": 2.0042319085907745e-06,
      "epoch": 10.923428571428571,
      "step": 23900
    },
    {
      "loss": 1.0006,
      "grad_norm": 3.971897602081299,
      "learning_rate": 1.919593736775286e-06,
      "epoch": 10.969142857142858,
      "step": 24000
    },
    {
      "eval_loss": 0.5181084871292114,
      "eval_roc_auc": 0.8001357333333333,
      "eval_accuracy": 0.7407333333333334,
      "eval_f1": 0.7407298475901731,
      "eval_precision": 0.7407462801332871,
      "eval_recall": 0.7407333333333334,
      "eval_runtime": 28.2801,
      "eval_samples_per_second": 530.408,
      "eval_steps_per_second": 16.584,
      "epoch": 11.0,
      "step": 24068
    },
    {
      "loss": 1.0031,
      "grad_norm": 4.0858330726623535,
      "learning_rate": 1.834955564959797e-06,
      "epoch": 11.014628571428572,
      "step": 24100
    },
    {
      "loss": 1.0648,
      "grad_norm": 2.180846691131592,
      "learning_rate": 1.7503173931443082e-06,
      "epoch": 11.060342857142857,
      "step": 24200
    },
    {
      "loss": 1.0517,
      "grad_norm": 5.086282253265381,
      "learning_rate": 1.6656792213288196e-06,
      "epoch": 11.106057142857143,
      "step": 24300
    },
    {
      "loss": 1.0238,
      "grad_norm": 2.686506748199463,
      "learning_rate": 1.5810410495133307e-06,
      "epoch": 11.15177142857143,
      "step": 24400
    },
    {
      "loss": 1.0182,
      "grad_norm": 2.780690908432007,
      "learning_rate": 1.4964028776978418e-06,
      "epoch": 11.197485714285714,
      "step": 24500
    },
    {
      "loss": 0.9954,
      "grad_norm": 2.797908067703247,
      "learning_rate": 1.4117647058823531e-06,
      "epoch": 11.2432,
      "step": 24600
    },
    {
      "loss": 1.0382,
      "grad_norm": 2.7089121341705322,
      "learning_rate": 1.3271265340668642e-06,
      "epoch": 11.288914285714286,
      "step": 24700
    },
    {
      "loss": 1.0279,
      "grad_norm": 6.909435272216797,
      "learning_rate": 1.2424883622513755e-06,
      "epoch": 11.33462857142857,
      "step": 24800
    },
    {
      "loss": 1.0453,
      "grad_norm": 4.251756191253662,
      "learning_rate": 1.1578501904358867e-06,
      "epoch": 11.380342857142857,
      "step": 24900
    },
    {
      "loss": 1.0254,
      "grad_norm": 3.101799488067627,
      "learning_rate": 1.0732120186203978e-06,
      "epoch": 11.426057142857143,
      "step": 25000
    },
    {
      "loss": 1.0329,
      "grad_norm": 2.865713357925415,
      "learning_rate": 9.88573846804909e-07,
      "epoch": 11.47177142857143,
      "step": 25100
    },
    {
      "loss": 1.0329,
      "grad_norm": 2.2432355880737305,
      "learning_rate": 9.039356749894203e-07,
      "epoch": 11.517485714285714,
      "step": 25200
    },
    {
      "loss": 1.052,
      "grad_norm": 2.9819679260253906,
      "learning_rate": 8.192975031739315e-07,
      "epoch": 11.5632,
      "step": 25300
    },
    {
      "loss": 1.0222,
      "grad_norm": 2.1208322048187256,
      "learning_rate": 7.346593313584427e-07,
      "epoch": 11.608914285714286,
      "step": 25400
    },
    {
      "loss": 1.014,
      "grad_norm": 2.5599544048309326,
      "learning_rate": 6.508675412611089e-07,
      "epoch": 11.654628571428571,
      "step": 25500
    },
    {
      "loss": 1.0167,
      "grad_norm": 2.974571943283081,
      "learning_rate": 5.6622936944562e-07,
      "epoch": 11.700342857142857,
      "step": 25600
    },
    {
      "loss": 1.002,
      "grad_norm": 2.3426010608673096,
      "learning_rate": 4.815911976301312e-07,
      "epoch": 11.746057142857143,
      "step": 25700
    },
    {
      "loss": 1.0519,
      "grad_norm": 1.9267613887786865,
      "learning_rate": 3.9695302581464244e-07,
      "epoch": 11.791771428571428,
      "step": 25800
    },
    {
      "loss": 1.0369,
      "grad_norm": 2.3663535118103027,
      "learning_rate": 3.1231485399915366e-07,
      "epoch": 11.837485714285714,
      "step": 25900
    },
    {
      "loss": 1.0474,
      "grad_norm": 2.3817522525787354,
      "learning_rate": 2.2767668218366485e-07,
      "epoch": 11.8832,
      "step": 26000
    },
    {
      "loss": 1.0336,
      "grad_norm": 1.968591332435608,
      "learning_rate": 1.4303851036817606e-07,
      "epoch": 11.928914285714285,
      "step": 26100
    },
    {
      "loss": 1.0175,
      "grad_norm": 2.8284785747528076,
      "learning_rate": 5.8400338552687266e-08,
      "epoch": 11.974628571428571,
      "step": 26200
    },
    {
      "eval_loss": 0.5178505182266235,
      "eval_roc_auc": 0.8004984622222222,
      "eval_accuracy": 0.741,
      "eval_f1": 0.7409948325591261,
      "eval_precision": 0.7410192344061023,
      "eval_recall": 0.741,
      "eval_runtime": 28.3053,
      "eval_samples_per_second": 529.936,
      "eval_steps_per_second": 16.569,
      "epoch": 12.0,
      "step": 26256
    },
    {
      "train_runtime": 2334.9248,
      "train_samples_per_second": 359.755,
      "train_steps_per_second": 11.245,
      "total_flos": 2.8623659065344e+17,
      "train_loss": 1.0927000981434898,
      "epoch": 12.0,
      "step": 26256
    },
    {
      "eval_loss": 0.5214334726333618,
      "eval_roc_auc": 0.7980433066666667,
      "eval_accuracy": 0.7377333333333334,
      "eval_f1": 0.7377329556687895,
      "eval_precision": 0.7377347026852208,
      "eval_recall": 0.7377333333333334,
      "eval_runtime": 28.2025,
      "eval_samples_per_second": 531.867,
      "eval_steps_per_second": 16.63,
      "epoch": 12.0,
      "step": 26256
    }
  ],
  "run_name": "modernbert-sentiment-% Y0816_1050"
}