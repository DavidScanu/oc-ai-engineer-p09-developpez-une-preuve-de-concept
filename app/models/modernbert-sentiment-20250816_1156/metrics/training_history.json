{
  "log_history": [
    {
      "loss": 0.7616,
      "grad_norm": 2.3601815700531006,
      "learning_rate": 5.026656511805027e-07,
      "epoch": 0.04570383912248629,
      "step": 100
    },
    {
      "loss": 0.7613,
      "grad_norm": 2.180464029312134,
      "learning_rate": 1.0104087331810104e-06,
      "epoch": 0.09140767824497258,
      "step": 200
    },
    {
      "loss": 0.7627,
      "grad_norm": 2.0089383125305176,
      "learning_rate": 1.5181518151815183e-06,
      "epoch": 0.13711151736745886,
      "step": 300
    },
    {
      "loss": 0.758,
      "grad_norm": 1.7303084135055542,
      "learning_rate": 2.025894897182026e-06,
      "epoch": 0.18281535648994515,
      "step": 400
    },
    {
      "loss": 0.741,
      "grad_norm": 2.4469146728515625,
      "learning_rate": 2.533637979182534e-06,
      "epoch": 0.22851919561243145,
      "step": 500
    },
    {
      "loss": 0.7379,
      "grad_norm": 1.4006836414337158,
      "learning_rate": 3.0413810611830417e-06,
      "epoch": 0.2742230347349177,
      "step": 600
    },
    {
      "loss": 0.7302,
      "grad_norm": 2.101956844329834,
      "learning_rate": 3.5491241431835496e-06,
      "epoch": 0.31992687385740404,
      "step": 700
    },
    {
      "loss": 0.7197,
      "grad_norm": 1.4638515710830688,
      "learning_rate": 4.056867225184058e-06,
      "epoch": 0.3656307129798903,
      "step": 800
    },
    {
      "loss": 0.7191,
      "grad_norm": 1.3506101369857788,
      "learning_rate": 4.564610307184565e-06,
      "epoch": 0.4113345521023766,
      "step": 900
    },
    {
      "loss": 0.7114,
      "grad_norm": 2.1383001804351807,
      "learning_rate": 5.072353389185073e-06,
      "epoch": 0.4570383912248629,
      "step": 1000
    },
    {
      "loss": 0.7069,
      "grad_norm": 1.093566656112671,
      "learning_rate": 5.580096471185581e-06,
      "epoch": 0.5027422303473492,
      "step": 1100
    },
    {
      "loss": 0.6992,
      "grad_norm": 1.3175314664840698,
      "learning_rate": 6.087839553186088e-06,
      "epoch": 0.5484460694698354,
      "step": 1200
    },
    {
      "loss": 0.6962,
      "grad_norm": 1.2941083908081055,
      "learning_rate": 6.595582635186596e-06,
      "epoch": 0.5941499085923218,
      "step": 1300
    },
    {
      "loss": 0.6968,
      "grad_norm": 1.1518248319625854,
      "learning_rate": 7.103325717187104e-06,
      "epoch": 0.6398537477148081,
      "step": 1400
    },
    {
      "loss": 0.69,
      "grad_norm": 1.3888962268829346,
      "learning_rate": 7.611068799187612e-06,
      "epoch": 0.6855575868372943,
      "step": 1500
    },
    {
      "loss": 0.6844,
      "grad_norm": 1.1015112400054932,
      "learning_rate": 8.11881188118812e-06,
      "epoch": 0.7312614259597806,
      "step": 1600
    },
    {
      "loss": 0.6804,
      "grad_norm": 0.9812160730361938,
      "learning_rate": 8.626554963188627e-06,
      "epoch": 0.7769652650822669,
      "step": 1700
    },
    {
      "loss": 0.6727,
      "grad_norm": 1.0862913131713867,
      "learning_rate": 9.134298045189134e-06,
      "epoch": 0.8226691042047533,
      "step": 1800
    },
    {
      "loss": 0.6707,
      "grad_norm": 1.0725741386413574,
      "learning_rate": 9.642041127189643e-06,
      "epoch": 0.8683729433272395,
      "step": 1900
    },
    {
      "loss": 0.6639,
      "grad_norm": 0.8787115812301636,
      "learning_rate": 1.014978420919015e-05,
      "epoch": 0.9140767824497258,
      "step": 2000
    },
    {
      "loss": 0.6612,
      "grad_norm": 1.3725603818893433,
      "learning_rate": 1.0657527291190659e-05,
      "epoch": 0.9597806215722121,
      "step": 2100
    },
    {
      "eval_loss": 0.6532429456710815,
      "eval_roc_auc": 0.6285471555555556,
      "eval_accuracy": 0.6164666666666667,
      "eval_f1": 0.6162356848950721,
      "eval_precision": 0.6167477412642305,
      "eval_recall": 0.6164666666666667,
      "eval_runtime": 48.621,
      "eval_samples_per_second": 617.017,
      "eval_steps_per_second": 4.833,
      "epoch": 1.0,
      "step": 2188
    },
    {
      "loss": 0.658,
      "grad_norm": 0.9286664128303528,
      "learning_rate": 1.1165270373191166e-05,
      "epoch": 1.0054844606946984,
      "step": 2200
    },
    {
      "loss": 0.645,
      "grad_norm": 1.7588452100753784,
      "learning_rate": 1.1673013455191673e-05,
      "epoch": 1.0511882998171846,
      "step": 2300
    },
    {
      "loss": 0.6467,
      "grad_norm": 0.8471697568893433,
      "learning_rate": 1.2180756537192181e-05,
      "epoch": 1.0968921389396709,
      "step": 2400
    },
    {
      "loss": 0.6451,
      "grad_norm": 0.9791184663772583,
      "learning_rate": 1.2688499619192688e-05,
      "epoch": 1.1425959780621573,
      "step": 2500
    },
    {
      "loss": 0.6312,
      "grad_norm": 1.3314026594161987,
      "learning_rate": 1.3196242701193199e-05,
      "epoch": 1.1882998171846435,
      "step": 2600
    },
    {
      "loss": 0.636,
      "grad_norm": 0.798202633857727,
      "learning_rate": 1.3703985783193706e-05,
      "epoch": 1.2340036563071297,
      "step": 2700
    },
    {
      "loss": 0.6269,
      "grad_norm": 0.9478300213813782,
      "learning_rate": 1.4211728865194213e-05,
      "epoch": 1.2797074954296161,
      "step": 2800
    },
    {
      "loss": 0.6163,
      "grad_norm": 1.1448235511779785,
      "learning_rate": 1.4719471947194721e-05,
      "epoch": 1.3254113345521024,
      "step": 2900
    },
    {
      "loss": 0.6105,
      "grad_norm": 1.4003894329071045,
      "learning_rate": 1.5227215029195228e-05,
      "epoch": 1.3711151736745886,
      "step": 3000
    },
    {
      "loss": 0.6154,
      "grad_norm": 0.9039885997772217,
      "learning_rate": 1.5734958111195737e-05,
      "epoch": 1.416819012797075,
      "step": 3100
    },
    {
      "loss": 0.6079,
      "grad_norm": 1.1521852016448975,
      "learning_rate": 1.6242701193196244e-05,
      "epoch": 1.4625228519195612,
      "step": 3200
    },
    {
      "loss": 0.603,
      "grad_norm": 1.1801460981369019,
      "learning_rate": 1.675044427519675e-05,
      "epoch": 1.5082266910420477,
      "step": 3300
    },
    {
      "loss": 0.5958,
      "grad_norm": 1.2328792810440063,
      "learning_rate": 1.725818735719726e-05,
      "epoch": 1.5539305301645339,
      "step": 3400
    },
    {
      "loss": 0.5944,
      "grad_norm": 1.3368552923202515,
      "learning_rate": 1.7765930439197768e-05,
      "epoch": 1.59963436928702,
      "step": 3500
    },
    {
      "loss": 0.5955,
      "grad_norm": 1.7843122482299805,
      "learning_rate": 1.8273673521198275e-05,
      "epoch": 1.6453382084095063,
      "step": 3600
    },
    {
      "loss": 0.5851,
      "grad_norm": 0.8145878314971924,
      "learning_rate": 1.8781416603198782e-05,
      "epoch": 1.6910420475319927,
      "step": 3700
    },
    {
      "loss": 0.5912,
      "grad_norm": 0.7791167497634888,
      "learning_rate": 1.928915968519929e-05,
      "epoch": 1.736745886654479,
      "step": 3800
    },
    {
      "loss": 0.5814,
      "grad_norm": 1.0667195320129395,
      "learning_rate": 1.97969027671998e-05,
      "epoch": 1.7824497257769654,
      "step": 3900
    },
    {
      "loss": 0.584,
      "grad_norm": 1.9285061359405518,
      "learning_rate": 1.998055136869743e-05,
      "epoch": 1.8281535648994516,
      "step": 4000
    },
    {
      "loss": 0.5704,
      "grad_norm": 2.164001226425171,
      "learning_rate": 1.9948136983193143e-05,
      "epoch": 1.8738574040219378,
      "step": 4100
    },
    {
      "loss": 0.571,
      "grad_norm": 1.0326534509658813,
      "learning_rate": 1.9915722597688857e-05,
      "epoch": 1.919561243144424,
      "step": 4200
    },
    {
      "loss": 0.5701,
      "grad_norm": 0.8215468525886536,
      "learning_rate": 1.9883308212184567e-05,
      "epoch": 1.9652650822669104,
      "step": 4300
    },
    {
      "eval_loss": 0.5675836205482483,
      "eval_roc_auc": 0.7517705911111111,
      "eval_accuracy": 0.7092666666666667,
      "eval_f1": 0.7092297569381685,
      "eval_precision": 0.7093729760278814,
      "eval_recall": 0.7092666666666667,
      "eval_runtime": 48.6668,
      "eval_samples_per_second": 616.436,
      "eval_steps_per_second": 4.829,
      "epoch": 2.0,
      "step": 4376
    },
    {
      "loss": 0.5682,
      "grad_norm": 0.8387689590454102,
      "learning_rate": 1.985089382668028e-05,
      "epoch": 2.010968921389397,
      "step": 4400
    },
    {
      "loss": 0.5647,
      "grad_norm": 0.8263800144195557,
      "learning_rate": 1.9818479441175995e-05,
      "epoch": 2.056672760511883,
      "step": 4500
    },
    {
      "loss": 0.5678,
      "grad_norm": 0.9458545446395874,
      "learning_rate": 1.978606505567171e-05,
      "epoch": 2.1023765996343693,
      "step": 4600
    },
    {
      "loss": 0.5617,
      "grad_norm": 0.6576220989227295,
      "learning_rate": 1.975365067016742e-05,
      "epoch": 2.1480804387568555,
      "step": 4700
    },
    {
      "loss": 0.5621,
      "grad_norm": 1.2192482948303223,
      "learning_rate": 1.9721236284663134e-05,
      "epoch": 2.1937842778793417,
      "step": 4800
    },
    {
      "loss": 0.5568,
      "grad_norm": 0.9761418104171753,
      "learning_rate": 1.9688821899158848e-05,
      "epoch": 2.2394881170018284,
      "step": 4900
    },
    {
      "loss": 0.5549,
      "grad_norm": 0.8974860310554504,
      "learning_rate": 1.965640751365456e-05,
      "epoch": 2.2851919561243146,
      "step": 5000
    },
    {
      "loss": 0.5626,
      "grad_norm": 1.0379101037979126,
      "learning_rate": 1.9623993128150272e-05,
      "epoch": 2.330895795246801,
      "step": 5100
    },
    {
      "loss": 0.5486,
      "grad_norm": 1.0257669687271118,
      "learning_rate": 1.9591578742645986e-05,
      "epoch": 2.376599634369287,
      "step": 5200
    },
    {
      "loss": 0.5553,
      "grad_norm": 0.9026777744293213,
      "learning_rate": 1.95591643571417e-05,
      "epoch": 2.422303473491773,
      "step": 5300
    },
    {
      "loss": 0.5507,
      "grad_norm": 0.8402749300003052,
      "learning_rate": 1.9526749971637414e-05,
      "epoch": 2.4680073126142594,
      "step": 5400
    },
    {
      "loss": 0.5398,
      "grad_norm": 1.082417368888855,
      "learning_rate": 1.9494335586133128e-05,
      "epoch": 2.5137111517367456,
      "step": 5500
    },
    {
      "loss": 0.5426,
      "grad_norm": 1.0682017803192139,
      "learning_rate": 1.9461921200628842e-05,
      "epoch": 2.5594149908592323,
      "step": 5600
    },
    {
      "loss": 0.5354,
      "grad_norm": 0.8590943217277527,
      "learning_rate": 1.9429506815124556e-05,
      "epoch": 2.6051188299817185,
      "step": 5700
    },
    {
      "loss": 0.5423,
      "grad_norm": 1.346603274345398,
      "learning_rate": 1.9397092429620267e-05,
      "epoch": 2.6508226691042047,
      "step": 5800
    },
    {
      "loss": 0.546,
      "grad_norm": 1.633599877357483,
      "learning_rate": 1.936467804411598e-05,
      "epoch": 2.696526508226691,
      "step": 5900
    },
    {
      "loss": 0.5355,
      "grad_norm": 0.9302443265914917,
      "learning_rate": 1.9332263658611695e-05,
      "epoch": 2.742230347349177,
      "step": 6000
    },
    {
      "loss": 0.5407,
      "grad_norm": 0.8794371485710144,
      "learning_rate": 1.929984927310741e-05,
      "epoch": 2.787934186471664,
      "step": 6100
    },
    {
      "loss": 0.5376,
      "grad_norm": 1.496270775794983,
      "learning_rate": 1.926743488760312e-05,
      "epoch": 2.83363802559415,
      "step": 6200
    },
    {
      "loss": 0.5354,
      "grad_norm": 0.8038992285728455,
      "learning_rate": 1.9235020502098833e-05,
      "epoch": 2.8793418647166362,
      "step": 6300
    },
    {
      "loss": 0.5364,
      "grad_norm": 2.1843292713165283,
      "learning_rate": 1.9202606116594547e-05,
      "epoch": 2.9250457038391224,
      "step": 6400
    },
    {
      "loss": 0.5275,
      "grad_norm": 0.989048182964325,
      "learning_rate": 1.917019173109026e-05,
      "epoch": 2.9707495429616086,
      "step": 6500
    },
    {
      "eval_loss": 0.5340120792388916,
      "eval_roc_auc": 0.7884452155555555,
      "eval_accuracy": 0.7343333333333333,
      "eval_f1": 0.734332407629367,
      "eval_precision": 0.7343365994647819,
      "eval_recall": 0.7343333333333333,
      "eval_runtime": 48.6621,
      "eval_samples_per_second": 616.496,
      "eval_steps_per_second": 4.829,
      "epoch": 3.0,
      "step": 6564
    },
    {
      "loss": 0.5289,
      "grad_norm": 1.3444217443466187,
      "learning_rate": 1.9137777345585972e-05,
      "epoch": 3.016453382084095,
      "step": 6600
    },
    {
      "loss": 0.5308,
      "grad_norm": 1.2452187538146973,
      "learning_rate": 1.9105362960081686e-05,
      "epoch": 3.0621572212065815,
      "step": 6700
    },
    {
      "loss": 0.5369,
      "grad_norm": 1.597006916999817,
      "learning_rate": 1.90729485745774e-05,
      "epoch": 3.1078610603290677,
      "step": 6800
    },
    {
      "loss": 0.5262,
      "grad_norm": 0.8934258222579956,
      "learning_rate": 1.9040534189073114e-05,
      "epoch": 3.153564899451554,
      "step": 6900
    },
    {
      "loss": 0.5243,
      "grad_norm": 1.4648243188858032,
      "learning_rate": 1.9008119803568824e-05,
      "epoch": 3.19926873857404,
      "step": 7000
    },
    {
      "loss": 0.5248,
      "grad_norm": 1.8094215393066406,
      "learning_rate": 1.8975705418064538e-05,
      "epoch": 3.2449725776965264,
      "step": 7100
    },
    {
      "loss": 0.5241,
      "grad_norm": 1.4958131313323975,
      "learning_rate": 1.8943291032560252e-05,
      "epoch": 3.2906764168190126,
      "step": 7200
    },
    {
      "loss": 0.5288,
      "grad_norm": 1.64145827293396,
      "learning_rate": 1.8910876647055966e-05,
      "epoch": 3.3363802559414992,
      "step": 7300
    },
    {
      "loss": 0.5231,
      "grad_norm": 1.249111294746399,
      "learning_rate": 1.8878462261551677e-05,
      "epoch": 3.3820840950639854,
      "step": 7400
    },
    {
      "loss": 0.5315,
      "grad_norm": 0.7593551874160767,
      "learning_rate": 1.884604787604739e-05,
      "epoch": 3.4277879341864717,
      "step": 7500
    },
    {
      "loss": 0.525,
      "grad_norm": 0.7097333073616028,
      "learning_rate": 1.8813633490543105e-05,
      "epoch": 3.473491773308958,
      "step": 7600
    },
    {
      "loss": 0.5254,
      "grad_norm": 1.48331880569458,
      "learning_rate": 1.878121910503882e-05,
      "epoch": 3.519195612431444,
      "step": 7700
    },
    {
      "loss": 0.5256,
      "grad_norm": 0.944642961025238,
      "learning_rate": 1.874880471953453e-05,
      "epoch": 3.5648994515539307,
      "step": 7800
    },
    {
      "loss": 0.5185,
      "grad_norm": 1.061812400817871,
      "learning_rate": 1.8716390334030243e-05,
      "epoch": 3.610603290676417,
      "step": 7900
    },
    {
      "loss": 0.5249,
      "grad_norm": 0.7182438373565674,
      "learning_rate": 1.8683975948525957e-05,
      "epoch": 3.656307129798903,
      "step": 8000
    },
    {
      "loss": 0.5227,
      "grad_norm": 0.6943650245666504,
      "learning_rate": 1.865156156302167e-05,
      "epoch": 3.7020109689213894,
      "step": 8100
    },
    {
      "loss": 0.523,
      "grad_norm": 2.144733190536499,
      "learning_rate": 1.8619147177517382e-05,
      "epoch": 3.7477148080438756,
      "step": 8200
    },
    {
      "loss": 0.5293,
      "grad_norm": 0.7023442983627319,
      "learning_rate": 1.85867327920131e-05,
      "epoch": 3.7934186471663622,
      "step": 8300
    },
    {
      "loss": 0.5202,
      "grad_norm": 0.8073356747627258,
      "learning_rate": 1.855431840650881e-05,
      "epoch": 3.839122486288848,
      "step": 8400
    },
    {
      "loss": 0.5269,
      "grad_norm": 1.0242393016815186,
      "learning_rate": 1.8521904021004524e-05,
      "epoch": 3.8848263254113347,
      "step": 8500
    },
    {
      "loss": 0.5159,
      "grad_norm": 1.566967487335205,
      "learning_rate": 1.8489489635500238e-05,
      "epoch": 3.930530164533821,
      "step": 8600
    },
    {
      "loss": 0.5127,
      "grad_norm": 1.1070266962051392,
      "learning_rate": 1.845707524999595e-05,
      "epoch": 3.976234003656307,
      "step": 8700
    },
    {
      "eval_loss": 0.5185382962226868,
      "eval_roc_auc": 0.8029810577777778,
      "eval_accuracy": 0.7439666666666667,
      "eval_f1": 0.7439362437317844,
      "eval_precision": 0.7440826645121495,
      "eval_recall": 0.7439666666666667,
      "eval_runtime": 48.6547,
      "eval_samples_per_second": 616.59,
      "eval_steps_per_second": 4.83,
      "epoch": 4.0,
      "step": 8752
    },
    {
      "loss": 0.5204,
      "grad_norm": 0.8519808650016785,
      "learning_rate": 1.8424660864491662e-05,
      "epoch": 4.021937842778794,
      "step": 8800
    },
    {
      "loss": 0.5259,
      "grad_norm": 1.052008867263794,
      "learning_rate": 1.8392246478987376e-05,
      "epoch": 4.0676416819012795,
      "step": 8900
    },
    {
      "loss": 0.5188,
      "grad_norm": 0.7038499116897583,
      "learning_rate": 1.835983209348309e-05,
      "epoch": 4.113345521023766,
      "step": 9000
    },
    {
      "loss": 0.519,
      "grad_norm": 1.1421176195144653,
      "learning_rate": 1.8327417707978804e-05,
      "epoch": 4.159049360146252,
      "step": 9100
    },
    {
      "loss": 0.5127,
      "grad_norm": 0.9577773809432983,
      "learning_rate": 1.8295003322474515e-05,
      "epoch": 4.204753199268739,
      "step": 9200
    },
    {
      "loss": 0.5147,
      "grad_norm": 0.8823177814483643,
      "learning_rate": 1.826258893697023e-05,
      "epoch": 4.250457038391225,
      "step": 9300
    },
    {
      "loss": 0.5125,
      "grad_norm": 0.8852212429046631,
      "learning_rate": 1.8230174551465943e-05,
      "epoch": 4.296160877513711,
      "step": 9400
    },
    {
      "loss": 0.5024,
      "grad_norm": 0.9925124049186707,
      "learning_rate": 1.8197760165961657e-05,
      "epoch": 4.341864716636198,
      "step": 9500
    },
    {
      "loss": 0.515,
      "grad_norm": 0.8540719747543335,
      "learning_rate": 1.8165345780457367e-05,
      "epoch": 4.387568555758683,
      "step": 9600
    },
    {
      "loss": 0.5215,
      "grad_norm": 0.8782159686088562,
      "learning_rate": 1.813293139495308e-05,
      "epoch": 4.43327239488117,
      "step": 9700
    },
    {
      "loss": 0.5187,
      "grad_norm": 1.1167411804199219,
      "learning_rate": 1.8100517009448795e-05,
      "epoch": 4.478976234003657,
      "step": 9800
    },
    {
      "loss": 0.5106,
      "grad_norm": 0.8463632464408875,
      "learning_rate": 1.806810262394451e-05,
      "epoch": 4.5246800731261425,
      "step": 9900
    },
    {
      "loss": 0.5052,
      "grad_norm": 0.6568104028701782,
      "learning_rate": 1.803568823844022e-05,
      "epoch": 4.570383912248629,
      "step": 10000
    },
    {
      "loss": 0.5098,
      "grad_norm": 0.946955680847168,
      "learning_rate": 1.8003273852935934e-05,
      "epoch": 4.616087751371115,
      "step": 10100
    },
    {
      "loss": 0.5106,
      "grad_norm": 0.9618228077888489,
      "learning_rate": 1.7970859467431648e-05,
      "epoch": 4.661791590493602,
      "step": 10200
    },
    {
      "loss": 0.5242,
      "grad_norm": 0.9998368620872498,
      "learning_rate": 1.7938445081927362e-05,
      "epoch": 4.707495429616088,
      "step": 10300
    },
    {
      "loss": 0.5166,
      "grad_norm": 0.9014186263084412,
      "learning_rate": 1.7906030696423072e-05,
      "epoch": 4.753199268738574,
      "step": 10400
    },
    {
      "loss": 0.5074,
      "grad_norm": 1.1940497159957886,
      "learning_rate": 1.7873616310918786e-05,
      "epoch": 4.798903107861061,
      "step": 10500
    },
    {
      "loss": 0.5102,
      "grad_norm": 1.2628754377365112,
      "learning_rate": 1.78412019254145e-05,
      "epoch": 4.844606946983546,
      "step": 10600
    },
    {
      "loss": 0.5015,
      "grad_norm": 1.386962890625,
      "learning_rate": 1.7808787539910214e-05,
      "epoch": 4.890310786106033,
      "step": 10700
    },
    {
      "loss": 0.5082,
      "grad_norm": 1.027797818183899,
      "learning_rate": 1.7776373154405925e-05,
      "epoch": 4.936014625228519,
      "step": 10800
    },
    {
      "loss": 0.5017,
      "grad_norm": 1.354455590248108,
      "learning_rate": 1.774395876890164e-05,
      "epoch": 4.9817184643510055,
      "step": 10900
    },
    {
      "eval_loss": 0.5091652870178223,
      "eval_roc_auc": 0.8114071822222223,
      "eval_accuracy": 0.7497666666666667,
      "eval_f1": 0.7497520852767823,
      "eval_precision": 0.7498248936322088,
      "eval_recall": 0.7497666666666667,
      "eval_runtime": 48.7135,
      "eval_samples_per_second": 615.846,
      "eval_steps_per_second": 4.824,
      "epoch": 5.0,
      "step": 10940
    },
    {
      "loss": 0.5112,
      "grad_norm": 0.9889988303184509,
      "learning_rate": 1.7711544383397353e-05,
      "epoch": 5.027422303473492,
      "step": 11000
    },
    {
      "loss": 0.5122,
      "grad_norm": 1.6069387197494507,
      "learning_rate": 1.7679129997893067e-05,
      "epoch": 5.073126142595978,
      "step": 11100
    },
    {
      "loss": 0.5057,
      "grad_norm": 1.3277552127838135,
      "learning_rate": 1.764671561238878e-05,
      "epoch": 5.118829981718465,
      "step": 11200
    },
    {
      "loss": 0.5204,
      "grad_norm": 1.091042160987854,
      "learning_rate": 1.7614301226884495e-05,
      "epoch": 5.16453382084095,
      "step": 11300
    },
    {
      "loss": 0.501,
      "grad_norm": 0.7100074291229248,
      "learning_rate": 1.7581886841380205e-05,
      "epoch": 5.210237659963437,
      "step": 11400
    },
    {
      "loss": 0.5071,
      "grad_norm": 1.178941011428833,
      "learning_rate": 1.754947245587592e-05,
      "epoch": 5.255941499085923,
      "step": 11500
    },
    {
      "loss": 0.5101,
      "grad_norm": 0.9787272810935974,
      "learning_rate": 1.7517058070371633e-05,
      "epoch": 5.301645338208409,
      "step": 11600
    },
    {
      "loss": 0.5036,
      "grad_norm": 0.78940349817276,
      "learning_rate": 1.7484643684867347e-05,
      "epoch": 5.347349177330896,
      "step": 11700
    },
    {
      "loss": 0.5017,
      "grad_norm": 0.7166414260864258,
      "learning_rate": 1.7452229299363058e-05,
      "epoch": 5.393053016453382,
      "step": 11800
    },
    {
      "loss": 0.4981,
      "grad_norm": 0.8748329281806946,
      "learning_rate": 1.7419814913858772e-05,
      "epoch": 5.4387568555758685,
      "step": 11900
    },
    {
      "loss": 0.5023,
      "grad_norm": 0.994286835193634,
      "learning_rate": 1.7387400528354486e-05,
      "epoch": 5.484460694698354,
      "step": 12000
    },
    {
      "loss": 0.506,
      "grad_norm": 0.8988235592842102,
      "learning_rate": 1.73549861428502e-05,
      "epoch": 5.530164533820841,
      "step": 12100
    },
    {
      "loss": 0.4996,
      "grad_norm": 1.2298414707183838,
      "learning_rate": 1.732257175734591e-05,
      "epoch": 5.575868372943328,
      "step": 12200
    },
    {
      "loss": 0.5138,
      "grad_norm": 1.3997539281845093,
      "learning_rate": 1.7290157371841624e-05,
      "epoch": 5.621572212065813,
      "step": 12300
    },
    {
      "loss": 0.5041,
      "grad_norm": 0.6998929977416992,
      "learning_rate": 1.725774298633734e-05,
      "epoch": 5.6672760511883,
      "step": 12400
    },
    {
      "loss": 0.5113,
      "grad_norm": 0.9803102016448975,
      "learning_rate": 1.7225328600833052e-05,
      "epoch": 5.712979890310786,
      "step": 12500
    },
    {
      "loss": 0.5033,
      "grad_norm": 0.7820250391960144,
      "learning_rate": 1.7192914215328763e-05,
      "epoch": 5.7586837294332724,
      "step": 12600
    },
    {
      "loss": 0.4983,
      "grad_norm": 1.4762250185012817,
      "learning_rate": 1.7160499829824477e-05,
      "epoch": 5.804387568555759,
      "step": 12700
    },
    {
      "loss": 0.5069,
      "grad_norm": 0.754836916923523,
      "learning_rate": 1.712808544432019e-05,
      "epoch": 5.850091407678245,
      "step": 12800
    },
    {
      "loss": 0.5069,
      "grad_norm": 0.7286662459373474,
      "learning_rate": 1.7095671058815905e-05,
      "epoch": 5.8957952468007315,
      "step": 12900
    },
    {
      "loss": 0.5022,
      "grad_norm": 1.596085548400879,
      "learning_rate": 1.7063256673311615e-05,
      "epoch": 5.941499085923217,
      "step": 13000
    },
    {
      "loss": 0.4863,
      "grad_norm": 1.3438539505004883,
      "learning_rate": 1.703084228780733e-05,
      "epoch": 5.987202925045704,
      "step": 13100
    },
    {
      "eval_loss": 0.5027390122413635,
      "eval_roc_auc": 0.8171725422222221,
      "eval_accuracy": 0.7537333333333334,
      "eval_f1": 0.7537276592186016,
      "eval_precision": 0.7537567195526071,
      "eval_recall": 0.7537333333333334,
      "eval_runtime": 48.6987,
      "eval_samples_per_second": 616.033,
      "eval_steps_per_second": 4.826,
      "epoch": 6.0,
      "step": 13128
    },
    {
      "loss": 0.5105,
      "grad_norm": 1.1259971857070923,
      "learning_rate": 1.6998427902303043e-05,
      "epoch": 6.03290676416819,
      "step": 13200
    },
    {
      "loss": 0.5026,
      "grad_norm": 1.0229122638702393,
      "learning_rate": 1.6966013516798757e-05,
      "epoch": 6.078610603290676,
      "step": 13300
    },
    {
      "loss": 0.5075,
      "grad_norm": 1.0814324617385864,
      "learning_rate": 1.6933599131294468e-05,
      "epoch": 6.124314442413163,
      "step": 13400
    },
    {
      "loss": 0.5064,
      "grad_norm": 1.3915770053863525,
      "learning_rate": 1.6901184745790182e-05,
      "epoch": 6.170018281535649,
      "step": 13500
    },
    {
      "loss": 0.4976,
      "grad_norm": 0.8783285021781921,
      "learning_rate": 1.6868770360285896e-05,
      "epoch": 6.2157221206581355,
      "step": 13600
    },
    {
      "loss": 0.4994,
      "grad_norm": 1.249489665031433,
      "learning_rate": 1.683635597478161e-05,
      "epoch": 6.261425959780621,
      "step": 13700
    },
    {
      "loss": 0.4909,
      "grad_norm": 0.8599708080291748,
      "learning_rate": 1.680394158927732e-05,
      "epoch": 6.307129798903108,
      "step": 13800
    },
    {
      "loss": 0.5005,
      "grad_norm": 1.1106280088424683,
      "learning_rate": 1.6771527203773034e-05,
      "epoch": 6.3528336380255945,
      "step": 13900
    },
    {
      "loss": 0.4992,
      "grad_norm": 0.6392598748207092,
      "learning_rate": 1.6739112818268752e-05,
      "epoch": 6.39853747714808,
      "step": 14000
    },
    {
      "loss": 0.4984,
      "grad_norm": 0.6277339458465576,
      "learning_rate": 1.6706698432764462e-05,
      "epoch": 6.444241316270567,
      "step": 14100
    },
    {
      "loss": 0.498,
      "grad_norm": 0.8240312337875366,
      "learning_rate": 1.6674284047260176e-05,
      "epoch": 6.489945155393053,
      "step": 14200
    },
    {
      "loss": 0.4966,
      "grad_norm": 1.7261916399002075,
      "learning_rate": 1.664186966175589e-05,
      "epoch": 6.535648994515539,
      "step": 14300
    },
    {
      "loss": 0.4893,
      "grad_norm": 0.8547182083129883,
      "learning_rate": 1.66094552762516e-05,
      "epoch": 6.581352833638025,
      "step": 14400
    },
    {
      "loss": 0.5019,
      "grad_norm": 0.8179837465286255,
      "learning_rate": 1.6577040890747315e-05,
      "epoch": 6.627056672760512,
      "step": 14500
    },
    {
      "loss": 0.4963,
      "grad_norm": 0.7785555720329285,
      "learning_rate": 1.654462650524303e-05,
      "epoch": 6.6727605118829985,
      "step": 14600
    },
    {
      "loss": 0.5039,
      "grad_norm": 1.1305772066116333,
      "learning_rate": 1.6512212119738743e-05,
      "epoch": 6.718464351005484,
      "step": 14700
    },
    {
      "loss": 0.5038,
      "grad_norm": 0.7538353204727173,
      "learning_rate": 1.6479797734234453e-05,
      "epoch": 6.764168190127971,
      "step": 14800
    },
    {
      "loss": 0.4946,
      "grad_norm": 0.8710645437240601,
      "learning_rate": 1.6447383348730167e-05,
      "epoch": 6.809872029250457,
      "step": 14900
    },
    {
      "loss": 0.5032,
      "grad_norm": 0.9379597902297974,
      "learning_rate": 1.641496896322588e-05,
      "epoch": 6.855575868372943,
      "step": 15000
    },
    {
      "loss": 0.5086,
      "grad_norm": 1.2692008018493652,
      "learning_rate": 1.6382554577721595e-05,
      "epoch": 6.90127970749543,
      "step": 15100
    },
    {
      "loss": 0.495,
      "grad_norm": 1.0951675176620483,
      "learning_rate": 1.6350140192217306e-05,
      "epoch": 6.946983546617916,
      "step": 15200
    },
    {
      "loss": 0.4961,
      "grad_norm": 0.9223989844322205,
      "learning_rate": 1.631772580671302e-05,
      "epoch": 6.992687385740402,
      "step": 15300
    },
    {
      "eval_loss": 0.49828118085861206,
      "eval_roc_auc": 0.8213132244444445,
      "eval_accuracy": 0.7559333333333333,
      "eval_f1": 0.7559111494537564,
      "eval_precision": 0.7560264086049701,
      "eval_recall": 0.7559333333333333,
      "eval_runtime": 48.7416,
      "eval_samples_per_second": 615.49,
      "eval_steps_per_second": 4.821,
      "epoch": 7.0,
      "step": 15316
    },
    {
      "loss": 0.4942,
      "grad_norm": 1.0954217910766602,
      "learning_rate": 1.6285311421208734e-05,
      "epoch": 7.038391224862888,
      "step": 15400
    },
    {
      "loss": 0.4936,
      "grad_norm": 0.8065797686576843,
      "learning_rate": 1.6252897035704448e-05,
      "epoch": 7.084095063985375,
      "step": 15500
    },
    {
      "loss": 0.492,
      "grad_norm": 1.0804378986358643,
      "learning_rate": 1.622048265020016e-05,
      "epoch": 7.1297989031078615,
      "step": 15600
    },
    {
      "loss": 0.4976,
      "grad_norm": 0.7147574424743652,
      "learning_rate": 1.6188068264695872e-05,
      "epoch": 7.175502742230347,
      "step": 15700
    },
    {
      "loss": 0.4977,
      "grad_norm": 1.0667335987091064,
      "learning_rate": 1.6155653879191586e-05,
      "epoch": 7.221206581352834,
      "step": 15800
    },
    {
      "loss": 0.4931,
      "grad_norm": 2.097996234893799,
      "learning_rate": 1.61232394936873e-05,
      "epoch": 7.26691042047532,
      "step": 15900
    },
    {
      "loss": 0.4957,
      "grad_norm": 0.9854501485824585,
      "learning_rate": 1.609082510818301e-05,
      "epoch": 7.312614259597806,
      "step": 16000
    },
    {
      "loss": 0.497,
      "grad_norm": 2.0007991790771484,
      "learning_rate": 1.6058410722678725e-05,
      "epoch": 7.358318098720293,
      "step": 16100
    },
    {
      "loss": 0.4974,
      "grad_norm": 1.1971077919006348,
      "learning_rate": 1.602599633717444e-05,
      "epoch": 7.404021937842779,
      "step": 16200
    },
    {
      "loss": 0.4951,
      "grad_norm": 0.8520934581756592,
      "learning_rate": 1.5993581951670153e-05,
      "epoch": 7.449725776965265,
      "step": 16300
    },
    {
      "loss": 0.495,
      "grad_norm": 0.870824933052063,
      "learning_rate": 1.5961167566165863e-05,
      "epoch": 7.495429616087751,
      "step": 16400
    },
    {
      "loss": 0.5015,
      "grad_norm": 0.8327226042747498,
      "learning_rate": 1.5928753180661577e-05,
      "epoch": 7.541133455210238,
      "step": 16500
    },
    {
      "loss": 0.499,
      "grad_norm": 0.7863295674324036,
      "learning_rate": 1.589633879515729e-05,
      "epoch": 7.586837294332724,
      "step": 16600
    },
    {
      "loss": 0.4948,
      "grad_norm": 1.0783720016479492,
      "learning_rate": 1.5863924409653005e-05,
      "epoch": 7.63254113345521,
      "step": 16700
    },
    {
      "loss": 0.494,
      "grad_norm": 1.953031301498413,
      "learning_rate": 1.5831510024148716e-05,
      "epoch": 7.678244972577697,
      "step": 16800
    },
    {
      "loss": 0.498,
      "grad_norm": 0.8516457080841064,
      "learning_rate": 1.5799095638644433e-05,
      "epoch": 7.723948811700183,
      "step": 16900
    },
    {
      "loss": 0.4946,
      "grad_norm": 1.1297518014907837,
      "learning_rate": 1.5766681253140147e-05,
      "epoch": 7.769652650822669,
      "step": 17000
    },
    {
      "loss": 0.5007,
      "grad_norm": 1.0044463872909546,
      "learning_rate": 1.5734266867635858e-05,
      "epoch": 7.815356489945155,
      "step": 17100
    },
    {
      "loss": 0.4859,
      "grad_norm": 0.6724786758422852,
      "learning_rate": 1.5701852482131572e-05,
      "epoch": 7.861060329067642,
      "step": 17200
    },
    {
      "loss": 0.4909,
      "grad_norm": 0.9182630777359009,
      "learning_rate": 1.5669438096627286e-05,
      "epoch": 7.9067641681901275,
      "step": 17300
    },
    {
      "loss": 0.4946,
      "grad_norm": 0.7678365707397461,
      "learning_rate": 1.5637023711123e-05,
      "epoch": 7.952468007312614,
      "step": 17400
    },
    {
      "loss": 0.5034,
      "grad_norm": 0.854941725730896,
      "learning_rate": 1.560460932561871e-05,
      "epoch": 7.998171846435101,
      "step": 17500
    },
    {
      "eval_loss": 0.4945497512817383,
      "eval_roc_auc": 0.8247697688888889,
      "eval_accuracy": 0.7587,
      "eval_f1": 0.7586987964432191,
      "eval_precision": 0.7587051614554211,
      "eval_recall": 0.7587,
      "eval_runtime": 48.6772,
      "eval_samples_per_second": 616.305,
      "eval_steps_per_second": 4.828,
      "epoch": 8.0,
      "step": 17504
    },
    {
      "loss": 0.4875,
      "grad_norm": 0.6590226292610168,
      "learning_rate": 1.5572194940114424e-05,
      "epoch": 8.043875685557587,
      "step": 17600
    },
    {
      "loss": 0.4876,
      "grad_norm": 0.9482914805412292,
      "learning_rate": 1.553978055461014e-05,
      "epoch": 8.089579524680072,
      "step": 17700
    },
    {
      "loss": 0.4975,
      "grad_norm": 0.9833114147186279,
      "learning_rate": 1.5507366169105852e-05,
      "epoch": 8.135283363802559,
      "step": 17800
    },
    {
      "loss": 0.4905,
      "grad_norm": 1.086273193359375,
      "learning_rate": 1.5474951783601563e-05,
      "epoch": 8.180987202925046,
      "step": 17900
    },
    {
      "loss": 0.4962,
      "grad_norm": 1.9879231452941895,
      "learning_rate": 1.5442537398097277e-05,
      "epoch": 8.226691042047532,
      "step": 18000
    },
    {
      "loss": 0.4917,
      "grad_norm": 0.893794596195221,
      "learning_rate": 1.541012301259299e-05,
      "epoch": 8.272394881170019,
      "step": 18100
    },
    {
      "loss": 0.4928,
      "grad_norm": 0.8200089931488037,
      "learning_rate": 1.5377708627088705e-05,
      "epoch": 8.318098720292504,
      "step": 18200
    },
    {
      "loss": 0.4908,
      "grad_norm": 0.6523421406745911,
      "learning_rate": 1.5345294241584415e-05,
      "epoch": 8.36380255941499,
      "step": 18300
    },
    {
      "loss": 0.4877,
      "grad_norm": 1.3837357759475708,
      "learning_rate": 1.531287985608013e-05,
      "epoch": 8.409506398537477,
      "step": 18400
    },
    {
      "loss": 0.503,
      "grad_norm": 0.8757205009460449,
      "learning_rate": 1.5280465470575843e-05,
      "epoch": 8.455210237659964,
      "step": 18500
    },
    {
      "loss": 0.4856,
      "grad_norm": 0.8492480516433716,
      "learning_rate": 1.5248051085071556e-05,
      "epoch": 8.50091407678245,
      "step": 18600
    },
    {
      "loss": 0.4854,
      "grad_norm": 1.337253451347351,
      "learning_rate": 1.5215636699567268e-05,
      "epoch": 8.546617915904935,
      "step": 18700
    },
    {
      "loss": 0.4913,
      "grad_norm": 0.8802668452262878,
      "learning_rate": 1.5183222314062982e-05,
      "epoch": 8.592321755027422,
      "step": 18800
    },
    {
      "loss": 0.4889,
      "grad_norm": 0.7434343099594116,
      "learning_rate": 1.5150807928558694e-05,
      "epoch": 8.638025594149909,
      "step": 18900
    },
    {
      "loss": 0.4972,
      "grad_norm": 0.8842307925224304,
      "learning_rate": 1.5118393543054408e-05,
      "epoch": 8.683729433272395,
      "step": 19000
    },
    {
      "loss": 0.4936,
      "grad_norm": 0.7901228070259094,
      "learning_rate": 1.508597915755012e-05,
      "epoch": 8.729433272394882,
      "step": 19100
    },
    {
      "loss": 0.4818,
      "grad_norm": 1.8796870708465576,
      "learning_rate": 1.5053564772045835e-05,
      "epoch": 8.775137111517367,
      "step": 19200
    },
    {
      "loss": 0.4978,
      "grad_norm": 0.9252172708511353,
      "learning_rate": 1.5021150386541547e-05,
      "epoch": 8.820840950639854,
      "step": 19300
    },
    {
      "loss": 0.493,
      "grad_norm": 0.9440110325813293,
      "learning_rate": 1.498873600103726e-05,
      "epoch": 8.86654478976234,
      "step": 19400
    },
    {
      "loss": 0.4995,
      "grad_norm": 0.8932631611824036,
      "learning_rate": 1.4956321615532973e-05,
      "epoch": 8.912248628884827,
      "step": 19500
    },
    {
      "loss": 0.4986,
      "grad_norm": 0.7475103735923767,
      "learning_rate": 1.4923907230028687e-05,
      "epoch": 8.957952468007313,
      "step": 19600
    },
    {
      "eval_loss": 0.49193570017814636,
      "eval_roc_auc": 0.827026131111111,
      "eval_accuracy": 0.76,
      "eval_f1": 0.7599702480455456,
      "eval_precision": 0.7601289731009923,
      "eval_recall": 0.76,
      "eval_runtime": 48.7172,
      "eval_samples_per_second": 615.799,
      "eval_steps_per_second": 4.824,
      "epoch": 9.0,
      "step": 19692
    },
    {
      "loss": 0.4948,
      "grad_norm": 1.1415656805038452,
      "learning_rate": 1.4891492844524403e-05,
      "epoch": 9.003656307129798,
      "step": 19700
    },
    {
      "loss": 0.4941,
      "grad_norm": 1.0380027294158936,
      "learning_rate": 1.4859078459020115e-05,
      "epoch": 9.049360146252285,
      "step": 19800
    },
    {
      "loss": 0.4924,
      "grad_norm": 0.8070912957191467,
      "learning_rate": 1.4826664073515829e-05,
      "epoch": 9.095063985374772,
      "step": 19900
    },
    {
      "loss": 0.4836,
      "grad_norm": 1.255074143409729,
      "learning_rate": 1.4794249688011541e-05,
      "epoch": 9.140767824497258,
      "step": 20000
    },
    {
      "loss": 0.4961,
      "grad_norm": 0.892586886882782,
      "learning_rate": 1.4761835302507255e-05,
      "epoch": 9.186471663619743,
      "step": 20100
    },
    {
      "loss": 0.5002,
      "grad_norm": 0.8913043141365051,
      "learning_rate": 1.4729420917002967e-05,
      "epoch": 9.23217550274223,
      "step": 20200
    },
    {
      "loss": 0.4934,
      "grad_norm": 0.7222060561180115,
      "learning_rate": 1.4697006531498681e-05,
      "epoch": 9.277879341864717,
      "step": 20300
    },
    {
      "loss": 0.4884,
      "grad_norm": 0.6851872205734253,
      "learning_rate": 1.4664592145994394e-05,
      "epoch": 9.323583180987203,
      "step": 20400
    },
    {
      "loss": 0.4886,
      "grad_norm": 0.7533177733421326,
      "learning_rate": 1.4632177760490108e-05,
      "epoch": 9.36928702010969,
      "step": 20500
    },
    {
      "loss": 0.4922,
      "grad_norm": 1.1985818147659302,
      "learning_rate": 1.459976337498582e-05,
      "epoch": 9.414990859232175,
      "step": 20600
    },
    {
      "loss": 0.4886,
      "grad_norm": 1.612555980682373,
      "learning_rate": 1.4567348989481534e-05,
      "epoch": 9.460694698354661,
      "step": 20700
    },
    {
      "loss": 0.4855,
      "grad_norm": 0.9303874969482422,
      "learning_rate": 1.4534934603977246e-05,
      "epoch": 9.506398537477148,
      "step": 20800
    },
    {
      "loss": 0.4923,
      "grad_norm": 1.1420329809188843,
      "learning_rate": 1.450252021847296e-05,
      "epoch": 9.552102376599635,
      "step": 20900
    },
    {
      "loss": 0.4924,
      "grad_norm": 0.7628949880599976,
      "learning_rate": 1.4470105832968673e-05,
      "epoch": 9.597806215722121,
      "step": 21000
    },
    {
      "loss": 0.4873,
      "grad_norm": 0.7828512787818909,
      "learning_rate": 1.4437691447464387e-05,
      "epoch": 9.643510054844606,
      "step": 21100
    },
    {
      "loss": 0.4994,
      "grad_norm": 0.82466721534729,
      "learning_rate": 1.4405277061960099e-05,
      "epoch": 9.689213893967093,
      "step": 21200
    },
    {
      "loss": 0.4904,
      "grad_norm": 0.8128069639205933,
      "learning_rate": 1.4372862676455813e-05,
      "epoch": 9.73491773308958,
      "step": 21300
    },
    {
      "loss": 0.4901,
      "grad_norm": 0.824411928653717,
      "learning_rate": 1.4340448290951525e-05,
      "epoch": 9.780621572212066,
      "step": 21400
    },
    {
      "loss": 0.4873,
      "grad_norm": 1.2992863655090332,
      "learning_rate": 1.4308033905447239e-05,
      "epoch": 9.826325411334553,
      "step": 21500
    },
    {
      "loss": 0.4789,
      "grad_norm": 1.1520253419876099,
      "learning_rate": 1.4275619519942951e-05,
      "epoch": 9.872029250457038,
      "step": 21600
    },
    {
      "loss": 0.4856,
      "grad_norm": 0.8105871677398682,
      "learning_rate": 1.4243205134438665e-05,
      "epoch": 9.917733089579524,
      "step": 21700
    },
    {
      "loss": 0.4899,
      "grad_norm": 0.9538588523864746,
      "learning_rate": 1.4210790748934378e-05,
      "epoch": 9.963436928702011,
      "step": 21800
    },
    {
      "eval_loss": 0.48963308334350586,
      "eval_roc_auc": 0.8289011866666667,
      "eval_accuracy": 0.7621333333333333,
      "eval_f1": 0.7621247698250472,
      "eval_precision": 0.7621710859697131,
      "eval_recall": 0.7621333333333333,
      "eval_runtime": 48.6858,
      "eval_samples_per_second": 616.196,
      "eval_steps_per_second": 4.827,
      "epoch": 10.0,
      "step": 21880
    },
    {
      "loss": 0.4778,
      "grad_norm": 1.1889402866363525,
      "learning_rate": 1.4178376363430092e-05,
      "epoch": 10.009140767824498,
      "step": 21900
    },
    {
      "loss": 0.4889,
      "grad_norm": 1.1605687141418457,
      "learning_rate": 1.4145961977925804e-05,
      "epoch": 10.054844606946984,
      "step": 22000
    },
    {
      "loss": 0.4839,
      "grad_norm": 0.7675915956497192,
      "learning_rate": 1.4113547592421518e-05,
      "epoch": 10.10054844606947,
      "step": 22100
    },
    {
      "loss": 0.4892,
      "grad_norm": 0.8081179261207581,
      "learning_rate": 1.408113320691723e-05,
      "epoch": 10.146252285191956,
      "step": 22200
    },
    {
      "loss": 0.4902,
      "grad_norm": 0.9688366055488586,
      "learning_rate": 1.4048718821412944e-05,
      "epoch": 10.191956124314443,
      "step": 22300
    },
    {
      "loss": 0.497,
      "grad_norm": 0.9270855784416199,
      "learning_rate": 1.4016304435908656e-05,
      "epoch": 10.23765996343693,
      "step": 22400
    },
    {
      "loss": 0.4775,
      "grad_norm": 0.6973048448562622,
      "learning_rate": 1.398389005040437e-05,
      "epoch": 10.283363802559416,
      "step": 22500
    },
    {
      "loss": 0.4934,
      "grad_norm": 0.8800080418586731,
      "learning_rate": 1.3951475664900084e-05,
      "epoch": 10.3290676416819,
      "step": 22600
    },
    {
      "loss": 0.49,
      "grad_norm": 1.8318084478378296,
      "learning_rate": 1.3919061279395798e-05,
      "epoch": 10.374771480804387,
      "step": 22700
    },
    {
      "loss": 0.4908,
      "grad_norm": 1.1964813470840454,
      "learning_rate": 1.388664689389151e-05,
      "epoch": 10.420475319926874,
      "step": 22800
    },
    {
      "loss": 0.488,
      "grad_norm": 0.6969913244247437,
      "learning_rate": 1.3854232508387225e-05,
      "epoch": 10.46617915904936,
      "step": 22900
    },
    {
      "loss": 0.4781,
      "grad_norm": 0.7884758114814758,
      "learning_rate": 1.3821818122882937e-05,
      "epoch": 10.511882998171846,
      "step": 23000
    },
    {
      "loss": 0.4878,
      "grad_norm": 1.1194124221801758,
      "learning_rate": 1.378940373737865e-05,
      "epoch": 10.557586837294332,
      "step": 23100
    },
    {
      "loss": 0.4826,
      "grad_norm": 1.0191466808319092,
      "learning_rate": 1.3756989351874363e-05,
      "epoch": 10.603290676416819,
      "step": 23200
    },
    {
      "loss": 0.5017,
      "grad_norm": 1.358400583267212,
      "learning_rate": 1.3724574966370077e-05,
      "epoch": 10.648994515539306,
      "step": 23300
    },
    {
      "loss": 0.4823,
      "grad_norm": 1.0194920301437378,
      "learning_rate": 1.369216058086579e-05,
      "epoch": 10.694698354661792,
      "step": 23400
    },
    {
      "loss": 0.4916,
      "grad_norm": 0.8823726773262024,
      "learning_rate": 1.3659746195361503e-05,
      "epoch": 10.740402193784277,
      "step": 23500
    },
    {
      "loss": 0.4848,
      "grad_norm": 0.857855498790741,
      "learning_rate": 1.3627331809857216e-05,
      "epoch": 10.786106032906764,
      "step": 23600
    },
    {
      "loss": 0.4912,
      "grad_norm": 0.9724682569503784,
      "learning_rate": 1.359491742435293e-05,
      "epoch": 10.83180987202925,
      "step": 23700
    },
    {
      "loss": 0.4934,
      "grad_norm": 0.9311016201972961,
      "learning_rate": 1.3562503038848642e-05,
      "epoch": 10.877513711151737,
      "step": 23800
    },
    {
      "loss": 0.4881,
      "grad_norm": 1.7241450548171997,
      "learning_rate": 1.3530088653344356e-05,
      "epoch": 10.923217550274224,
      "step": 23900
    },
    {
      "loss": 0.4835,
      "grad_norm": 0.9507932066917419,
      "learning_rate": 1.3497674267840068e-05,
      "epoch": 10.968921389396709,
      "step": 24000
    },
    {
      "eval_loss": 0.48777058720588684,
      "eval_roc_auc": 0.8306469644444444,
      "eval_accuracy": 0.7633,
      "eval_f1": 0.7632972098001098,
      "eval_precision": 0.7633124154729589,
      "eval_recall": 0.7633,
      "eval_runtime": 48.7226,
      "eval_samples_per_second": 615.73,
      "eval_steps_per_second": 4.823,
      "epoch": 11.0,
      "step": 24068
    },
    {
      "loss": 0.4829,
      "grad_norm": 0.8662140965461731,
      "learning_rate": 1.3465259882335782e-05,
      "epoch": 11.014625228519195,
      "step": 24100
    },
    {
      "loss": 0.4906,
      "grad_norm": 1.3026047945022583,
      "learning_rate": 1.3432845496831494e-05,
      "epoch": 11.060329067641682,
      "step": 24200
    },
    {
      "loss": 0.4759,
      "grad_norm": 0.8878284692764282,
      "learning_rate": 1.3400431111327208e-05,
      "epoch": 11.106032906764169,
      "step": 24300
    },
    {
      "loss": 0.4911,
      "grad_norm": 1.2103971242904663,
      "learning_rate": 1.336801672582292e-05,
      "epoch": 11.151736745886655,
      "step": 24400
    },
    {
      "loss": 0.4864,
      "grad_norm": 0.843166708946228,
      "learning_rate": 1.3335602340318635e-05,
      "epoch": 11.19744058500914,
      "step": 24500
    },
    {
      "loss": 0.4895,
      "grad_norm": 0.9990550875663757,
      "learning_rate": 1.3303187954814347e-05,
      "epoch": 11.243144424131627,
      "step": 24600
    },
    {
      "loss": 0.4765,
      "grad_norm": 0.9640450477600098,
      "learning_rate": 1.3270773569310061e-05,
      "epoch": 11.288848263254113,
      "step": 24700
    },
    {
      "loss": 0.4736,
      "grad_norm": 1.103681206703186,
      "learning_rate": 1.3238359183805773e-05,
      "epoch": 11.3345521023766,
      "step": 24800
    },
    {
      "loss": 0.4895,
      "grad_norm": 1.254122257232666,
      "learning_rate": 1.3205944798301487e-05,
      "epoch": 11.380255941499087,
      "step": 24900
    },
    {
      "loss": 0.4862,
      "grad_norm": 0.8493323922157288,
      "learning_rate": 1.31735304127972e-05,
      "epoch": 11.425959780621572,
      "step": 25000
    },
    {
      "loss": 0.4893,
      "grad_norm": 0.833128809928894,
      "learning_rate": 1.3141116027292913e-05,
      "epoch": 11.471663619744058,
      "step": 25100
    },
    {
      "loss": 0.4827,
      "grad_norm": 1.0877776145935059,
      "learning_rate": 1.3108701641788626e-05,
      "epoch": 11.517367458866545,
      "step": 25200
    },
    {
      "loss": 0.4915,
      "grad_norm": 0.9156039953231812,
      "learning_rate": 1.307628725628434e-05,
      "epoch": 11.563071297989032,
      "step": 25300
    },
    {
      "loss": 0.4809,
      "grad_norm": 0.8794538974761963,
      "learning_rate": 1.3043872870780052e-05,
      "epoch": 11.608775137111518,
      "step": 25400
    },
    {
      "loss": 0.4808,
      "grad_norm": 0.7192158102989197,
      "learning_rate": 1.3011458485275768e-05,
      "epoch": 11.654478976234003,
      "step": 25500
    },
    {
      "loss": 0.492,
      "grad_norm": 0.7750130891799927,
      "learning_rate": 1.297904409977148e-05,
      "epoch": 11.70018281535649,
      "step": 25600
    },
    {
      "loss": 0.4819,
      "grad_norm": 1.4030240774154663,
      "learning_rate": 1.2946629714267194e-05,
      "epoch": 11.745886654478976,
      "step": 25700
    },
    {
      "loss": 0.4922,
      "grad_norm": 1.651945948600769,
      "learning_rate": 1.2914215328762906e-05,
      "epoch": 11.791590493601463,
      "step": 25800
    },
    {
      "loss": 0.4822,
      "grad_norm": 0.7486042380332947,
      "learning_rate": 1.288180094325862e-05,
      "epoch": 11.83729433272395,
      "step": 25900
    },
    {
      "loss": 0.4919,
      "grad_norm": 1.0415642261505127,
      "learning_rate": 1.2849386557754332e-05,
      "epoch": 11.882998171846435,
      "step": 26000
    },
    {
      "loss": 0.4901,
      "grad_norm": 0.8962777256965637,
      "learning_rate": 1.2816972172250046e-05,
      "epoch": 11.928702010968921,
      "step": 26100
    },
    {
      "loss": 0.4963,
      "grad_norm": 0.8373185992240906,
      "learning_rate": 1.2784557786745759e-05,
      "epoch": 11.974405850091408,
      "step": 26200
    },
    {
      "eval_loss": 0.4863745868206024,
      "eval_roc_auc": 0.8319447622222221,
      "eval_accuracy": 0.7636333333333334,
      "eval_f1": 0.7636154413860919,
      "eval_precision": 0.763713175134237,
      "eval_recall": 0.7636333333333334,
      "eval_runtime": 48.7469,
      "eval_samples_per_second": 615.424,
      "eval_steps_per_second": 4.821,
      "epoch": 12.0,
      "step": 26256
    },
    {
      "loss": 0.4926,
      "grad_norm": 1.079465389251709,
      "learning_rate": 1.2752143401241473e-05,
      "epoch": 12.020109689213895,
      "step": 26300
    },
    {
      "loss": 0.4932,
      "grad_norm": 0.8345968723297119,
      "learning_rate": 1.2719729015737185e-05,
      "epoch": 12.06581352833638,
      "step": 26400
    },
    {
      "loss": 0.4789,
      "grad_norm": 0.9003552198410034,
      "learning_rate": 1.2687314630232899e-05,
      "epoch": 12.111517367458866,
      "step": 26500
    },
    {
      "loss": 0.4832,
      "grad_norm": 0.643897294998169,
      "learning_rate": 1.2654900244728611e-05,
      "epoch": 12.157221206581353,
      "step": 26600
    },
    {
      "loss": 0.4823,
      "grad_norm": 1.4997893571853638,
      "learning_rate": 1.2622485859224325e-05,
      "epoch": 12.20292504570384,
      "step": 26700
    },
    {
      "loss": 0.4822,
      "grad_norm": 1.0803853273391724,
      "learning_rate": 1.2590071473720037e-05,
      "epoch": 12.248628884826326,
      "step": 26800
    },
    {
      "loss": 0.4865,
      "grad_norm": 0.9162460565567017,
      "learning_rate": 1.2557657088215751e-05,
      "epoch": 12.294332723948811,
      "step": 26900
    },
    {
      "loss": 0.4774,
      "grad_norm": 1.3327292203903198,
      "learning_rate": 1.2525242702711464e-05,
      "epoch": 12.340036563071298,
      "step": 27000
    },
    {
      "loss": 0.4736,
      "grad_norm": 0.9583084583282471,
      "learning_rate": 1.2492828317207178e-05,
      "epoch": 12.385740402193784,
      "step": 27100
    },
    {
      "loss": 0.4826,
      "grad_norm": 1.3048349618911743,
      "learning_rate": 1.246041393170289e-05,
      "epoch": 12.431444241316271,
      "step": 27200
    },
    {
      "loss": 0.4799,
      "grad_norm": 1.0665606260299683,
      "learning_rate": 1.2427999546198604e-05,
      "epoch": 12.477148080438758,
      "step": 27300
    },
    {
      "loss": 0.4794,
      "grad_norm": 0.8677024245262146,
      "learning_rate": 1.2395585160694316e-05,
      "epoch": 12.522851919561242,
      "step": 27400
    },
    {
      "loss": 0.489,
      "grad_norm": 1.1227360963821411,
      "learning_rate": 1.236317077519003e-05,
      "epoch": 12.568555758683729,
      "step": 27500
    },
    {
      "loss": 0.4881,
      "grad_norm": 1.0305039882659912,
      "learning_rate": 1.2330756389685742e-05,
      "epoch": 12.614259597806216,
      "step": 27600
    },
    {
      "loss": 0.4927,
      "grad_norm": 0.832489550113678,
      "learning_rate": 1.2298342004181456e-05,
      "epoch": 12.659963436928702,
      "step": 27700
    },
    {
      "loss": 0.4838,
      "grad_norm": 1.116350531578064,
      "learning_rate": 1.2265927618677169e-05,
      "epoch": 12.705667276051189,
      "step": 27800
    },
    {
      "loss": 0.4823,
      "grad_norm": 1.2783684730529785,
      "learning_rate": 1.2233513233172883e-05,
      "epoch": 12.751371115173674,
      "step": 27900
    },
    {
      "loss": 0.487,
      "grad_norm": 0.7656200528144836,
      "learning_rate": 1.2201098847668595e-05,
      "epoch": 12.79707495429616,
      "step": 28000
    },
    {
      "loss": 0.4882,
      "grad_norm": 1.208739995956421,
      "learning_rate": 1.2168684462164309e-05,
      "epoch": 12.842778793418647,
      "step": 28100
    },
    {
      "loss": 0.4874,
      "grad_norm": 1.428299069404602,
      "learning_rate": 1.2136270076660021e-05,
      "epoch": 12.888482632541134,
      "step": 28200
    },
    {
      "loss": 0.4891,
      "grad_norm": 0.7435972690582275,
      "learning_rate": 1.2103855691155737e-05,
      "epoch": 12.93418647166362,
      "step": 28300
    },
    {
      "loss": 0.4877,
      "grad_norm": 0.9651961922645569,
      "learning_rate": 1.2071441305651451e-05,
      "epoch": 12.979890310786105,
      "step": 28400
    },
    {
      "eval_loss": 0.4851132929325104,
      "eval_roc_auc": 0.8333030333333333,
      "eval_accuracy": 0.7652,
      "eval_f1": 0.7651864371686109,
      "eval_precision": 0.7652612859675098,
      "eval_recall": 0.7652,
      "eval_runtime": 48.7368,
      "eval_samples_per_second": 615.551,
      "eval_steps_per_second": 4.822,
      "epoch": 13.0,
      "step": 28444
    },
    {
      "loss": 0.4923,
      "grad_norm": 1.768652081489563,
      "learning_rate": 1.2039026920147163e-05,
      "epoch": 13.025594149908592,
      "step": 28500
    },
    {
      "loss": 0.4835,
      "grad_norm": 0.8226003646850586,
      "learning_rate": 1.2006612534642877e-05,
      "epoch": 13.071297989031079,
      "step": 28600
    },
    {
      "loss": 0.4922,
      "grad_norm": 1.255381464958191,
      "learning_rate": 1.197419814913859e-05,
      "epoch": 13.117001828153565,
      "step": 28700
    },
    {
      "loss": 0.4874,
      "grad_norm": 0.9713600277900696,
      "learning_rate": 1.1941783763634303e-05,
      "epoch": 13.16270566727605,
      "step": 28800
    },
    {
      "loss": 0.4778,
      "grad_norm": 0.8637880682945251,
      "learning_rate": 1.1909369378130016e-05,
      "epoch": 13.208409506398537,
      "step": 28900
    },
    {
      "loss": 0.4954,
      "grad_norm": 0.941394031047821,
      "learning_rate": 1.187695499262573e-05,
      "epoch": 13.254113345521024,
      "step": 29000
    },
    {
      "loss": 0.481,
      "grad_norm": 0.6596505641937256,
      "learning_rate": 1.1844540607121442e-05,
      "epoch": 13.29981718464351,
      "step": 29100
    },
    {
      "loss": 0.4874,
      "grad_norm": 0.7013460993766785,
      "learning_rate": 1.1812126221617154e-05,
      "epoch": 13.345521023765997,
      "step": 29200
    },
    {
      "loss": 0.4794,
      "grad_norm": 0.7938830852508545,
      "learning_rate": 1.1779711836112868e-05,
      "epoch": 13.391224862888482,
      "step": 29300
    },
    {
      "loss": 0.4866,
      "grad_norm": 0.9469627141952515,
      "learning_rate": 1.174729745060858e-05,
      "epoch": 13.436928702010968,
      "step": 29400
    },
    {
      "loss": 0.4807,
      "grad_norm": 0.9084783792495728,
      "learning_rate": 1.1714883065104294e-05,
      "epoch": 13.482632541133455,
      "step": 29500
    },
    {
      "loss": 0.487,
      "grad_norm": 2.010997772216797,
      "learning_rate": 1.1682468679600007e-05,
      "epoch": 13.528336380255942,
      "step": 29600
    },
    {
      "loss": 0.4859,
      "grad_norm": 0.9483566880226135,
      "learning_rate": 1.165005429409572e-05,
      "epoch": 13.574040219378428,
      "step": 29700
    },
    {
      "loss": 0.4813,
      "grad_norm": 1.571648359298706,
      "learning_rate": 1.1617639908591433e-05,
      "epoch": 13.619744058500913,
      "step": 29800
    },
    {
      "loss": 0.4856,
      "grad_norm": 0.8758825659751892,
      "learning_rate": 1.1585225523087147e-05,
      "epoch": 13.6654478976234,
      "step": 29900
    },
    {
      "loss": 0.4902,
      "grad_norm": 1.105699062347412,
      "learning_rate": 1.155281113758286e-05,
      "epoch": 13.711151736745887,
      "step": 30000
    },
    {
      "loss": 0.4756,
      "grad_norm": 0.8841583132743835,
      "learning_rate": 1.1520396752078573e-05,
      "epoch": 13.756855575868373,
      "step": 30100
    },
    {
      "loss": 0.4815,
      "grad_norm": 1.1861885786056519,
      "learning_rate": 1.1487982366574286e-05,
      "epoch": 13.80255941499086,
      "step": 30200
    },
    {
      "loss": 0.4772,
      "grad_norm": 0.7481352686882019,
      "learning_rate": 1.145556798107e-05,
      "epoch": 13.848263254113345,
      "step": 30300
    },
    {
      "loss": 0.4751,
      "grad_norm": 1.4380501508712769,
      "learning_rate": 1.1423153595565712e-05,
      "epoch": 13.893967093235831,
      "step": 30400
    },
    {
      "loss": 0.4843,
      "grad_norm": 1.1084845066070557,
      "learning_rate": 1.1390739210061426e-05,
      "epoch": 13.939670932358318,
      "step": 30500
    },
    {
      "loss": 0.4814,
      "grad_norm": 0.889133870601654,
      "learning_rate": 1.1358324824557138e-05,
      "epoch": 13.985374771480805,
      "step": 30600
    },
    {
      "eval_loss": 0.48391467332839966,
      "eval_roc_auc": 0.8338367333333334,
      "eval_accuracy": 0.7654,
      "eval_f1": 0.7653998498559039,
      "eval_precision": 0.7654006794257393,
      "eval_recall": 0.7654,
      "eval_runtime": 48.7251,
      "eval_samples_per_second": 615.699,
      "eval_steps_per_second": 4.823,
      "epoch": 14.0,
      "step": 30632
    },
    {
      "loss": 0.4809,
      "grad_norm": 0.8127636313438416,
      "learning_rate": 1.1325910439052852e-05,
      "epoch": 14.031078610603291,
      "step": 30700
    },
    {
      "loss": 0.4847,
      "grad_norm": 0.6700981259346008,
      "learning_rate": 1.1293496053548564e-05,
      "epoch": 14.076782449725776,
      "step": 30800
    },
    {
      "loss": 0.4864,
      "grad_norm": 0.7807637453079224,
      "learning_rate": 1.1261081668044278e-05,
      "epoch": 14.122486288848263,
      "step": 30900
    },
    {
      "loss": 0.4854,
      "grad_norm": 0.8869264125823975,
      "learning_rate": 1.122866728253999e-05,
      "epoch": 14.16819012797075,
      "step": 31000
    },
    {
      "loss": 0.4758,
      "grad_norm": 0.7881008982658386,
      "learning_rate": 1.1196252897035705e-05,
      "epoch": 14.213893967093236,
      "step": 31100
    },
    {
      "loss": 0.488,
      "grad_norm": 1.042116403579712,
      "learning_rate": 1.116383851153142e-05,
      "epoch": 14.259597806215723,
      "step": 31200
    },
    {
      "loss": 0.4851,
      "grad_norm": 1.2497347593307495,
      "learning_rate": 1.1131424126027132e-05,
      "epoch": 14.305301645338208,
      "step": 31300
    },
    {
      "loss": 0.4813,
      "grad_norm": 0.9712427258491516,
      "learning_rate": 1.1099009740522846e-05,
      "epoch": 14.351005484460694,
      "step": 31400
    },
    {
      "loss": 0.4827,
      "grad_norm": 1.134432315826416,
      "learning_rate": 1.1066595355018559e-05,
      "epoch": 14.396709323583181,
      "step": 31500
    },
    {
      "loss": 0.4788,
      "grad_norm": 1.2672444581985474,
      "learning_rate": 1.1034180969514273e-05,
      "epoch": 14.442413162705668,
      "step": 31600
    },
    {
      "loss": 0.4829,
      "grad_norm": 0.9121729731559753,
      "learning_rate": 1.1001766584009985e-05,
      "epoch": 14.488117001828154,
      "step": 31700
    },
    {
      "loss": 0.4787,
      "grad_norm": 1.3538564443588257,
      "learning_rate": 1.0969352198505699e-05,
      "epoch": 14.53382084095064,
      "step": 31800
    },
    {
      "loss": 0.4816,
      "grad_norm": 0.9820117354393005,
      "learning_rate": 1.0936937813001411e-05,
      "epoch": 14.579524680073126,
      "step": 31900
    },
    {
      "loss": 0.4845,
      "grad_norm": 0.8386770486831665,
      "learning_rate": 1.0904523427497125e-05,
      "epoch": 14.625228519195613,
      "step": 32000
    },
    {
      "loss": 0.4771,
      "grad_norm": 1.266534447669983,
      "learning_rate": 1.0872109041992838e-05,
      "epoch": 14.6709323583181,
      "step": 32100
    },
    {
      "loss": 0.4786,
      "grad_norm": 0.9300833940505981,
      "learning_rate": 1.0839694656488552e-05,
      "epoch": 14.716636197440586,
      "step": 32200
    },
    {
      "loss": 0.4965,
      "grad_norm": 0.8193660378456116,
      "learning_rate": 1.0807280270984264e-05,
      "epoch": 14.76234003656307,
      "step": 32300
    },
    {
      "loss": 0.4915,
      "grad_norm": 1.2734647989273071,
      "learning_rate": 1.0774865885479978e-05,
      "epoch": 14.808043875685557,
      "step": 32400
    },
    {
      "loss": 0.4717,
      "grad_norm": 0.6901965737342834,
      "learning_rate": 1.074245149997569e-05,
      "epoch": 14.853747714808044,
      "step": 32500
    },
    {
      "loss": 0.4806,
      "grad_norm": 0.9231914281845093,
      "learning_rate": 1.0710037114471404e-05,
      "epoch": 14.89945155393053,
      "step": 32600
    },
    {
      "loss": 0.4705,
      "grad_norm": 1.619280457496643,
      "learning_rate": 1.0677622728967116e-05,
      "epoch": 14.945155393053016,
      "step": 32700
    },
    {
      "loss": 0.4882,
      "grad_norm": 0.9723416566848755,
      "learning_rate": 1.064520834346283e-05,
      "epoch": 14.990859232175502,
      "step": 32800
    },
    {
      "eval_loss": 0.4830140173435211,
      "eval_roc_auc": 0.8348924688888889,
      "eval_accuracy": 0.7657333333333334,
      "eval_f1": 0.7657231282327991,
      "eval_precision": 0.7657796427782911,
      "eval_recall": 0.7657333333333334,
      "eval_runtime": 48.6584,
      "eval_samples_per_second": 616.543,
      "eval_steps_per_second": 4.83,
      "epoch": 15.0,
      "step": 32820
    },
    {
      "loss": 0.4853,
      "grad_norm": 1.087329626083374,
      "learning_rate": 1.0612793957958543e-05,
      "epoch": 15.036563071297989,
      "step": 32900
    },
    {
      "loss": 0.4808,
      "grad_norm": 0.7323034405708313,
      "learning_rate": 1.0580379572454257e-05,
      "epoch": 15.082266910420476,
      "step": 33000
    },
    {
      "loss": 0.4746,
      "grad_norm": 1.1638985872268677,
      "learning_rate": 1.0547965186949969e-05,
      "epoch": 15.127970749542962,
      "step": 33100
    },
    {
      "loss": 0.4791,
      "grad_norm": 1.0538567304611206,
      "learning_rate": 1.0515550801445683e-05,
      "epoch": 15.173674588665447,
      "step": 33200
    },
    {
      "loss": 0.4701,
      "grad_norm": 0.9547519683837891,
      "learning_rate": 1.0483136415941395e-05,
      "epoch": 15.219378427787934,
      "step": 33300
    },
    {
      "loss": 0.4882,
      "grad_norm": 0.7379986047744751,
      "learning_rate": 1.0450722030437107e-05,
      "epoch": 15.26508226691042,
      "step": 33400
    },
    {
      "loss": 0.4856,
      "grad_norm": 0.8090484142303467,
      "learning_rate": 1.0418307644932821e-05,
      "epoch": 15.310786106032907,
      "step": 33500
    },
    {
      "loss": 0.483,
      "grad_norm": 1.1931545734405518,
      "learning_rate": 1.0385893259428534e-05,
      "epoch": 15.356489945155394,
      "step": 33600
    },
    {
      "loss": 0.4689,
      "grad_norm": 1.209215521812439,
      "learning_rate": 1.0353478873924248e-05,
      "epoch": 15.402193784277879,
      "step": 33700
    },
    {
      "loss": 0.4921,
      "grad_norm": 0.9429575800895691,
      "learning_rate": 1.032106448841996e-05,
      "epoch": 15.447897623400365,
      "step": 33800
    },
    {
      "loss": 0.4761,
      "grad_norm": 1.3716928958892822,
      "learning_rate": 1.0288650102915674e-05,
      "epoch": 15.493601462522852,
      "step": 33900
    },
    {
      "loss": 0.4837,
      "grad_norm": 1.0473178625106812,
      "learning_rate": 1.0256235717411386e-05,
      "epoch": 15.539305301645339,
      "step": 34000
    },
    {
      "loss": 0.4906,
      "grad_norm": 1.1264094114303589,
      "learning_rate": 1.0223821331907102e-05,
      "epoch": 15.585009140767825,
      "step": 34100
    },
    {
      "loss": 0.4765,
      "grad_norm": 1.1596100330352783,
      "learning_rate": 1.0191406946402816e-05,
      "epoch": 15.63071297989031,
      "step": 34200
    },
    {
      "loss": 0.4787,
      "grad_norm": 1.1266437768936157,
      "learning_rate": 1.0158992560898528e-05,
      "epoch": 15.676416819012797,
      "step": 34300
    },
    {
      "loss": 0.4842,
      "grad_norm": 0.6201194524765015,
      "learning_rate": 1.0126578175394242e-05,
      "epoch": 15.722120658135283,
      "step": 34400
    },
    {
      "loss": 0.4888,
      "grad_norm": 0.900368332862854,
      "learning_rate": 1.0094163789889954e-05,
      "epoch": 15.76782449725777,
      "step": 34500
    },
    {
      "loss": 0.4888,
      "grad_norm": 0.7589792013168335,
      "learning_rate": 1.0061749404385668e-05,
      "epoch": 15.813528336380255,
      "step": 34600
    },
    {
      "loss": 0.4836,
      "grad_norm": 1.1694133281707764,
      "learning_rate": 1.002933501888138e-05,
      "epoch": 15.859232175502742,
      "step": 34700
    },
    {
      "loss": 0.4803,
      "grad_norm": 0.7540772557258606,
      "learning_rate": 9.996920633377095e-06,
      "epoch": 15.904936014625228,
      "step": 34800
    },
    {
      "loss": 0.4855,
      "grad_norm": 0.844218909740448,
      "learning_rate": 9.964506247872807e-06,
      "epoch": 15.950639853747715,
      "step": 34900
    },
    {
      "loss": 0.474,
      "grad_norm": 0.7481986284255981,
      "learning_rate": 9.93209186236852e-06,
      "epoch": 15.996343692870202,
      "step": 35000
    },
    {
      "eval_loss": 0.4822116196155548,
      "eval_roc_auc": 0.8353289666666667,
      "eval_accuracy": 0.7664333333333333,
      "eval_f1": 0.7664292782860813,
      "eval_precision": 0.7664518369331204,
      "eval_recall": 0.7664333333333333,
      "eval_runtime": 48.7414,
      "eval_samples_per_second": 615.494,
      "eval_steps_per_second": 4.821,
      "epoch": 16.0,
      "step": 35008
    },
    {
      "loss": 0.4868,
      "grad_norm": 1.0600080490112305,
      "learning_rate": 9.899677476864233e-06,
      "epoch": 16.042047531992687,
      "step": 35100
    },
    {
      "loss": 0.4804,
      "grad_norm": 1.403706669807434,
      "learning_rate": 9.867263091359947e-06,
      "epoch": 16.087751371115175,
      "step": 35200
    },
    {
      "loss": 0.4832,
      "grad_norm": 0.7739900350570679,
      "learning_rate": 9.83484870585566e-06,
      "epoch": 16.13345521023766,
      "step": 35300
    },
    {
      "loss": 0.4808,
      "grad_norm": 0.8154575824737549,
      "learning_rate": 9.802434320351373e-06,
      "epoch": 16.179159049360145,
      "step": 35400
    },
    {
      "loss": 0.4763,
      "grad_norm": 0.6895953416824341,
      "learning_rate": 9.770019934847086e-06,
      "epoch": 16.224862888482633,
      "step": 35500
    },
    {
      "loss": 0.4836,
      "grad_norm": 0.9058078527450562,
      "learning_rate": 9.7376055493428e-06,
      "epoch": 16.270566727605118,
      "step": 35600
    },
    {
      "loss": 0.4802,
      "grad_norm": 0.7229408025741577,
      "learning_rate": 9.705191163838512e-06,
      "epoch": 16.316270566727606,
      "step": 35700
    },
    {
      "loss": 0.4778,
      "grad_norm": 0.7784397006034851,
      "learning_rate": 9.672776778334226e-06,
      "epoch": 16.36197440585009,
      "step": 35800
    },
    {
      "loss": 0.4705,
      "grad_norm": 1.4506254196166992,
      "learning_rate": 9.640362392829938e-06,
      "epoch": 16.407678244972576,
      "step": 35900
    },
    {
      "loss": 0.4843,
      "grad_norm": 1.286708116531372,
      "learning_rate": 9.607948007325652e-06,
      "epoch": 16.453382084095065,
      "step": 36000
    },
    {
      "loss": 0.4701,
      "grad_norm": 1.5341112613677979,
      "learning_rate": 9.575533621821364e-06,
      "epoch": 16.49908592321755,
      "step": 36100
    },
    {
      "loss": 0.4823,
      "grad_norm": 0.7793065309524536,
      "learning_rate": 9.543119236317078e-06,
      "epoch": 16.544789762340038,
      "step": 36200
    },
    {
      "loss": 0.485,
      "grad_norm": 1.1703383922576904,
      "learning_rate": 9.510704850812792e-06,
      "epoch": 16.590493601462523,
      "step": 36300
    },
    {
      "loss": 0.4723,
      "grad_norm": 1.0245305299758911,
      "learning_rate": 9.478290465308505e-06,
      "epoch": 16.636197440585008,
      "step": 36400
    },
    {
      "loss": 0.4814,
      "grad_norm": 0.8991852402687073,
      "learning_rate": 9.445876079804219e-06,
      "epoch": 16.681901279707496,
      "step": 36500
    },
    {
      "loss": 0.4801,
      "grad_norm": 0.8878356218338013,
      "learning_rate": 9.413461694299931e-06,
      "epoch": 16.72760511882998,
      "step": 36600
    },
    {
      "loss": 0.4856,
      "grad_norm": 1.3536524772644043,
      "learning_rate": 9.381047308795645e-06,
      "epoch": 16.77330895795247,
      "step": 36700
    },
    {
      "loss": 0.4859,
      "grad_norm": 1.1868183612823486,
      "learning_rate": 9.348632923291357e-06,
      "epoch": 16.819012797074954,
      "step": 36800
    },
    {
      "loss": 0.4816,
      "grad_norm": 0.7099548578262329,
      "learning_rate": 9.316218537787071e-06,
      "epoch": 16.86471663619744,
      "step": 36900
    },
    {
      "loss": 0.485,
      "grad_norm": 0.7593239545822144,
      "learning_rate": 9.283804152282783e-06,
      "epoch": 16.910420475319928,
      "step": 37000
    },
    {
      "loss": 0.4927,
      "grad_norm": 0.7581604719161987,
      "learning_rate": 9.251389766778497e-06,
      "epoch": 16.956124314442413,
      "step": 37100
    },
    {
      "eval_loss": 0.48149779438972473,
      "eval_roc_auc": 0.8361717555555556,
      "eval_accuracy": 0.7676333333333333,
      "eval_f1": 0.7676324345872276,
      "eval_precision": 0.7676374739824308,
      "eval_recall": 0.7676333333333333,
      "eval_runtime": 48.7505,
      "eval_samples_per_second": 615.378,
      "eval_steps_per_second": 4.82,
      "epoch": 17.0,
      "step": 37196
    },
    {
      "loss": 0.4825,
      "grad_norm": 0.8408358097076416,
      "learning_rate": 9.21897538127421e-06,
      "epoch": 17.0018281535649,
      "step": 37200
    },
    {
      "loss": 0.4864,
      "grad_norm": 0.9281221628189087,
      "learning_rate": 9.186560995769924e-06,
      "epoch": 17.047531992687386,
      "step": 37300
    },
    {
      "loss": 0.4757,
      "grad_norm": 0.9686380624771118,
      "learning_rate": 9.154146610265636e-06,
      "epoch": 17.09323583180987,
      "step": 37400
    },
    {
      "loss": 0.4872,
      "grad_norm": 1.0430855751037598,
      "learning_rate": 9.12173222476135e-06,
      "epoch": 17.13893967093236,
      "step": 37500
    },
    {
      "loss": 0.4852,
      "grad_norm": 0.7810894846916199,
      "learning_rate": 9.089317839257064e-06,
      "epoch": 17.184643510054844,
      "step": 37600
    },
    {
      "loss": 0.4778,
      "grad_norm": 0.9439040422439575,
      "learning_rate": 9.056903453752776e-06,
      "epoch": 17.230347349177332,
      "step": 37700
    },
    {
      "loss": 0.4673,
      "grad_norm": 1.1728849411010742,
      "learning_rate": 9.02448906824849e-06,
      "epoch": 17.276051188299817,
      "step": 37800
    },
    {
      "loss": 0.4849,
      "grad_norm": 0.8938090801239014,
      "learning_rate": 8.992074682744202e-06,
      "epoch": 17.321755027422302,
      "step": 37900
    },
    {
      "loss": 0.4715,
      "grad_norm": 1.0363348722457886,
      "learning_rate": 8.959660297239916e-06,
      "epoch": 17.36745886654479,
      "step": 38000
    },
    {
      "loss": 0.4819,
      "grad_norm": 0.7874264717102051,
      "learning_rate": 8.927245911735629e-06,
      "epoch": 17.413162705667276,
      "step": 38100
    },
    {
      "loss": 0.4817,
      "grad_norm": 1.5722452402114868,
      "learning_rate": 8.894831526231343e-06,
      "epoch": 17.458866544789764,
      "step": 38200
    },
    {
      "loss": 0.4806,
      "grad_norm": 0.8917723894119263,
      "learning_rate": 8.862417140727055e-06,
      "epoch": 17.50457038391225,
      "step": 38300
    },
    {
      "loss": 0.4797,
      "grad_norm": 0.5443920493125916,
      "learning_rate": 8.830002755222769e-06,
      "epoch": 17.550274223034734,
      "step": 38400
    },
    {
      "loss": 0.4895,
      "grad_norm": 0.760079026222229,
      "learning_rate": 8.797588369718481e-06,
      "epoch": 17.595978062157222,
      "step": 38500
    },
    {
      "loss": 0.4849,
      "grad_norm": 0.7238060832023621,
      "learning_rate": 8.765173984214195e-06,
      "epoch": 17.641681901279707,
      "step": 38600
    },
    {
      "loss": 0.4695,
      "grad_norm": 0.9970922470092773,
      "learning_rate": 8.732759598709907e-06,
      "epoch": 17.687385740402195,
      "step": 38700
    },
    {
      "loss": 0.4736,
      "grad_norm": 2.1153676509857178,
      "learning_rate": 8.700345213205621e-06,
      "epoch": 17.73308957952468,
      "step": 38800
    },
    {
      "loss": 0.4855,
      "grad_norm": 0.779649555683136,
      "learning_rate": 8.667930827701334e-06,
      "epoch": 17.778793418647165,
      "step": 38900
    },
    {
      "loss": 0.485,
      "grad_norm": 0.8693227171897888,
      "learning_rate": 8.635516442197048e-06,
      "epoch": 17.824497257769654,
      "step": 39000
    },
    {
      "loss": 0.4804,
      "grad_norm": 1.0514769554138184,
      "learning_rate": 8.603102056692762e-06,
      "epoch": 17.87020109689214,
      "step": 39100
    },
    {
      "loss": 0.472,
      "grad_norm": 0.7972711324691772,
      "learning_rate": 8.570687671188474e-06,
      "epoch": 17.915904936014627,
      "step": 39200
    },
    {
      "loss": 0.4815,
      "grad_norm": 0.7704988121986389,
      "learning_rate": 8.538273285684188e-06,
      "epoch": 17.961608775137112,
      "step": 39300
    },
    {
      "eval_loss": 0.4809585213661194,
      "eval_roc_auc": 0.8364366977777777,
      "eval_accuracy": 0.7672,
      "eval_f1": 0.7671961499416619,
      "eval_precision": 0.7672176767462253,
      "eval_recall": 0.7672,
      "eval_runtime": 48.6638,
      "eval_samples_per_second": 616.475,
      "eval_steps_per_second": 4.829,
      "epoch": 18.0,
      "step": 39384
    },
    {
      "loss": 0.4822,
      "grad_norm": 1.4859081506729126,
      "learning_rate": 8.5058589001799e-06,
      "epoch": 18.007312614259597,
      "step": 39400
    },
    {
      "loss": 0.4714,
      "grad_norm": 1.1557368040084839,
      "learning_rate": 8.473444514675614e-06,
      "epoch": 18.053016453382085,
      "step": 39500
    },
    {
      "loss": 0.4837,
      "grad_norm": 0.7700473070144653,
      "learning_rate": 8.441030129171326e-06,
      "epoch": 18.09872029250457,
      "step": 39600
    },
    {
      "loss": 0.4843,
      "grad_norm": 0.7415896058082581,
      "learning_rate": 8.40861574366704e-06,
      "epoch": 18.144424131627055,
      "step": 39700
    },
    {
      "loss": 0.483,
      "grad_norm": 1.014485239982605,
      "learning_rate": 8.376201358162753e-06,
      "epoch": 18.190127970749543,
      "step": 39800
    },
    {
      "loss": 0.4852,
      "grad_norm": 0.7703522443771362,
      "learning_rate": 8.343786972658467e-06,
      "epoch": 18.23583180987203,
      "step": 39900
    },
    {
      "loss": 0.4736,
      "grad_norm": 1.1105940341949463,
      "learning_rate": 8.311372587154179e-06,
      "epoch": 18.281535648994517,
      "step": 40000
    },
    {
      "loss": 0.4861,
      "grad_norm": 1.166943073272705,
      "learning_rate": 8.278958201649893e-06,
      "epoch": 18.327239488117,
      "step": 40100
    },
    {
      "loss": 0.4781,
      "grad_norm": 0.878653883934021,
      "learning_rate": 8.246543816145605e-06,
      "epoch": 18.372943327239486,
      "step": 40200
    },
    {
      "loss": 0.4768,
      "grad_norm": 0.8580049872398376,
      "learning_rate": 8.21412943064132e-06,
      "epoch": 18.418647166361975,
      "step": 40300
    },
    {
      "loss": 0.4969,
      "grad_norm": 0.967138946056366,
      "learning_rate": 8.181715045137032e-06,
      "epoch": 18.46435100548446,
      "step": 40400
    },
    {
      "loss": 0.4727,
      "grad_norm": 0.9194285273551941,
      "learning_rate": 8.149300659632745e-06,
      "epoch": 18.510054844606948,
      "step": 40500
    },
    {
      "loss": 0.4773,
      "grad_norm": 1.6191579103469849,
      "learning_rate": 8.11688627412846e-06,
      "epoch": 18.555758683729433,
      "step": 40600
    },
    {
      "loss": 0.4799,
      "grad_norm": 0.7621014714241028,
      "learning_rate": 8.084471888624172e-06,
      "epoch": 18.601462522851918,
      "step": 40700
    },
    {
      "loss": 0.4759,
      "grad_norm": 0.7413060069084167,
      "learning_rate": 8.052057503119886e-06,
      "epoch": 18.647166361974406,
      "step": 40800
    },
    {
      "loss": 0.4828,
      "grad_norm": 0.6441780924797058,
      "learning_rate": 8.019643117615598e-06,
      "epoch": 18.69287020109689,
      "step": 40900
    },
    {
      "loss": 0.4796,
      "grad_norm": 0.7404165863990784,
      "learning_rate": 7.987228732111312e-06,
      "epoch": 18.73857404021938,
      "step": 41000
    },
    {
      "loss": 0.4662,
      "grad_norm": 0.7317129373550415,
      "learning_rate": 7.954814346607024e-06,
      "epoch": 18.784277879341865,
      "step": 41100
    },
    {
      "loss": 0.4793,
      "grad_norm": 0.9965487122535706,
      "learning_rate": 7.922399961102738e-06,
      "epoch": 18.82998171846435,
      "step": 41200
    },
    {
      "loss": 0.4847,
      "grad_norm": 0.6752312183380127,
      "learning_rate": 7.88998557559845e-06,
      "epoch": 18.875685557586838,
      "step": 41300
    },
    {
      "loss": 0.4792,
      "grad_norm": 0.7911190986633301,
      "learning_rate": 7.857571190094164e-06,
      "epoch": 18.921389396709323,
      "step": 41400
    },
    {
      "loss": 0.4818,
      "grad_norm": 0.874042272567749,
      "learning_rate": 7.825156804589877e-06,
      "epoch": 18.96709323583181,
      "step": 41500
    },
    {
      "eval_loss": 0.4804023504257202,
      "eval_roc_auc": 0.8369792577777778,
      "eval_accuracy": 0.7681666666666667,
      "eval_f1": 0.7681666458016647,
      "eval_precision": 0.7681667632067013,
      "eval_recall": 0.7681666666666667,
      "eval_runtime": 48.7923,
      "eval_samples_per_second": 614.851,
      "eval_steps_per_second": 4.816,
      "epoch": 19.0,
      "step": 41572
    },
    {
      "loss": 0.4776,
      "grad_norm": 1.3031686544418335,
      "learning_rate": 7.79274241908559e-06,
      "epoch": 19.012797074954296,
      "step": 41600
    },
    {
      "loss": 0.4627,
      "grad_norm": 1.3791805505752563,
      "learning_rate": 7.760328033581303e-06,
      "epoch": 19.05850091407678,
      "step": 41700
    },
    {
      "loss": 0.4788,
      "grad_norm": 0.9012678861618042,
      "learning_rate": 7.727913648077017e-06,
      "epoch": 19.10420475319927,
      "step": 41800
    },
    {
      "loss": 0.468,
      "grad_norm": 0.904858410358429,
      "learning_rate": 7.695499262572731e-06,
      "epoch": 19.149908592321754,
      "step": 41900
    },
    {
      "loss": 0.4873,
      "grad_norm": 0.8314229846000671,
      "learning_rate": 7.663084877068443e-06,
      "epoch": 19.195612431444243,
      "step": 42000
    },
    {
      "loss": 0.4785,
      "grad_norm": 1.0851396322250366,
      "learning_rate": 7.630670491564157e-06,
      "epoch": 19.241316270566728,
      "step": 42100
    },
    {
      "loss": 0.4751,
      "grad_norm": 0.9588165879249573,
      "learning_rate": 7.59825610605987e-06,
      "epoch": 19.287020109689212,
      "step": 42200
    },
    {
      "loss": 0.4821,
      "grad_norm": 0.6794592142105103,
      "learning_rate": 7.5658417205555835e-06,
      "epoch": 19.3327239488117,
      "step": 42300
    },
    {
      "loss": 0.478,
      "grad_norm": 1.1539812088012695,
      "learning_rate": 7.533427335051297e-06,
      "epoch": 19.378427787934186,
      "step": 42400
    },
    {
      "loss": 0.4707,
      "grad_norm": 0.897800862789154,
      "learning_rate": 7.50101294954701e-06,
      "epoch": 19.424131627056674,
      "step": 42500
    },
    {
      "loss": 0.4812,
      "grad_norm": 1.0446444749832153,
      "learning_rate": 7.468598564042723e-06,
      "epoch": 19.46983546617916,
      "step": 42600
    },
    {
      "loss": 0.4787,
      "grad_norm": 0.7424044013023376,
      "learning_rate": 7.436184178538436e-06,
      "epoch": 19.515539305301644,
      "step": 42700
    },
    {
      "loss": 0.4784,
      "grad_norm": 0.943028450012207,
      "learning_rate": 7.403769793034149e-06,
      "epoch": 19.561243144424132,
      "step": 42800
    },
    {
      "loss": 0.4841,
      "grad_norm": 0.896821141242981,
      "learning_rate": 7.371355407529862e-06,
      "epoch": 19.606946983546617,
      "step": 42900
    },
    {
      "loss": 0.4845,
      "grad_norm": 0.65236496925354,
      "learning_rate": 7.338941022025575e-06,
      "epoch": 19.652650822669106,
      "step": 43000
    },
    {
      "loss": 0.4845,
      "grad_norm": 1.3672808408737183,
      "learning_rate": 7.3065266365212885e-06,
      "epoch": 19.69835466179159,
      "step": 43100
    },
    {
      "loss": 0.4806,
      "grad_norm": 1.4298672676086426,
      "learning_rate": 7.274112251017002e-06,
      "epoch": 19.744058500914075,
      "step": 43200
    },
    {
      "loss": 0.4811,
      "grad_norm": 0.5907933712005615,
      "learning_rate": 7.241697865512715e-06,
      "epoch": 19.789762340036564,
      "step": 43300
    },
    {
      "loss": 0.478,
      "grad_norm": 0.735781192779541,
      "learning_rate": 7.209283480008429e-06,
      "epoch": 19.83546617915905,
      "step": 43400
    },
    {
      "loss": 0.479,
      "grad_norm": 0.9812037348747253,
      "learning_rate": 7.176869094504142e-06,
      "epoch": 19.881170018281537,
      "step": 43500
    },
    {
      "loss": 0.482,
      "grad_norm": 0.712503969669342,
      "learning_rate": 7.144454708999855e-06,
      "epoch": 19.926873857404022,
      "step": 43600
    },
    {
      "loss": 0.4826,
      "grad_norm": 0.8690168261528015,
      "learning_rate": 7.112040323495568e-06,
      "epoch": 19.972577696526507,
      "step": 43700
    },
    {
      "eval_loss": 0.48002007603645325,
      "eval_roc_auc": 0.837439668888889,
      "eval_accuracy": 0.7681333333333333,
      "eval_f1": 0.7681281383730912,
      "eval_precision": 0.7681573650004795,
      "eval_recall": 0.7681333333333333,
      "eval_runtime": 48.694,
      "eval_samples_per_second": 616.092,
      "eval_steps_per_second": 4.826,
      "epoch": 20.0,
      "step": 43760
    },
    {
      "loss": 0.4894,
      "grad_norm": 0.6461741924285889,
      "learning_rate": 7.079625937991281e-06,
      "epoch": 20.018281535648995,
      "step": 43800
    },
    {
      "loss": 0.4834,
      "grad_norm": 1.2567391395568848,
      "learning_rate": 7.047211552486994e-06,
      "epoch": 20.06398537477148,
      "step": 43900
    },
    {
      "loss": 0.4784,
      "grad_norm": 0.9908385276794434,
      "learning_rate": 7.0147971669827076e-06,
      "epoch": 20.10968921389397,
      "step": 44000
    },
    {
      "loss": 0.4913,
      "grad_norm": 0.8655299544334412,
      "learning_rate": 6.982382781478421e-06,
      "epoch": 20.155393053016454,
      "step": 44100
    },
    {
      "loss": 0.4843,
      "grad_norm": 0.6818928718566895,
      "learning_rate": 6.949968395974134e-06,
      "epoch": 20.20109689213894,
      "step": 44200
    },
    {
      "loss": 0.4791,
      "grad_norm": 1.0323407649993896,
      "learning_rate": 6.917554010469847e-06,
      "epoch": 20.246800731261427,
      "step": 44300
    },
    {
      "loss": 0.4656,
      "grad_norm": 1.2540526390075684,
      "learning_rate": 6.88513962496556e-06,
      "epoch": 20.29250457038391,
      "step": 44400
    },
    {
      "loss": 0.4717,
      "grad_norm": 0.996332049369812,
      "learning_rate": 6.852725239461273e-06,
      "epoch": 20.3382084095064,
      "step": 44500
    },
    {
      "loss": 0.4759,
      "grad_norm": 0.6509119868278503,
      "learning_rate": 6.820310853956986e-06,
      "epoch": 20.383912248628885,
      "step": 44600
    },
    {
      "loss": 0.4819,
      "grad_norm": 1.1039016246795654,
      "learning_rate": 6.7878964684526995e-06,
      "epoch": 20.42961608775137,
      "step": 44700
    },
    {
      "loss": 0.4735,
      "grad_norm": 0.7386903166770935,
      "learning_rate": 6.7554820829484134e-06,
      "epoch": 20.47531992687386,
      "step": 44800
    },
    {
      "loss": 0.4748,
      "grad_norm": 1.2150542736053467,
      "learning_rate": 6.7230676974441266e-06,
      "epoch": 20.521023765996343,
      "step": 44900
    },
    {
      "loss": 0.4832,
      "grad_norm": 1.0537642240524292,
      "learning_rate": 6.69065331193984e-06,
      "epoch": 20.56672760511883,
      "step": 45000
    },
    {
      "loss": 0.4743,
      "grad_norm": 0.7050768136978149,
      "learning_rate": 6.658238926435553e-06,
      "epoch": 20.612431444241317,
      "step": 45100
    },
    {
      "loss": 0.4756,
      "grad_norm": 1.2911694049835205,
      "learning_rate": 6.625824540931266e-06,
      "epoch": 20.6581352833638,
      "step": 45200
    },
    {
      "loss": 0.4781,
      "grad_norm": 0.9243592023849487,
      "learning_rate": 6.593410155426979e-06,
      "epoch": 20.70383912248629,
      "step": 45300
    },
    {
      "loss": 0.4783,
      "grad_norm": 1.2517890930175781,
      "learning_rate": 6.560995769922692e-06,
      "epoch": 20.749542961608775,
      "step": 45400
    },
    {
      "loss": 0.4795,
      "grad_norm": 0.9159523844718933,
      "learning_rate": 6.528581384418405e-06,
      "epoch": 20.795246800731263,
      "step": 45500
    },
    {
      "loss": 0.4848,
      "grad_norm": 1.2100833654403687,
      "learning_rate": 6.4961669989141185e-06,
      "epoch": 20.840950639853748,
      "step": 45600
    },
    {
      "loss": 0.4837,
      "grad_norm": 1.1386381387710571,
      "learning_rate": 6.463752613409832e-06,
      "epoch": 20.886654478976233,
      "step": 45700
    },
    {
      "loss": 0.4779,
      "grad_norm": 1.1936452388763428,
      "learning_rate": 6.431338227905545e-06,
      "epoch": 20.93235831809872,
      "step": 45800
    },
    {
      "loss": 0.4805,
      "grad_norm": 1.0590462684631348,
      "learning_rate": 6.398923842401258e-06,
      "epoch": 20.978062157221206,
      "step": 45900
    },
    {
      "eval_loss": 0.47956544160842896,
      "eval_roc_auc": 0.8378432844444444,
      "eval_accuracy": 0.7682666666666667,
      "eval_f1": 0.7682658592019271,
      "eval_precision": 0.7682704057599665,
      "eval_recall": 0.7682666666666667,
      "eval_runtime": 48.7691,
      "eval_samples_per_second": 615.144,
      "eval_steps_per_second": 4.819,
      "epoch": 21.0,
      "step": 45948
    },
    {
      "loss": 0.4787,
      "grad_norm": 1.478021502494812,
      "learning_rate": 6.366509456896971e-06,
      "epoch": 21.02376599634369,
      "step": 46000
    },
    {
      "loss": 0.4817,
      "grad_norm": 1.7227174043655396,
      "learning_rate": 6.334095071392684e-06,
      "epoch": 21.06946983546618,
      "step": 46100
    },
    {
      "loss": 0.4803,
      "grad_norm": 1.0520566701889038,
      "learning_rate": 6.301680685888398e-06,
      "epoch": 21.115173674588664,
      "step": 46200
    },
    {
      "loss": 0.4737,
      "grad_norm": 1.2785906791687012,
      "learning_rate": 6.269266300384111e-06,
      "epoch": 21.160877513711153,
      "step": 46300
    },
    {
      "loss": 0.4812,
      "grad_norm": 0.9032114744186401,
      "learning_rate": 6.236851914879824e-06,
      "epoch": 21.206581352833638,
      "step": 46400
    },
    {
      "loss": 0.4805,
      "grad_norm": 1.109264612197876,
      "learning_rate": 6.2044375293755375e-06,
      "epoch": 21.252285191956123,
      "step": 46500
    },
    {
      "loss": 0.4945,
      "grad_norm": 0.8413925766944885,
      "learning_rate": 6.172023143871251e-06,
      "epoch": 21.29798903107861,
      "step": 46600
    },
    {
      "loss": 0.4744,
      "grad_norm": 0.897728443145752,
      "learning_rate": 6.139608758366964e-06,
      "epoch": 21.343692870201096,
      "step": 46700
    },
    {
      "loss": 0.484,
      "grad_norm": 1.1170693635940552,
      "learning_rate": 6.107194372862677e-06,
      "epoch": 21.389396709323584,
      "step": 46800
    },
    {
      "loss": 0.4753,
      "grad_norm": 1.0519568920135498,
      "learning_rate": 6.07477998735839e-06,
      "epoch": 21.43510054844607,
      "step": 46900
    },
    {
      "loss": 0.4867,
      "grad_norm": 0.9644506573677063,
      "learning_rate": 6.042365601854103e-06,
      "epoch": 21.480804387568554,
      "step": 47000
    },
    {
      "loss": 0.4815,
      "grad_norm": 0.801170289516449,
      "learning_rate": 6.009951216349816e-06,
      "epoch": 21.526508226691043,
      "step": 47100
    },
    {
      "loss": 0.4775,
      "grad_norm": 0.7638825178146362,
      "learning_rate": 5.977536830845529e-06,
      "epoch": 21.572212065813527,
      "step": 47200
    },
    {
      "loss": 0.477,
      "grad_norm": 0.8808513283729553,
      "learning_rate": 5.9451224453412425e-06,
      "epoch": 21.617915904936016,
      "step": 47300
    },
    {
      "loss": 0.4747,
      "grad_norm": 0.7209402918815613,
      "learning_rate": 5.912708059836956e-06,
      "epoch": 21.6636197440585,
      "step": 47400
    },
    {
      "loss": 0.4816,
      "grad_norm": 1.3752124309539795,
      "learning_rate": 5.880293674332669e-06,
      "epoch": 21.709323583180986,
      "step": 47500
    },
    {
      "loss": 0.4741,
      "grad_norm": 0.8826931715011597,
      "learning_rate": 5.847879288828382e-06,
      "epoch": 21.755027422303474,
      "step": 47600
    },
    {
      "loss": 0.4731,
      "grad_norm": 0.9233576059341431,
      "learning_rate": 5.815464903324096e-06,
      "epoch": 21.80073126142596,
      "step": 47700
    },
    {
      "loss": 0.4713,
      "grad_norm": 0.7954463362693787,
      "learning_rate": 5.783050517819809e-06,
      "epoch": 21.846435100548447,
      "step": 47800
    },
    {
      "loss": 0.4837,
      "grad_norm": 0.8854296207427979,
      "learning_rate": 5.750636132315522e-06,
      "epoch": 21.892138939670932,
      "step": 47900
    },
    {
      "loss": 0.4711,
      "grad_norm": 0.7655118107795715,
      "learning_rate": 5.718221746811235e-06,
      "epoch": 21.937842778793417,
      "step": 48000
    },
    {
      "loss": 0.4632,
      "grad_norm": 0.8521143794059753,
      "learning_rate": 5.685807361306948e-06,
      "epoch": 21.983546617915906,
      "step": 48100
    },
    {
      "eval_loss": 0.4792498052120209,
      "eval_roc_auc": 0.8380765333333333,
      "eval_accuracy": 0.7688333333333334,
      "eval_f1": 0.7688280808504725,
      "eval_precision": 0.768857768322242,
      "eval_recall": 0.7688333333333334,
      "eval_runtime": 48.714,
      "eval_samples_per_second": 615.839,
      "eval_steps_per_second": 4.824,
      "epoch": 22.0,
      "step": 48136
    },
    {
      "loss": 0.4751,
      "grad_norm": 1.9767290353775024,
      "learning_rate": 5.6533929758026615e-06,
      "epoch": 22.02925045703839,
      "step": 48200
    },
    {
      "loss": 0.4781,
      "grad_norm": 0.7651291489601135,
      "learning_rate": 5.620978590298375e-06,
      "epoch": 22.07495429616088,
      "step": 48300
    },
    {
      "loss": 0.47,
      "grad_norm": 0.6972662806510925,
      "learning_rate": 5.588564204794088e-06,
      "epoch": 22.120658135283364,
      "step": 48400
    },
    {
      "loss": 0.4827,
      "grad_norm": 0.8911331295967102,
      "learning_rate": 5.556149819289801e-06,
      "epoch": 22.16636197440585,
      "step": 48500
    },
    {
      "loss": 0.4772,
      "grad_norm": 0.807378351688385,
      "learning_rate": 5.523735433785514e-06,
      "epoch": 22.212065813528337,
      "step": 48600
    },
    {
      "loss": 0.4802,
      "grad_norm": 1.0965213775634766,
      "learning_rate": 5.491321048281227e-06,
      "epoch": 22.257769652650822,
      "step": 48700
    },
    {
      "loss": 0.4846,
      "grad_norm": 0.8856799006462097,
      "learning_rate": 5.45890666277694e-06,
      "epoch": 22.30347349177331,
      "step": 48800
    },
    {
      "loss": 0.4844,
      "grad_norm": 0.817471981048584,
      "learning_rate": 5.4264922772726534e-06,
      "epoch": 22.349177330895795,
      "step": 48900
    },
    {
      "loss": 0.4731,
      "grad_norm": 1.1039735078811646,
      "learning_rate": 5.3940778917683666e-06,
      "epoch": 22.39488117001828,
      "step": 49000
    },
    {
      "loss": 0.4766,
      "grad_norm": 0.8320253491401672,
      "learning_rate": 5.3616635062640805e-06,
      "epoch": 22.44058500914077,
      "step": 49100
    },
    {
      "loss": 0.4773,
      "grad_norm": 1.189024567604065,
      "learning_rate": 5.329249120759794e-06,
      "epoch": 22.486288848263253,
      "step": 49200
    },
    {
      "loss": 0.4811,
      "grad_norm": 0.6750577092170715,
      "learning_rate": 5.296834735255507e-06,
      "epoch": 22.531992687385742,
      "step": 49300
    },
    {
      "loss": 0.4764,
      "grad_norm": 1.027724027633667,
      "learning_rate": 5.26442034975122e-06,
      "epoch": 22.577696526508227,
      "step": 49400
    },
    {
      "loss": 0.4766,
      "grad_norm": 0.7377123236656189,
      "learning_rate": 5.232005964246933e-06,
      "epoch": 22.62340036563071,
      "step": 49500
    },
    {
      "loss": 0.476,
      "grad_norm": 1.0949469804763794,
      "learning_rate": 5.199591578742646e-06,
      "epoch": 22.6691042047532,
      "step": 49600
    },
    {
      "loss": 0.4667,
      "grad_norm": 1.1046500205993652,
      "learning_rate": 5.167177193238359e-06,
      "epoch": 22.714808043875685,
      "step": 49700
    },
    {
      "loss": 0.4755,
      "grad_norm": 0.7680239081382751,
      "learning_rate": 5.1347628077340724e-06,
      "epoch": 22.760511882998173,
      "step": 49800
    },
    {
      "loss": 0.4791,
      "grad_norm": 1.3143806457519531,
      "learning_rate": 5.102348422229786e-06,
      "epoch": 22.80621572212066,
      "step": 49900
    },
    {
      "loss": 0.4776,
      "grad_norm": 0.8820700645446777,
      "learning_rate": 5.069934036725499e-06,
      "epoch": 22.851919561243143,
      "step": 50000
    },
    {
      "loss": 0.4765,
      "grad_norm": 0.6796519756317139,
      "learning_rate": 5.037519651221212e-06,
      "epoch": 22.89762340036563,
      "step": 50100
    },
    {
      "loss": 0.488,
      "grad_norm": 0.8613776564598083,
      "learning_rate": 5.005105265716925e-06,
      "epoch": 22.943327239488116,
      "step": 50200
    },
    {
      "loss": 0.4784,
      "grad_norm": 0.8862566351890564,
      "learning_rate": 4.972690880212639e-06,
      "epoch": 22.989031078610605,
      "step": 50300
    },
    {
      "eval_loss": 0.4789731800556183,
      "eval_roc_auc": 0.8384595533333334,
      "eval_accuracy": 0.7685666666666666,
      "eval_f1": 0.7685666643523333,
      "eval_precision": 0.7685666774093338,
      "eval_recall": 0.7685666666666666,
      "eval_runtime": 48.7826,
      "eval_samples_per_second": 614.973,
      "eval_steps_per_second": 4.817,
      "epoch": 23.0,
      "step": 50324
    },
    {
      "loss": 0.4767,
      "grad_norm": 1.343900442123413,
      "learning_rate": 4.940276494708352e-06,
      "epoch": 23.03473491773309,
      "step": 50400
    },
    {
      "loss": 0.4856,
      "grad_norm": 1.0464770793914795,
      "learning_rate": 4.907862109204065e-06,
      "epoch": 23.080438756855575,
      "step": 50500
    },
    {
      "loss": 0.4748,
      "grad_norm": 1.0066797733306885,
      "learning_rate": 4.875447723699778e-06,
      "epoch": 23.126142595978063,
      "step": 50600
    },
    {
      "loss": 0.4799,
      "grad_norm": 0.9575040936470032,
      "learning_rate": 4.8430333381954915e-06,
      "epoch": 23.171846435100548,
      "step": 50700
    },
    {
      "loss": 0.4792,
      "grad_norm": 1.3938313722610474,
      "learning_rate": 4.810618952691205e-06,
      "epoch": 23.217550274223036,
      "step": 50800
    },
    {
      "loss": 0.4724,
      "grad_norm": 0.742855429649353,
      "learning_rate": 4.7782045671869186e-06,
      "epoch": 23.26325411334552,
      "step": 50900
    },
    {
      "loss": 0.4754,
      "grad_norm": 1.3241904973983765,
      "learning_rate": 4.745790181682632e-06,
      "epoch": 23.308957952468006,
      "step": 51000
    },
    {
      "loss": 0.4792,
      "grad_norm": 1.1699228286743164,
      "learning_rate": 4.713375796178344e-06,
      "epoch": 23.354661791590495,
      "step": 51100
    },
    {
      "loss": 0.4734,
      "grad_norm": 1.4843379259109497,
      "learning_rate": 4.680961410674057e-06,
      "epoch": 23.40036563071298,
      "step": 51200
    },
    {
      "loss": 0.4759,
      "grad_norm": 1.2040752172470093,
      "learning_rate": 4.64854702516977e-06,
      "epoch": 23.446069469835468,
      "step": 51300
    },
    {
      "loss": 0.4719,
      "grad_norm": 0.9157677888870239,
      "learning_rate": 4.616132639665483e-06,
      "epoch": 23.491773308957953,
      "step": 51400
    },
    {
      "loss": 0.4708,
      "grad_norm": 0.7649509906768799,
      "learning_rate": 4.5837182541611965e-06,
      "epoch": 23.537477148080438,
      "step": 51500
    },
    {
      "loss": 0.4769,
      "grad_norm": 1.365655779838562,
      "learning_rate": 4.5513038686569105e-06,
      "epoch": 23.583180987202926,
      "step": 51600
    },
    {
      "loss": 0.4901,
      "grad_norm": 1.103564977645874,
      "learning_rate": 4.518889483152624e-06,
      "epoch": 23.62888482632541,
      "step": 51700
    },
    {
      "loss": 0.4758,
      "grad_norm": 1.4075424671173096,
      "learning_rate": 4.486475097648337e-06,
      "epoch": 23.6745886654479,
      "step": 51800
    },
    {
      "loss": 0.4864,
      "grad_norm": 0.7829253077507019,
      "learning_rate": 4.45406071214405e-06,
      "epoch": 23.720292504570384,
      "step": 51900
    },
    {
      "loss": 0.4704,
      "grad_norm": 0.8196996450424194,
      "learning_rate": 4.421646326639763e-06,
      "epoch": 23.76599634369287,
      "step": 52000
    },
    {
      "loss": 0.4767,
      "grad_norm": 0.8635275959968567,
      "learning_rate": 4.389231941135476e-06,
      "epoch": 23.811700182815358,
      "step": 52100
    },
    {
      "loss": 0.4803,
      "grad_norm": 1.1406488418579102,
      "learning_rate": 4.356817555631189e-06,
      "epoch": 23.857404021937842,
      "step": 52200
    },
    {
      "loss": 0.488,
      "grad_norm": 0.6693164706230164,
      "learning_rate": 4.324403170126903e-06,
      "epoch": 23.903107861060327,
      "step": 52300
    },
    {
      "loss": 0.4744,
      "grad_norm": 1.0962789058685303,
      "learning_rate": 4.291988784622616e-06,
      "epoch": 23.948811700182816,
      "step": 52400
    },
    {
      "loss": 0.4776,
      "grad_norm": 0.7999894022941589,
      "learning_rate": 4.2595743991183295e-06,
      "epoch": 23.9945155393053,
      "step": 52500
    },
    {
      "eval_loss": 0.4787406325340271,
      "eval_roc_auc": 0.8386016733333332,
      "eval_accuracy": 0.7691666666666667,
      "eval_f1": 0.7691617110815776,
      "eval_precision": 0.7691897822923718,
      "eval_recall": 0.7691666666666667,
      "eval_runtime": 48.7619,
      "eval_samples_per_second": 615.234,
      "eval_steps_per_second": 4.819,
      "epoch": 24.0,
      "step": 52512
    },
    {
      "loss": 0.4797,
      "grad_norm": 0.8673723936080933,
      "learning_rate": 4.227160013614043e-06,
      "epoch": 24.04021937842779,
      "step": 52600
    },
    {
      "loss": 0.4842,
      "grad_norm": 0.8210523128509521,
      "learning_rate": 4.194745628109756e-06,
      "epoch": 24.085923217550274,
      "step": 52700
    },
    {
      "loss": 0.4753,
      "grad_norm": 1.2162234783172607,
      "learning_rate": 4.162331242605469e-06,
      "epoch": 24.13162705667276,
      "step": 52800
    },
    {
      "loss": 0.4781,
      "grad_norm": 0.903827428817749,
      "learning_rate": 4.129916857101182e-06,
      "epoch": 24.177330895795247,
      "step": 52900
    },
    {
      "loss": 0.4743,
      "grad_norm": 0.6398141980171204,
      "learning_rate": 4.097502471596895e-06,
      "epoch": 24.223034734917732,
      "step": 53000
    },
    {
      "loss": 0.4799,
      "grad_norm": 0.7279695272445679,
      "learning_rate": 4.065088086092608e-06,
      "epoch": 24.26873857404022,
      "step": 53100
    },
    {
      "loss": 0.4835,
      "grad_norm": 1.0495076179504395,
      "learning_rate": 4.032673700588321e-06,
      "epoch": 24.314442413162705,
      "step": 53200
    },
    {
      "loss": 0.4693,
      "grad_norm": 0.6402170062065125,
      "learning_rate": 4.0002593150840345e-06,
      "epoch": 24.36014625228519,
      "step": 53300
    },
    {
      "loss": 0.4762,
      "grad_norm": 1.0812504291534424,
      "learning_rate": 3.967844929579748e-06,
      "epoch": 24.40585009140768,
      "step": 53400
    },
    {
      "loss": 0.4894,
      "grad_norm": 0.8559828996658325,
      "learning_rate": 3.935430544075461e-06,
      "epoch": 24.451553930530164,
      "step": 53500
    },
    {
      "loss": 0.4634,
      "grad_norm": 0.7171596884727478,
      "learning_rate": 3.903016158571174e-06,
      "epoch": 24.497257769652652,
      "step": 53600
    },
    {
      "loss": 0.4787,
      "grad_norm": 1.5012863874435425,
      "learning_rate": 3.870601773066888e-06,
      "epoch": 24.542961608775137,
      "step": 53700
    },
    {
      "loss": 0.4804,
      "grad_norm": 0.91566002368927,
      "learning_rate": 3.838187387562601e-06,
      "epoch": 24.588665447897622,
      "step": 53800
    },
    {
      "loss": 0.4911,
      "grad_norm": 0.7106621265411377,
      "learning_rate": 3.8057730020583137e-06,
      "epoch": 24.63436928702011,
      "step": 53900
    },
    {
      "loss": 0.4739,
      "grad_norm": 1.009945034980774,
      "learning_rate": 3.773358616554027e-06,
      "epoch": 24.680073126142595,
      "step": 54000
    },
    {
      "loss": 0.4701,
      "grad_norm": 1.8391729593276978,
      "learning_rate": 3.74094423104974e-06,
      "epoch": 24.725776965265084,
      "step": 54100
    },
    {
      "loss": 0.4736,
      "grad_norm": 1.213033676147461,
      "learning_rate": 3.708529845545453e-06,
      "epoch": 24.77148080438757,
      "step": 54200
    },
    {
      "loss": 0.4678,
      "grad_norm": 0.7343942523002625,
      "learning_rate": 3.6761154600411662e-06,
      "epoch": 24.817184643510053,
      "step": 54300
    },
    {
      "loss": 0.4787,
      "grad_norm": 0.9040113687515259,
      "learning_rate": 3.6437010745368794e-06,
      "epoch": 24.862888482632542,
      "step": 54400
    },
    {
      "loss": 0.4828,
      "grad_norm": 1.2303893566131592,
      "learning_rate": 3.6112866890325933e-06,
      "epoch": 24.908592321755027,
      "step": 54500
    },
    {
      "loss": 0.4834,
      "grad_norm": 0.6605854034423828,
      "learning_rate": 3.5788723035283065e-06,
      "epoch": 24.954296160877515,
      "step": 54600
    },
    {
      "loss": 0.4718,
      "grad_norm": 1.0630346536636353,
      "learning_rate": 3.5464579180240196e-06,
      "epoch": 25.0,
      "step": 54700
    },
    {
      "eval_loss": 0.47854453325271606,
      "eval_roc_auc": 0.838740028888889,
      "eval_accuracy": 0.7689,
      "eval_f1": 0.7688999976889999,
      "eval_precision": 0.7689000107560003,
      "eval_recall": 0.7689,
      "eval_runtime": 48.7584,
      "eval_samples_per_second": 615.279,
      "eval_steps_per_second": 4.82,
      "epoch": 25.0,
      "step": 54700
    },
    {
      "loss": 0.4697,
      "grad_norm": 0.9878870248794556,
      "learning_rate": 3.5140435325197323e-06,
      "epoch": 25.045703839122485,
      "step": 54800
    },
    {
      "loss": 0.483,
      "grad_norm": 1.0900096893310547,
      "learning_rate": 3.4816291470154454e-06,
      "epoch": 25.091407678244973,
      "step": 54900
    },
    {
      "loss": 0.4838,
      "grad_norm": 1.0025981664657593,
      "learning_rate": 3.4492147615111586e-06,
      "epoch": 25.137111517367458,
      "step": 55000
    },
    {
      "loss": 0.4822,
      "grad_norm": 0.8863704204559326,
      "learning_rate": 3.4168003760068717e-06,
      "epoch": 25.182815356489947,
      "step": 55100
    },
    {
      "loss": 0.4764,
      "grad_norm": 1.1036789417266846,
      "learning_rate": 3.3843859905025857e-06,
      "epoch": 25.22851919561243,
      "step": 55200
    },
    {
      "loss": 0.457,
      "grad_norm": 1.0050097703933716,
      "learning_rate": 3.351971604998299e-06,
      "epoch": 25.274223034734916,
      "step": 55300
    },
    {
      "loss": 0.4672,
      "grad_norm": 1.2476340532302856,
      "learning_rate": 3.319557219494012e-06,
      "epoch": 25.319926873857405,
      "step": 55400
    },
    {
      "loss": 0.483,
      "grad_norm": 1.1798195838928223,
      "learning_rate": 3.287142833989725e-06,
      "epoch": 25.36563071297989,
      "step": 55500
    },
    {
      "loss": 0.4811,
      "grad_norm": 1.3930469751358032,
      "learning_rate": 3.254728448485438e-06,
      "epoch": 25.411334552102378,
      "step": 55600
    },
    {
      "loss": 0.4796,
      "grad_norm": 0.8713249564170837,
      "learning_rate": 3.2223140629811513e-06,
      "epoch": 25.457038391224863,
      "step": 55700
    },
    {
      "loss": 0.4783,
      "grad_norm": 0.8613261580467224,
      "learning_rate": 3.1898996774768645e-06,
      "epoch": 25.502742230347348,
      "step": 55800
    },
    {
      "loss": 0.4715,
      "grad_norm": 1.465773344039917,
      "learning_rate": 3.157485291972578e-06,
      "epoch": 25.548446069469836,
      "step": 55900
    },
    {
      "loss": 0.4794,
      "grad_norm": 0.8698953986167908,
      "learning_rate": 3.125070906468291e-06,
      "epoch": 25.59414990859232,
      "step": 56000
    },
    {
      "loss": 0.4735,
      "grad_norm": 1.2231611013412476,
      "learning_rate": 3.0926565209640043e-06,
      "epoch": 25.63985374771481,
      "step": 56100
    },
    {
      "loss": 0.48,
      "grad_norm": 0.7932169437408447,
      "learning_rate": 3.0602421354597174e-06,
      "epoch": 25.685557586837295,
      "step": 56200
    },
    {
      "loss": 0.4837,
      "grad_norm": 1.259600281715393,
      "learning_rate": 3.0278277499554305e-06,
      "epoch": 25.73126142595978,
      "step": 56300
    },
    {
      "loss": 0.4761,
      "grad_norm": 0.7241405844688416,
      "learning_rate": 2.9954133644511437e-06,
      "epoch": 25.776965265082268,
      "step": 56400
    },
    {
      "loss": 0.4817,
      "grad_norm": 0.8812822103500366,
      "learning_rate": 2.9629989789468568e-06,
      "epoch": 25.822669104204753,
      "step": 56500
    },
    {
      "loss": 0.4863,
      "grad_norm": 1.228602409362793,
      "learning_rate": 2.9305845934425703e-06,
      "epoch": 25.86837294332724,
      "step": 56600
    },
    {
      "loss": 0.4757,
      "grad_norm": 1.7836463451385498,
      "learning_rate": 2.8981702079382835e-06,
      "epoch": 25.914076782449726,
      "step": 56700
    },
    {
      "loss": 0.4856,
      "grad_norm": 0.8556657433509827,
      "learning_rate": 2.8657558224339966e-06,
      "epoch": 25.95978062157221,
      "step": 56800
    },
    {
      "eval_loss": 0.4783812463283539,
      "eval_roc_auc": 0.8390106355555556,
      "eval_accuracy": 0.7697333333333334,
      "eval_f1": 0.7697298905393412,
      "eval_precision": 0.7697494655502599,
      "eval_recall": 0.7697333333333334,
      "eval_runtime": 48.7708,
      "eval_samples_per_second": 615.122,
      "eval_steps_per_second": 4.818,
      "epoch": 26.0,
      "step": 56888
    },
    {
      "loss": 0.4636,
      "grad_norm": 0.7678999900817871,
      "learning_rate": 2.8333414369297097e-06,
      "epoch": 26.0054844606947,
      "step": 56900
    },
    {
      "loss": 0.4709,
      "grad_norm": 0.8492956757545471,
      "learning_rate": 2.800927051425423e-06,
      "epoch": 26.051188299817184,
      "step": 57000
    },
    {
      "loss": 0.4668,
      "grad_norm": 1.17118239402771,
      "learning_rate": 2.768512665921136e-06,
      "epoch": 26.096892138939673,
      "step": 57100
    },
    {
      "loss": 0.4792,
      "grad_norm": 0.8998304605484009,
      "learning_rate": 2.736098280416849e-06,
      "epoch": 26.142595978062158,
      "step": 57200
    },
    {
      "loss": 0.4753,
      "grad_norm": 0.8057536482810974,
      "learning_rate": 2.7036838949125627e-06,
      "epoch": 26.188299817184642,
      "step": 57300
    },
    {
      "loss": 0.4786,
      "grad_norm": 0.8289275765419006,
      "learning_rate": 2.671269509408276e-06,
      "epoch": 26.23400365630713,
      "step": 57400
    },
    {
      "loss": 0.4757,
      "grad_norm": 1.0376999378204346,
      "learning_rate": 2.638855123903989e-06,
      "epoch": 26.279707495429616,
      "step": 57500
    },
    {
      "loss": 0.4768,
      "grad_norm": 1.0608330965042114,
      "learning_rate": 2.606440738399702e-06,
      "epoch": 26.3254113345521,
      "step": 57600
    },
    {
      "loss": 0.4753,
      "grad_norm": 0.6365672945976257,
      "learning_rate": 2.574026352895415e-06,
      "epoch": 26.37111517367459,
      "step": 57700
    },
    {
      "loss": 0.4719,
      "grad_norm": 1.5593287944793701,
      "learning_rate": 2.5416119673911283e-06,
      "epoch": 26.416819012797074,
      "step": 57800
    },
    {
      "loss": 0.4811,
      "grad_norm": 0.6921570301055908,
      "learning_rate": 2.5091975818868414e-06,
      "epoch": 26.462522851919562,
      "step": 57900
    },
    {
      "loss": 0.4763,
      "grad_norm": 1.0659606456756592,
      "learning_rate": 2.4767831963825546e-06,
      "epoch": 26.508226691042047,
      "step": 58000
    },
    {
      "loss": 0.4772,
      "grad_norm": 0.9975870251655579,
      "learning_rate": 2.4443688108782677e-06,
      "epoch": 26.553930530164536,
      "step": 58100
    },
    {
      "loss": 0.477,
      "grad_norm": 0.7672724723815918,
      "learning_rate": 2.4119544253739813e-06,
      "epoch": 26.59963436928702,
      "step": 58200
    },
    {
      "loss": 0.4822,
      "grad_norm": 1.8566153049468994,
      "learning_rate": 2.3795400398696944e-06,
      "epoch": 26.645338208409505,
      "step": 58300
    },
    {
      "loss": 0.4718,
      "grad_norm": 0.7113625407218933,
      "learning_rate": 2.3471256543654075e-06,
      "epoch": 26.691042047531994,
      "step": 58400
    },
    {
      "loss": 0.4791,
      "grad_norm": 1.5845308303833008,
      "learning_rate": 2.3147112688611206e-06,
      "epoch": 26.73674588665448,
      "step": 58500
    },
    {
      "loss": 0.4768,
      "grad_norm": 0.730094313621521,
      "learning_rate": 2.282296883356834e-06,
      "epoch": 26.782449725776964,
      "step": 58600
    },
    {
      "loss": 0.4908,
      "grad_norm": 1.3548774719238281,
      "learning_rate": 2.2498824978525473e-06,
      "epoch": 26.828153564899452,
      "step": 58700
    },
    {
      "loss": 0.4788,
      "grad_norm": 1.4824328422546387,
      "learning_rate": 2.2174681123482605e-06,
      "epoch": 26.873857404021937,
      "step": 58800
    },
    {
      "loss": 0.4829,
      "grad_norm": 1.0902520418167114,
      "learning_rate": 2.1850537268439736e-06,
      "epoch": 26.919561243144425,
      "step": 58900
    },
    {
      "loss": 0.4719,
      "grad_norm": 0.8758527636528015,
      "learning_rate": 2.1526393413396867e-06,
      "epoch": 26.96526508226691,
      "step": 59000
    },
    {
      "eval_loss": 0.47826525568962097,
      "eval_roc_auc": 0.8390642711111111,
      "eval_accuracy": 0.7694,
      "eval_f1": 0.7693981049648714,
      "eval_precision": 0.7694088557684323,
      "eval_recall": 0.7694,
      "eval_runtime": 48.7674,
      "eval_samples_per_second": 615.165,
      "eval_steps_per_second": 4.819,
      "epoch": 27.0,
      "step": 59076
    },
    {
      "loss": 0.4808,
      "grad_norm": 0.736616313457489,
      "learning_rate": 2.1202249558354e-06,
      "epoch": 27.010968921389395,
      "step": 59100
    },
    {
      "loss": 0.4763,
      "grad_norm": 1.1412910223007202,
      "learning_rate": 2.087810570331113e-06,
      "epoch": 27.056672760511884,
      "step": 59200
    },
    {
      "loss": 0.4693,
      "grad_norm": 0.9944353103637695,
      "learning_rate": 2.0553961848268265e-06,
      "epoch": 27.10237659963437,
      "step": 59300
    },
    {
      "loss": 0.4794,
      "grad_norm": 0.9768693447113037,
      "learning_rate": 2.0229817993225397e-06,
      "epoch": 27.148080438756857,
      "step": 59400
    },
    {
      "loss": 0.4788,
      "grad_norm": 0.6240454912185669,
      "learning_rate": 1.9905674138182528e-06,
      "epoch": 27.19378427787934,
      "step": 59500
    },
    {
      "loss": 0.4819,
      "grad_norm": 0.6408963203430176,
      "learning_rate": 1.958153028313966e-06,
      "epoch": 27.239488117001827,
      "step": 59600
    },
    {
      "loss": 0.4835,
      "grad_norm": 1.1604571342468262,
      "learning_rate": 1.925738642809679e-06,
      "epoch": 27.285191956124315,
      "step": 59700
    },
    {
      "loss": 0.4828,
      "grad_norm": 0.7023749351501465,
      "learning_rate": 1.8933242573053922e-06,
      "epoch": 27.3308957952468,
      "step": 59800
    },
    {
      "loss": 0.4758,
      "grad_norm": 1.0760178565979004,
      "learning_rate": 1.8609098718011053e-06,
      "epoch": 27.37659963436929,
      "step": 59900
    },
    {
      "loss": 0.4785,
      "grad_norm": 0.9015173316001892,
      "learning_rate": 1.8284954862968189e-06,
      "epoch": 27.422303473491773,
      "step": 60000
    },
    {
      "loss": 0.476,
      "grad_norm": 0.8555828928947449,
      "learning_rate": 1.796081100792532e-06,
      "epoch": 27.468007312614258,
      "step": 60100
    },
    {
      "loss": 0.4846,
      "grad_norm": 0.815904438495636,
      "learning_rate": 1.7636667152882451e-06,
      "epoch": 27.513711151736747,
      "step": 60200
    },
    {
      "loss": 0.4766,
      "grad_norm": 1.6119579076766968,
      "learning_rate": 1.731252329783958e-06,
      "epoch": 27.55941499085923,
      "step": 60300
    },
    {
      "loss": 0.4738,
      "grad_norm": 1.1897013187408447,
      "learning_rate": 1.6988379442796716e-06,
      "epoch": 27.60511882998172,
      "step": 60400
    },
    {
      "loss": 0.4599,
      "grad_norm": 0.7750605344772339,
      "learning_rate": 1.6664235587753847e-06,
      "epoch": 27.650822669104205,
      "step": 60500
    },
    {
      "loss": 0.4729,
      "grad_norm": 1.2739193439483643,
      "learning_rate": 1.6340091732710978e-06,
      "epoch": 27.69652650822669,
      "step": 60600
    },
    {
      "loss": 0.4741,
      "grad_norm": 0.9502938985824585,
      "learning_rate": 1.6015947877668112e-06,
      "epoch": 27.742230347349178,
      "step": 60700
    },
    {
      "loss": 0.4817,
      "grad_norm": 0.7288128733634949,
      "learning_rate": 1.5691804022625243e-06,
      "epoch": 27.787934186471663,
      "step": 60800
    },
    {
      "loss": 0.4763,
      "grad_norm": 1.055650234222412,
      "learning_rate": 1.5367660167582374e-06,
      "epoch": 27.83363802559415,
      "step": 60900
    },
    {
      "loss": 0.477,
      "grad_norm": 0.9294437170028687,
      "learning_rate": 1.5043516312539506e-06,
      "epoch": 27.879341864716636,
      "step": 61000
    },
    {
      "loss": 0.48,
      "grad_norm": 1.0605312585830688,
      "learning_rate": 1.471937245749664e-06,
      "epoch": 27.92504570383912,
      "step": 61100
    },
    {
      "loss": 0.4787,
      "grad_norm": 0.6678240895271301,
      "learning_rate": 1.439522860245377e-06,
      "epoch": 27.97074954296161,
      "step": 61200
    },
    {
      "eval_loss": 0.478163480758667,
      "eval_roc_auc": 0.8391440244444445,
      "eval_accuracy": 0.7695333333333333,
      "eval_f1": 0.7695314393939175,
      "eval_precision": 0.7695421934847244,
      "eval_recall": 0.7695333333333333,
      "eval_runtime": 48.7907,
      "eval_samples_per_second": 614.871,
      "eval_steps_per_second": 4.816,
      "epoch": 28.0,
      "step": 61264
    },
    {
      "loss": 0.4804,
      "grad_norm": 0.7674061059951782,
      "learning_rate": 1.4071084747410902e-06,
      "epoch": 28.016453382084094,
      "step": 61300
    },
    {
      "loss": 0.4801,
      "grad_norm": 0.7633477449417114,
      "learning_rate": 1.3746940892368035e-06,
      "epoch": 28.062157221206583,
      "step": 61400
    },
    {
      "loss": 0.4782,
      "grad_norm": 0.7747336030006409,
      "learning_rate": 1.3422797037325166e-06,
      "epoch": 28.107861060329068,
      "step": 61500
    },
    {
      "loss": 0.4792,
      "grad_norm": 0.6979794502258301,
      "learning_rate": 1.3098653182282298e-06,
      "epoch": 28.153564899451553,
      "step": 61600
    },
    {
      "loss": 0.4624,
      "grad_norm": 1.169772744178772,
      "learning_rate": 1.277450932723943e-06,
      "epoch": 28.19926873857404,
      "step": 61700
    },
    {
      "loss": 0.482,
      "grad_norm": 1.0427758693695068,
      "learning_rate": 1.2450365472196562e-06,
      "epoch": 28.244972577696526,
      "step": 61800
    },
    {
      "loss": 0.47,
      "grad_norm": 1.7656028270721436,
      "learning_rate": 1.2126221617153694e-06,
      "epoch": 28.290676416819014,
      "step": 61900
    },
    {
      "loss": 0.479,
      "grad_norm": 0.7678221464157104,
      "learning_rate": 1.1802077762110825e-06,
      "epoch": 28.3363802559415,
      "step": 62000
    },
    {
      "loss": 0.4804,
      "grad_norm": 1.001450777053833,
      "learning_rate": 1.1477933907067958e-06,
      "epoch": 28.382084095063984,
      "step": 62100
    },
    {
      "loss": 0.4774,
      "grad_norm": 0.8738945126533508,
      "learning_rate": 1.115379005202509e-06,
      "epoch": 28.427787934186473,
      "step": 62200
    },
    {
      "loss": 0.4703,
      "grad_norm": 0.6550184488296509,
      "learning_rate": 1.082964619698222e-06,
      "epoch": 28.473491773308957,
      "step": 62300
    },
    {
      "loss": 0.4725,
      "grad_norm": 1.1910136938095093,
      "learning_rate": 1.0505502341939354e-06,
      "epoch": 28.519195612431446,
      "step": 62400
    },
    {
      "loss": 0.4794,
      "grad_norm": 0.6665461659431458,
      "learning_rate": 1.0181358486896486e-06,
      "epoch": 28.56489945155393,
      "step": 62500
    },
    {
      "loss": 0.4717,
      "grad_norm": 0.9875330328941345,
      "learning_rate": 9.857214631853617e-07,
      "epoch": 28.610603290676416,
      "step": 62600
    },
    {
      "loss": 0.4828,
      "grad_norm": 0.8764094114303589,
      "learning_rate": 9.533070776810749e-07,
      "epoch": 28.656307129798904,
      "step": 62700
    },
    {
      "loss": 0.4855,
      "grad_norm": 1.1340121030807495,
      "learning_rate": 9.208926921767882e-07,
      "epoch": 28.70201096892139,
      "step": 62800
    },
    {
      "loss": 0.4796,
      "grad_norm": 0.8230337500572205,
      "learning_rate": 8.884783066725013e-07,
      "epoch": 28.747714808043877,
      "step": 62900
    },
    {
      "loss": 0.478,
      "grad_norm": 0.8886426091194153,
      "learning_rate": 8.560639211682145e-07,
      "epoch": 28.793418647166362,
      "step": 63000
    },
    {
      "loss": 0.4744,
      "grad_norm": 0.633073091506958,
      "learning_rate": 8.236495356639278e-07,
      "epoch": 28.839122486288847,
      "step": 63100
    },
    {
      "loss": 0.4773,
      "grad_norm": 1.2401158809661865,
      "learning_rate": 7.912351501596409e-07,
      "epoch": 28.884826325411336,
      "step": 63200
    },
    {
      "loss": 0.4878,
      "grad_norm": 0.7256876826286316,
      "learning_rate": 7.588207646553541e-07,
      "epoch": 28.93053016453382,
      "step": 63300
    },
    {
      "loss": 0.466,
      "grad_norm": 0.7945926785469055,
      "learning_rate": 7.264063791510673e-07,
      "epoch": 28.97623400365631,
      "step": 63400
    },
    {
      "eval_loss": 0.478127121925354,
      "eval_roc_auc": 0.8391516488888888,
      "eval_accuracy": 0.7694,
      "eval_f1": 0.769399015077571,
      "eval_precision": 0.7694046026279667,
      "eval_recall": 0.7694,
      "eval_runtime": 48.7368,
      "eval_samples_per_second": 615.552,
      "eval_steps_per_second": 4.822,
      "epoch": 29.0,
      "step": 63452
    },
    {
      "loss": 0.4736,
      "grad_norm": 0.6470497846603394,
      "learning_rate": 6.939919936467805e-07,
      "epoch": 29.021937842778794,
      "step": 63500
    },
    {
      "loss": 0.4861,
      "grad_norm": 1.6172327995300293,
      "learning_rate": 6.615776081424936e-07,
      "epoch": 29.06764168190128,
      "step": 63600
    },
    {
      "loss": 0.4879,
      "grad_norm": 1.0465426445007324,
      "learning_rate": 6.291632226382069e-07,
      "epoch": 29.113345521023767,
      "step": 63700
    },
    {
      "loss": 0.4765,
      "grad_norm": 1.2909669876098633,
      "learning_rate": 5.967488371339201e-07,
      "epoch": 29.159049360146252,
      "step": 63800
    },
    {
      "loss": 0.4936,
      "grad_norm": 0.8046048283576965,
      "learning_rate": 5.643344516296332e-07,
      "epoch": 29.204753199268737,
      "step": 63900
    },
    {
      "loss": 0.477,
      "grad_norm": 0.6256291270256042,
      "learning_rate": 5.319200661253465e-07,
      "epoch": 29.250457038391225,
      "step": 64000
    },
    {
      "loss": 0.4663,
      "grad_norm": 0.6709160208702087,
      "learning_rate": 4.995056806210596e-07,
      "epoch": 29.29616087751371,
      "step": 64100
    },
    {
      "loss": 0.474,
      "grad_norm": 0.9796401262283325,
      "learning_rate": 4.6709129511677283e-07,
      "epoch": 29.3418647166362,
      "step": 64200
    },
    {
      "loss": 0.4784,
      "grad_norm": 0.8193144202232361,
      "learning_rate": 4.3467690961248607e-07,
      "epoch": 29.387568555758683,
      "step": 64300
    },
    {
      "loss": 0.479,
      "grad_norm": 1.955587387084961,
      "learning_rate": 4.0226252410819925e-07,
      "epoch": 29.43327239488117,
      "step": 64400
    },
    {
      "loss": 0.4776,
      "grad_norm": 0.7170916199684143,
      "learning_rate": 3.698481386039125e-07,
      "epoch": 29.478976234003657,
      "step": 64500
    },
    {
      "loss": 0.4802,
      "grad_norm": 1.187055230140686,
      "learning_rate": 3.3743375309962567e-07,
      "epoch": 29.52468007312614,
      "step": 64600
    },
    {
      "loss": 0.4738,
      "grad_norm": 1.1016091108322144,
      "learning_rate": 3.0501936759533885e-07,
      "epoch": 29.57038391224863,
      "step": 64700
    },
    {
      "loss": 0.4806,
      "grad_norm": 0.8339217901229858,
      "learning_rate": 2.7260498209105203e-07,
      "epoch": 29.616087751371115,
      "step": 64800
    },
    {
      "loss": 0.4841,
      "grad_norm": 1.0748306512832642,
      "learning_rate": 2.401905965867652e-07,
      "epoch": 29.6617915904936,
      "step": 64900
    },
    {
      "loss": 0.4677,
      "grad_norm": 0.8317537307739258,
      "learning_rate": 2.0777621108247842e-07,
      "epoch": 29.70749542961609,
      "step": 65000
    },
    {
      "loss": 0.4684,
      "grad_norm": 1.3180075883865356,
      "learning_rate": 1.753618255781916e-07,
      "epoch": 29.753199268738573,
      "step": 65100
    },
    {
      "loss": 0.4803,
      "grad_norm": 1.0430028438568115,
      "learning_rate": 1.4294744007390481e-07,
      "epoch": 29.79890310786106,
      "step": 65200
    },
    {
      "loss": 0.4712,
      "grad_norm": 1.1120778322219849,
      "learning_rate": 1.1053305456961801e-07,
      "epoch": 29.844606946983546,
      "step": 65300
    },
    {
      "loss": 0.4832,
      "grad_norm": 0.8491816520690918,
      "learning_rate": 7.81186690653312e-08,
      "epoch": 29.89031078610603,
      "step": 65400
    },
    {
      "loss": 0.4694,
      "grad_norm": 0.7113807201385498,
      "learning_rate": 4.5704283561044394e-08,
      "epoch": 29.93601462522852,
      "step": 65500
    },
    {
      "loss": 0.465,
      "grad_norm": 1.2229681015014648,
      "learning_rate": 1.328989805675759e-08,
      "epoch": 29.981718464351005,
      "step": 65600
    },
    {
      "eval_loss": 0.47810715436935425,
      "eval_roc_auc": 0.8391705466666667,
      "eval_accuracy": 0.7694333333333333,
      "eval_f1": 0.7694318922826601,
      "eval_precision": 0.7694400693350668,
      "eval_recall": 0.7694333333333333,
      "eval_runtime": 48.7259,
      "eval_samples_per_second": 615.689,
      "eval_steps_per_second": 4.823,
      "epoch": 30.0,
      "step": 65640
    },
    {
      "train_runtime": 8900.1238,
      "train_samples_per_second": 471.904,
      "train_steps_per_second": 7.375,
      "total_flos": 1.4311829532672e+18,
      "train_loss": 0.49949290230824844,
      "epoch": 30.0,
      "step": 65640
    },
    {
      "eval_loss": 0.4774109125137329,
      "eval_roc_auc": 0.8391648622222222,
      "eval_accuracy": 0.7721666666666667,
      "eval_f1": 0.7721664537688752,
      "eval_precision": 0.7721676839689877,
      "eval_recall": 0.7721666666666667,
      "eval_runtime": 48.5807,
      "eval_samples_per_second": 617.53,
      "eval_steps_per_second": 4.837,
      "epoch": 30.0,
      "step": 65640
    }
  ],
  "run_name": "modernbert-sentiment-20250816_1156"
}