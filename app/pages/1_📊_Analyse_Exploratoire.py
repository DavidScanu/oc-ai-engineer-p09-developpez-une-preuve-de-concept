import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import sys
import os

# Ajouter le chemin parent pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.data_analysis import (
    load_sentiment140_data, 
    analyze_text_statistics, 
    get_word_frequencies, 
    create_wordcloud_from_data,
    get_temporal_analysis,
    get_basic_stats
)

st.set_page_config(
    page_title="Analyse Exploratoire",
    page_icon="üìä",
    layout="wide"
)

@st.cache_data
def load_data():
    """Cache le chargement des donn√©es"""
    return load_sentiment140_data()

def create_sentiment_distribution(df):
    """Cr√©e un graphique de distribution des sentiments avec vraies donn√©es"""
    sentiment_counts = df['target'].value_counts().sort_index()
    sentiment_labels = ['N√©gatif', 'Positif']
    percentages = (sentiment_counts / len(df) * 100).round(1)
    
    colors = ['#d62728', '#2ca02c']
    
    fig = px.bar(
        x=sentiment_labels, 
        y=sentiment_counts.values,
        color=sentiment_labels,
        color_discrete_sequence=colors,
        title="Distribution des Sentiments dans le Dataset Sentiment140",
        text=[f'{count:,}<br>({pct}%)' for count, pct in zip(sentiment_counts.values, percentages)]
    )
    
    fig.update_traces(
        textposition='outside',
        textfont_size=12
    )
    
    fig.update_layout(
        showlegend=False,
        title_font_size=18,
        font=dict(size=12),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)'
    )
    
    fig.update_yaxes(title_text="Nombre de tweets", title_font=dict(size=14))
    fig.update_xaxes(title_text="Sentiment", title_font=dict(size=14))

    
    return fig

def create_text_length_analysis(df):
    """Analyse de la longueur des textes avec vraies donn√©es"""
    
    fig = px.histogram(
        df,
        x='text_length',
        nbins=50,
        title="Distribution de la Longueur des Tweets (caract√®res)",
        labels={'text_length': 'Longueur (caract√®res)', 'count': 'Fr√©quence'},
        color_discrete_sequence=['#1f77b4']
    )
    
    # Ajouter des statistiques
    mean_length = df['text_length'].mean()
    median_length = df['text_length'].median()
    
    fig.add_vline(x=mean_length, line_dash="dash", line_color="red", 
                  annotation_text=f"Moyenne: {mean_length:.0f}")
    fig.add_vline(x=median_length, line_dash="dash", line_color="orange",
                  annotation_text=f"M√©diane: {median_length:.0f}")
    
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        title_font_size=18,
        font=dict(size=12)
    )
    
    return fig

def create_word_count_analysis(df):
    """Analyse du nombre de mots par tweet"""
    
    fig = px.histogram(
        df,
        x='word_count',
        nbins=30,
        title="Distribution du Nombre de Mots par Tweet",
        labels={'word_count': 'Nombre de mots', 'count': 'Fr√©quence'},
        color_discrete_sequence=['#ff7f0e']
    )
    
    mean_words = df['word_count'].mean()
    median_words = df['word_count'].median()
    
    fig.add_vline(x=mean_words, line_dash="dash", line_color="red",
                  annotation_text=f"Moyenne: {mean_words:.1f}")
    fig.add_vline(x=median_words, line_dash="dash", line_color="orange",
                  annotation_text=f"M√©diane: {median_words:.0f}")
    
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        title_font_size=18,
        font=dict(size=12)
    )
    
    return fig

def create_word_frequency_plot(word_freq):
    """Cr√©e un graphique de fr√©quence des mots avec vraies donn√©es"""
    words, frequencies = zip(*word_freq)
    
    df_words = pd.DataFrame({'Mot': words, 'Fr√©quence': frequencies})
    
    fig = px.bar(
        df_words, 
        x='Fr√©quence', 
        y='Mot',
        orientation='h',
        title="Top 20 des Mots les Plus Fr√©quents (apr√®s pr√©traitement)",
        color='Fr√©quence',
        color_continuous_scale='viridis'
    )
    
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        title_font_size=18,
        font=dict(size=12),
        yaxis={'categoryorder':'total ascending'},
        height=600
    )
    
    return fig

def create_sentiment_by_length(df):
    """Analyse du sentiment en fonction de la longueur"""
    # Cr√©er des bins de longueur
    df['length_bin'] = pd.cut(df['text_length'], bins=10, labels=False)
    sentiment_by_length = df.groupby('length_bin')['target'].mean()
    
    bin_ranges = pd.cut(df['text_length'], bins=10).cat.categories
    bin_labels = [f"{int(interval.left)}-{int(interval.right)}" for interval in bin_ranges]
    
    fig = px.bar(
        x=bin_labels,
        y=sentiment_by_length.values,
        title="Proportion de Sentiment Positif par Longueur de Tweet",
        labels={'x': 'Longueur (caract√®res)', 'y': 'Proportion de sentiment positif'},
        color=sentiment_by_length.values,
        color_continuous_scale='RdYlGn'
    )
    
    fig.add_hline(y=0.5, line_dash="dash", line_color="black",
                  annotation_text="√âquilibre (50%)")
    
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        title_font_size=16,
        font=dict(size=11),
        xaxis_tickangle=-45
    )
    
    return fig

def main():
    st.title("üìä Analyse Exploratoire - Dataset Sentiment140")
    st.markdown("---")
    
    # Chargement des donn√©es avec indication de progression
    with st.spinner("üì• Chargement du dataset Sentiment140..."):
        df = load_data()
    
    if df is None or len(df) == 0:
        st.error("‚ùå Impossible de charger le dataset")
        st.stop()
    
    st.success(f"‚úÖ Dataset charg√© avec succ√®s ! ({len(df):,} √©chantillons)")
    
    # Statistiques g√©n√©rales
    stats = analyze_text_statistics(df)
    
    # Section d'informations sur le dataset
    st.subheader("üìã Informations sur le Dataset")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("√âchantillons total", f"{stats['total_texts']:,}")
    with col2:
        st.metric("Tweets positifs", f"{stats['positive_count']:,}", 
                 delta=f"{(stats['positive_count']/stats['total_texts']*100):.1f}%")
    with col3:
        st.metric("Tweets n√©gatifs", f"{stats['negative_count']:,}",
                 delta=f"{(stats['negative_count']/stats['total_texts']*100):.1f}%")
    with col4:
        st.metric("Longueur moyenne", f"{stats['avg_length']:.0f} cars")
    with col5:
        st.metric("Mots moyens", f"{stats['avg_words']:.1f}")
    
    # Informations sur le dataset complet
    with st.expander("‚ÑπÔ∏è √Ä propos du Dataset Sentiment140"):
        st.markdown("""
        **Sentiment140** est un dataset de tweets annot√©s d√©velopp√© par l'Universit√© de Stanford :
        
        - üìä **1.6 million de tweets** au total (nous utilisons un √©chantillon de 50K)
        - üåç **Tweets en anglais** collect√©s en 2009
        - ‚öñÔ∏è **Dataset √©quilibr√©** : 50% positif, 50% n√©gatif
        - üîÑ **Pr√©traitement appliqu√©** : nettoyage, normalisation des URLs et mentions
        
        Ce dataset est largement utilis√© pour l'entra√Ænement de mod√®les de classification de sentiment.
        """)
    
    st.markdown("---")
    
    # Distribution des sentiments
    st.subheader("üéØ Distribution des Sentiments")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        fig_sentiment = create_sentiment_distribution(df)
        st.plotly_chart(fig_sentiment, use_container_width=True)
    
    with col2:
        st.markdown("""
        **Observations :**
        
        ‚úÖ **Parfaitement √©quilibr√©**
        
        ‚úÖ **Aucun biais de classe**
        
        ‚úÖ **Id√©al pour l'entra√Ænement**
        
        Les donn√©es sont √©quilibr√©es entre sentiments positifs et n√©gatifs, ce qui √©vite les biais dans l'apprentissage.
        """)
    
    st.markdown("---")
    
    # Analyses textuelles
    st.subheader("üìù Analyses Textuelles D√©taill√©es")
    
    # Longueur des textes et nombre de mots
    col1, col2 = st.columns(2)
    
    with col1:
        fig_length = create_text_length_analysis(df)
        st.plotly_chart(fig_length, use_container_width=True)
        
        # Statistiques d√©taill√©es
        st.markdown("**Statistiques de longueur :**")
        st.write(f"‚Ä¢ **Minimum :** {stats['min_length']} caract√®res")
        st.write(f"‚Ä¢ **M√©diane :** {stats['median_length']:.0f} caract√®res")
        st.write(f"‚Ä¢ **Moyenne :** {stats['avg_length']:.0f} caract√®res")
        st.write(f"‚Ä¢ **Maximum :** {stats['max_length']} caract√®res")
        st.write(f"‚Ä¢ **√âcart-type :** {stats['std_length']:.0f}")
    
    with col2:
        fig_words = create_word_count_analysis(df)
        st.plotly_chart(fig_words, use_container_width=True)
        
        # Statistiques de mots
        st.markdown("**Statistiques de mots :**")
        st.write(f"‚Ä¢ **M√©diane :** {stats['median_words']:.0f} mots")
        st.write(f"‚Ä¢ **Moyenne :** {stats['avg_words']:.1f} mots")
        st.write(f"‚Ä¢ **Total :** {stats['total_words']:,} mots")
        
        # Insight sur les limites Twitter
        if stats['max_length'] <= 280:
            st.info("üì± Tweets conformes √† la limite de 280 caract√®res")
    
    # Analyse du sentiment par longueur
    st.subheader("üìè Sentiment en Fonction de la Longueur")
    fig_sentiment_length = create_sentiment_by_length(df)
    st.plotly_chart(fig_sentiment_length, use_container_width=True)
    
    with st.expander("üí° Interpr√©tation"):
        st.markdown("""
        Ce graphique montre la **proportion de sentiment positif** pour diff√©rentes tranches de longueur de tweets.
        
        - **Au-dessus de 50% :** Les tweets de cette longueur tendent √† √™tre plus positifs
        - **En-dessous de 50% :** Les tweets de cette longueur tendent √† √™tre plus n√©gatifs
        - **Autour de 50% :** Pas de biais particulier pour cette longueur
        """)
    
    st.markdown("---")
    
    # Analyse de fr√©quence des mots
    st.subheader("üî§ Analyse de Fr√©quence des Mots")
    
    with st.spinner("üîç Analyse des fr√©quences de mots..."):
        word_freq = get_word_frequencies(df, top_n=20)
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        if word_freq:
            fig_words_freq = create_word_frequency_plot(word_freq)
            st.plotly_chart(fig_words_freq, use_container_width=True)
        else:
            st.warning("Impossible de calculer les fr√©quences de mots")
    
    with col2:
        st.markdown("**Top 10 des mots :**")
        if word_freq:
            for i, (word, freq) in enumerate(word_freq[:10], 1):
                st.write(f"{i}. **{word}** ({freq:,})")
        
        st.markdown("""
        **Observations :**
        - Vocabulaire √©motionnel dominant
        - Mots d'opinion fr√©quents
        - Expressions typiques des r√©seaux sociaux
        """)
    
    st.markdown("---")
    
    # WordClouds
    st.subheader("‚òÅÔ∏è WordClouds par Sentiment")
    
    tab1, tab2, tab3 = st.tabs(["Tous sentiments", "Sentiment Positif", "Sentiment N√©gatif"])
    
    with tab1:
        with st.spinner("G√©n√©ration du WordCloud g√©n√©ral..."):
            wordcloud_all = create_wordcloud_from_data(df)
            st.pyplot(wordcloud_all, use_container_width=True)
        
        with st.expander("‚ôø Description textuelle"):
            st.markdown("""
            Ce WordCloud pr√©sente les mots les plus fr√©quents de l'ensemble du dataset.
            Les mots apparaissent en diff√©rentes tailles selon leur fr√©quence d'usage.
            """)
    
    with tab2:
        with st.spinner("G√©n√©ration du WordCloud positif..."):
            wordcloud_pos = create_wordcloud_from_data(df, sentiment=1)
            st.pyplot(wordcloud_pos, use_container_width=True)
        
        with st.expander("‚ôø Description textuelle"):
            st.markdown("""
            WordCloud sp√©cifique aux tweets class√©s comme positifs.
            Domin√© par des termes exprimant la satisfaction, la joie et l'approbation.
            """)
    
    with tab3:
        with st.spinner("G√©n√©ration du WordCloud n√©gatif..."):
            wordcloud_neg = create_wordcloud_from_data(df, sentiment=0)
            st.pyplot(wordcloud_neg, use_container_width=True)
        
        with st.expander("‚ôø Description textuelle"):
            st.markdown("""
            WordCloud sp√©cifique aux tweets class√©s comme n√©gatifs.
            Domin√© par des termes exprimant la frustration, la d√©ception et la critique.
            """)
    
    st.markdown("---")
    
    # Exemples de tweets
    st.subheader("üìÑ Exemples de Tweets du Dataset")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Exemples de tweets positifs :**")
        positive_tweets = df[df['target'] == 1]['text'].sample(5, random_state=42)
        for i, tweet in enumerate(positive_tweets, 1):
            st.write(f"{i}. *\"{tweet}\"*")
    
    with col2:
        st.markdown("**Exemples de tweets n√©gatifs :**")
        negative_tweets = df[df['target'] == 0]['text'].sample(5, random_state=42)
        for i, tweet in enumerate(negative_tweets, 1):
            st.write(f"{i}. *\"{tweet}\"*")
    
    # R√©sum√© analytique
    st.markdown("---")
    st.subheader("üìä R√©sum√© de l'Analyse Exploratoire")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **‚úÖ Qualit√© du Dataset :**
        
        1. **√âquilibrage parfait** : 50% positif / 50% n√©gatif
        2. **Volume suffisant** : 50K √©chantillons pour l'analyse
        3. **Diversit√© linguistique** : Vocabulaire riche et vari√©
        4. **Longueur appropri√©e** : Compatible avec les mod√®les de NLP
        5. **Pr√©traitement coh√©rent** : Nettoyage standardis√© appliqu√©
        """)
    
    with col2:
        st.info("""
        **üìà Insights Cl√©s :**
        
        - **Longueur moyenne** : ~{:.0f} caract√®res par tweet
        - **Richesse lexicale** : Vocabulaire √©motionnel dominant
        - **Distribution homog√®ne** : Pas de biais temporel ou structurel
        - **Qualit√© √©lev√©e** : Tweets authentiques et repr√©sentatifs
        - **Pr√™t pour ML** : Format optimal pour l'entra√Ænement
        """.format(stats['avg_length']))
    
    # Recommandations pour la suite
    with st.expander("üöÄ Recommandations pour l'Entra√Ænement"):
        st.markdown("""
        **Strat√©gies d'optimisation bas√©es sur l'analyse :**
        
        1. **Gestion de la longueur :**
            - Utiliser une longueur max de 512 tokens (compatible avec BERT)
            - Tronquer intelligemment les tweets tr√®s longs
        
        2. **Pr√©traitement sp√©cialis√© :**
            - Maintenir le remplacement des URLs et mentions
            - Pr√©server les hashtags (information contextuelle)
            - Normaliser la casse pour r√©duire la variabilit√©
        
        3. **Augmentation des donn√©es :**
            - Utiliser des techniques de back-translation
            - Appliquer des transformations syntaxiques l√©g√®res
            - Pr√©server l'√©quilibre des classes
        
        4. **Validation robuste :**
            - Split stratifi√© pour maintenir l'√©quilibre
            - Validation crois√©e pour √©valuer la g√©n√©ralisation
            - M√©triques multiples (accuracy, F1, ROC-AUC)
        """)

if __name__ == "__main__":
    main()