# ğŸ“ Projet 9 â€“ DÃ©veloppez une preuve de concept : AmÃ©lioration dâ€™un modÃ¨le dâ€™analyse de sentiment de tweets

## ğŸ“Œ Introduction

Pour le **Projet 9 â€“ DÃ©veloppez une preuve de concept**, nous avons choisi de poursuivre et dâ€™amÃ©liorer un travail amorcÃ© lors du **Projet 7 â€“ RÃ©alisez une analyse de sentiments grÃ¢ce au Deep Learning**. Ce dernier avait abouti Ã  la mise en place dâ€™un pipeline complet dâ€™analyse de sentiment de tweets, utilisant notamment un modÃ¨le **DistilBERT** fine-tunÃ© sur le jeu de donnÃ©es **Sentiment140**.  

## âœ¨ Objectif

Lâ€™objectif du Projet 9 est de **dÃ©passer les performances obtenues prÃ©cÃ©demment** en explorant de nouvelles approches plus performantes et adaptÃ©es au contexte, avec un accent particulier sur le **fine-tuning de ModernBERT**. Cette dÃ©marche sâ€™appuiera sur des comparaisons avec des modÃ¨les spÃ©cialisÃ©s RoBERTa et des LLMs gÃ©nÃ©ralistes en mode zero-shot, afin de valider la pertinence et la supÃ©rioritÃ© de la solution proposÃ©e.

## ğŸ“Š Jeu de donnÃ©es : Sentiment140

**Sentiment140** est un jeu de donnÃ©es composÃ© de **1,6 million de tweets** annotÃ©s automatiquement comme **positifs (1)** ou **nÃ©gatifs (0)**.  
Ses caractÃ©ristiques principales :  
- **Format** : CSV avec colonnes `target`, `ids`, `date`, `flag`, `user`, `text`  
- **Langue** : Anglais  
- **ParticularitÃ©** : Capture les spÃ©cificitÃ©s du langage Twitter (hashtags, mentions, abrÃ©viations, emojis).

Ce dataset est largement utilisÃ© comme rÃ©fÃ©rence pour lâ€™entraÃ®nement et lâ€™Ã©valuation de modÃ¨les dâ€™analyse de sentiment.

## ğŸ¯ TÃ¢che : Classification binaire

La tÃ¢che consiste Ã  prÃ©dire si un tweet exprime un **sentiment positif** ou **nÃ©gatif**. 

Dans le **Projet 7**, notre modÃ¨le **DistilBERT** fine-tunÃ© sur Sentiment140 a atteint les performances suivantes :  

| Metric      | Score  |
|-------------|--------|
| Accuracy    | 0.829  |
| F1-score    | 0.827  |
| Precision   | 0.838  |
| Recall      | 0.816  |
| ROC AUC     | 0.899  |

Ces rÃ©sultats constituent notre **baseline** pour Ã©valuer les approches du Projet 9.

---

## ğŸ§  Approches

### ğŸ”¹ Classification zero-shot

La **classification zero-shot** est une approche oÃ¹ un modÃ¨le prÃ©-entraÃ®nÃ© peut classer un texte dans des catÃ©gories **sans avoir Ã©tÃ© spÃ©cifiquement entraÃ®nÃ©** pour cette tÃ¢che ou ces labels. Elle exploite la comprÃ©hension linguistique acquise lors du prÃ©-entraÃ®nement et repose souvent sur des modÃ¨les de type *transformer* ou des **LLMs** via des consignes (*prompts*).

#### ModÃ¨les RoBERTa spÃ©cialisÃ©s

- [`cardiffnlp/twitter-roberta-base-sentiment-latest`](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)  
- [`siebert/sentiment-roberta-large-english`](https://huggingface.co/siebert/sentiment-roberta-large-english)  

Ces modÃ¨les sont optimisÃ©s pour lâ€™analyse de sentiment et prÃ©-entraÃ®nÃ©s sur de grandes quantitÃ©s de donnÃ©es Twitter ou textuelles gÃ©nÃ©rales.

#### LLM Claude AI

Lâ€™utilisation dâ€™un **LLM** comme **Claude AI** pour la classification zero-shot consiste Ã  exploiter ses capacitÃ©s de comprÃ©hension via des *prompts* dÃ©crivant la tÃ¢che d'analse de sentimet et les classes que nous cherchons Ã  prÃ©dire (positive/negative).  

Nous avons testÃ© deux modÃ¨les Anthropic :
- `claude-3-haiku-20240307` (version rapide et Ã©conomique)
- `claude-3-5-haiku-20241022` (avec batch processing)

### ğŸ”¹ Transfer learning et ModernBERT

Le **transfer learning** consiste Ã  rÃ©utiliser un modÃ¨le prÃ©-entraÃ®nÃ© sur un large corpus pour lâ€™adapter Ã  une tÃ¢che spÃ©cifique. Pour notre tÃ¢che, nous exploitons **ModernBERT**, un modÃ¨le prÃ©-entraÃ®nÃ© sur plus de **2 000 milliards de tokens**, optimisÃ© pour la vitesse dâ€™infÃ©rence, lâ€™efficacitÃ© mÃ©moire et la gestion de longues sÃ©quences. En appliquant un fine-tuning sur **Sentiment140**, nous adaptons ModernBERT aux particularitÃ©s du langage Twitter, avec pour objectif de **surpasser les performances obtenues avec DistilBERT**.

#### ModernBERT 

[ModernBERT](https://huggingface.co/docs/transformers/model_doc/modernbert) est un encodeur *transformer* de derniÃ¨re gÃ©nÃ©ration, publiÃ© en dÃ©cembre 2014, offrant un Ã©quilibre optimal entre **performance**, **vitesse dâ€™infÃ©rence** et **efficacitÃ© mÃ©moire**. Il se distingue par des rÃ©sultats *state-of-the-art* sur le benchmark **GLUE** pour un modÃ¨le de sa taille, surpassant notamment **DeBERTaV3-base**, preuve de ses capacitÃ©s avancÃ©es de comprÃ©hension linguistique.

PrÃ©-entraÃ®nÃ© sur **2 000 milliards de tokens** (texte et code) avec une **longueur de sÃ©quence native de 8 192 tokens**, il bÃ©nÃ©ficie dâ€™une couverture linguistique exceptionnelle et dâ€™une grande robustesse face au vocabulaire variÃ© et informel des tweets. Son architecture intÃ¨gre des innovations modernes â€” **GeGLU**, **RoPE positional embeddings**, **attention locale/alternÃ©e**, gestion native des **sÃ©quences non paddÃ©es** â€” optimisÃ©es pour le calcul GPU et la rapiditÃ© dâ€™infÃ©rence.

En pratique, **ModernBERT** traite des batchs plus grands que ses concurrents (jusquâ€™Ã  Ã—2 pour la version base) et est environ **deux fois plus rapide** que DeBERTaV3 sur des contextes courts ou longs. Cette efficacitÃ© permet de concilier **prÃ©cision Ã©levÃ©e** et **coÃ»t de calcul rÃ©duit**, un atout clÃ© pour un dÃ©ploiement en production.

Dans le cadre de notre projet, nous procÃ©dons Ã  un **fine-tuning** sur le jeu de donnÃ©es **Sentiment140** afin dâ€™adapter le modÃ¨le Ã  la classification binaire de sentiments sur tweets. Lâ€™objectif est de dÃ©passer les performances obtenues lors du Projet 7 avec DistilBERT, en tirant parti du prÃ©-entraÃ®nement massif et des optimisations structurelles de ModernBERT pour obtenir des mÃ©triques supÃ©rieures tout en maintenant une excellente efficacitÃ© opÃ©rationnelle.

### ğŸ“ˆ Tableau comparatif des modÃ¨les

| ModÃ¨le                                          | Type          | StratÃ©gie          | Points forts                                                                 | Limites prÃ©vues                                             |
|------------------------------------------------|--------------|--------------------|-------------------------------------------------------------------------------|--------------------------------------------------------------|
| **cardiffnlp/twitter-roberta-base-sentiment-latest** | Transformer   | Zero-shot          | SpÃ©cialisÃ© Twitter, bon Ã©quilibre prÃ©cision/rapiditÃ©                         | Moins performant hors domaine Twitter                        |
| **siebert/sentiment-roberta-large-english**     | Transformer   | Zero-shot          | Grande capacitÃ©, robuste sur texte gÃ©nÃ©ral                                   | Temps dâ€™infÃ©rence plus Ã©levÃ©                                 |
| **Claude 3 Haiku 20240307**                     | LLM           | Zero-shot (API)    | Faible coÃ»t, rapiditÃ©, pas de prÃ©traitement complexe                         | DÃ©pendance API, pas optimisÃ© pour tweets courts               |
| **Claude 3.5 Haiku 20241022**                   | LLM           | Zero-shot (API)    | Meilleure comprÃ©hension contextuelle, batch processing                       | CoÃ»t plus Ã©levÃ©, temps de rÃ©ponse plus long                   |
| **ModernBERT (fine-tuning)**                    | Transformer   | Transfer learning  | PrÃ©-entraÃ®nement massif (2T tokens), optimisÃ© mÃ©moire & vitesse, sÃ©quence longue | NÃ©cessite entraÃ®nement, tuning hyperparamÃ¨tres                |

> **Note** : les performances rÃ©elles seront mesurÃ©es sur le mÃªme jeu de test Sentiment140 afin dâ€™assurer une comparaison Ã©quitable.

---

## ğŸ§ª DÃ©marche expÃ©rimentale

1. **PrÃ©paration des donnÃ©es**
   - Nettoyage et tokenisation adaptÃ©e Ã  chaque modÃ¨le
   - Split : 80% train, 10% validation, 10% test

2. **Ã‰valuation zero-shot**
   - RoBERTa et Claude AI Ã©valuÃ©s sans fine-tuning
   - Mesures : Accuracy, F1, Precision, Recall, ROC AUC

3. **Fine-tuning de ModernBERT**
   - HyperparamÃ¨tres optimisÃ©s (learning rate, batch size, epochs)
   - EntraÃ®nement sur GPU
   - Comparaison des performances sur le mÃªme set de test

4. **Analyse et comparaison**
   - Tableau comparatif des performances
   - Analyse dâ€™erreurs et cas limites

---

## ğŸ“š RÃ©fÃ©rences

1. Go, A., Bhayani, R., & Huang, L. (2009). [Twitter Sentiment Classification using Distant Supervision](http://help.sentiment140.com/for-students)  
2. Wolf, T. et al. (2020). [Transformers: State-of-the-Art Natural Language Processing](https://arxiv.org/abs/1910.03771)  
3. Answer.AI. (2024). [ModernBERT: Efficient Transformer for Long-Sequence NLP](https://huggingface.co/answerdotai/ModernBERT-base)

---

## ğŸ“¦ Technologies

- **Langages** : Python  
- **Librairies ML/DL** : PyTorch, Transformers, Scikit-learn  
- **MLOps** : MLFlow, GitHub Actions  
- **Backend/API** : Streamlit  
- **LLM API** : Claude AI  

