# üìù Projet 9 ‚Äì D√©veloppez une preuve de concept : Am√©lioration d‚Äôun mod√®le d‚Äôanalyse de sentiment de tweets

> üéì OpenClassrooms ‚Ä¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | üëã *√âtudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)

## üìå Introduction

Pour le **Projet 9 ‚Äì D√©veloppez une preuve de concept**, nous avons choisi de poursuivre et d‚Äôam√©liorer un travail amorc√© lors du **Projet 7 ‚Äì R√©alisez une analyse de sentiments gr√¢ce au Deep Learning**. Ce dernier avait abouti √† la mise en place d‚Äôun pipeline complet d‚Äôanalyse de sentiment de tweets, utilisant notamment un mod√®le **DistilBERT** fine-tun√© sur le jeu de donn√©es **Sentiment140**.  

## ‚ú® Objectif

L‚Äôobjectif du Projet 9 est de **d√©passer les performances obtenues pr√©c√©demment** en explorant de nouvelles approches plus performantes et adapt√©es au contexte, avec un accent particulier sur le **fine-tuning de ModernBERT**. Cette d√©marche s‚Äôappuiera sur des comparaisons avec des mod√®les sp√©cialis√©s RoBERTa et des LLMs g√©n√©ralistes en mode zero-shot, afin de valider la pertinence et la sup√©riorit√© de la solution propos√©e.

## üìä Jeu de donn√©es : Sentiment140

**Sentiment140** est un jeu de donn√©es compos√© de **1,6 million de tweets** annot√©s automatiquement comme **positifs (1)** ou **n√©gatifs (0)**.  
Ses caract√©ristiques principales :  
- **Format** : CSV avec colonnes `target`, `ids`, `date`, `flag`, `user`, `text`  
- **Langue** : Anglais  
- **Particularit√©** : Capture les sp√©cificit√©s du langage Twitter (hashtags, mentions, abr√©viations, emojis).

Ce dataset est largement utilis√© comme r√©f√©rence pour l‚Äôentra√Ænement et l‚Äô√©valuation de mod√®les d‚Äôanalyse de sentiment.

## üéØ T√¢che : Classification binaire

La t√¢che consiste √† pr√©dire si un tweet exprime un **sentiment positif** ou **n√©gatif**. 

Dans le **Projet 7**, notre mod√®le **DistilBERT** fine-tun√© sur Sentiment140 a atteint les performances suivantes :  

| Metric      | Score  |
|-------------|--------|
| Accuracy    | 0.829  |
| F1-score    | 0.827  |
| Precision   | 0.838  |
| Recall      | 0.816  |
| ROC AUC     | 0.899  |

Ces r√©sultats constituent notre **baseline** pour √©valuer les approches du Projet 9.

---

## üß† Approches

### üîπ Classification zero-shot

La **classification zero-shot** est une approche o√π un mod√®le pr√©-entra√Æn√© peut classer un texte dans des cat√©gories **sans avoir √©t√© sp√©cifiquement entra√Æn√©** pour cette t√¢che ou ces labels. Elle exploite la compr√©hension linguistique acquise lors du pr√©-entra√Ænement et repose souvent sur des mod√®les de type *transformer* ou des **LLMs** via des consignes (*prompts*).

#### Mod√®les RoBERTa sp√©cialis√©s

- [`cardiffnlp/twitter-roberta-base-sentiment-latest`](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)  
- [`siebert/sentiment-roberta-large-english`](https://huggingface.co/siebert/sentiment-roberta-large-english)  

Ces mod√®les sont optimis√©s pour l‚Äôanalyse de sentiment et pr√©-entra√Æn√©s sur de grandes quantit√©s de donn√©es Twitter ou textuelles g√©n√©rales.

#### LLM Claude AI

L‚Äôutilisation d‚Äôun **LLM** comme **Claude AI** pour la classification zero-shot consiste √† exploiter ses capacit√©s de compr√©hension via des *prompts* d√©crivant la t√¢che d'analse de sentimet et les classes que nous cherchons √† pr√©dire (positive/negative).  

Nous avons test√© deux mod√®les Anthropic :
- `claude-3-haiku-20240307` (version rapide et √©conomique)
- `claude-3-5-haiku-20241022` (avec batch processing)

### üîπ Transfer learning et ModernBERT

Le **transfer learning** consiste √† r√©utiliser un mod√®le pr√©-entra√Æn√© sur un large corpus pour l‚Äôadapter √† une t√¢che sp√©cifique. Pour notre t√¢che, nous exploitons **ModernBERT**, un mod√®le pr√©-entra√Æn√© sur plus de **2 000 milliards de tokens**, optimis√© pour la vitesse d‚Äôinf√©rence, l‚Äôefficacit√© m√©moire et la gestion de longues s√©quences. En appliquant un fine-tuning sur **Sentiment140**, nous adaptons ModernBERT aux particularit√©s du langage Twitter, avec pour objectif de **surpasser les performances obtenues avec DistilBERT**.

#### ModernBERT 

[ModernBERT](https://huggingface.co/docs/transformers/model_doc/modernbert) est un encodeur *transformer* de derni√®re g√©n√©ration, publi√© en d√©cembre 2014, offrant un √©quilibre optimal entre **performance**, **vitesse d‚Äôinf√©rence** et **efficacit√© m√©moire**. Il se distingue par des r√©sultats *state-of-the-art* sur le benchmark **GLUE** pour un mod√®le de sa taille, surpassant notamment **DeBERTaV3-base**, preuve de ses capacit√©s avanc√©es de compr√©hension linguistique.

Pr√©-entra√Æn√© sur **2 000 milliards de tokens** (texte et code) avec une **longueur de s√©quence native de 8 192 tokens**, il b√©n√©ficie d‚Äôune couverture linguistique exceptionnelle et d‚Äôune grande robustesse face au vocabulaire vari√© et informel des tweets. Son architecture int√®gre des innovations modernes ‚Äî **GeGLU**, **RoPE positional embeddings**, **attention locale/altern√©e**, gestion native des **s√©quences non padd√©es** ‚Äî optimis√©es pour le calcul GPU et la rapidit√© d‚Äôinf√©rence.

En pratique, **ModernBERT** traite des batchs plus grands que ses concurrents (jusqu‚Äô√† √ó2 pour la version base) et est environ **deux fois plus rapide** que DeBERTaV3 sur des contextes courts ou longs. Cette efficacit√© permet de concilier **pr√©cision √©lev√©e** et **co√ªt de calcul r√©duit**, un atout cl√© pour un d√©ploiement en production.

Dans le cadre de notre projet, nous proc√©dons √† un **fine-tuning** sur le jeu de donn√©es **Sentiment140** afin d‚Äôadapter le mod√®le √† la classification binaire de sentiments sur tweets. L‚Äôobjectif est de d√©passer les performances obtenues lors du Projet 7 avec DistilBERT, en tirant parti du pr√©-entra√Ænement massif et des optimisations structurelles de ModernBERT pour obtenir des m√©triques sup√©rieures tout en maintenant une excellente efficacit√© op√©rationnelle.

### üìà Tableau comparatif des mod√®les

| Mod√®le                                          | Type          | Strat√©gie          | Points forts                                                                 | Limites pr√©vues                                             |
|------------------------------------------------|--------------|--------------------|-------------------------------------------------------------------------------|--------------------------------------------------------------|
| **cardiffnlp/twitter-roberta-base-sentiment-latest** | Transformer   | Zero-shot          | Sp√©cialis√© Twitter, bon √©quilibre pr√©cision/rapidit√©                         | Moins performant hors domaine Twitter                        |
| **siebert/sentiment-roberta-large-english**     | Transformer   | Zero-shot          | Grande capacit√©, robuste sur texte g√©n√©ral                                   | Temps d‚Äôinf√©rence plus √©lev√©                                 |
| **Claude 3 Haiku 20240307**                     | LLM           | Zero-shot (API)    | Faible co√ªt, rapidit√©, pas de pr√©traitement complexe                         | D√©pendance API, pas optimis√© pour tweets courts               |
| **Claude 3.5 Haiku 20241022**                   | LLM           | Zero-shot (API)    | Meilleure compr√©hension contextuelle, batch processing                       | Co√ªt plus √©lev√©, temps de r√©ponse plus long                   |
| **ModernBERT (fine-tuning)**                    | Transformer   | Transfer learning  | Pr√©-entra√Ænement massif (2T tokens), optimis√© m√©moire & vitesse, s√©quence longue | N√©cessite entra√Ænement, tuning hyperparam√®tres                |

> **Note** : les performances r√©elles seront mesur√©es sur le m√™me jeu de test Sentiment140 afin d‚Äôassurer une comparaison √©quitable.

---

## üß™ D√©marche exp√©rimentale

1. **Pr√©paration des donn√©es**
   - Nettoyage et tokenisation adapt√©e √† chaque mod√®le
   - Split : 80% train, 10% validation, 10% test

2. **√âvaluation zero-shot**
   - RoBERTa et Claude AI √©valu√©s sans fine-tuning
   - Mesures : Accuracy, F1, Precision, Recall, ROC AUC

3. **Fine-tuning de ModernBERT**
   - Hyperparam√®tres optimis√©s (learning rate, batch size, epochs)
   - Entra√Ænement sur GPU
   - Comparaison des performances sur le m√™me set de test

4. **Analyse et comparaison**
   - Tableau comparatif des performances
   - Analyse d‚Äôerreurs et cas limites

---

## üìö R√©f√©rences

1. Go, A., Bhayani, R., & Huang, L. (2009). [Twitter Sentiment Classification using Distant Supervision](http://help.sentiment140.com/for-students)  
2. Wolf, T. et al. (2020). [Transformers: State-of-the-Art Natural Language Processing](https://arxiv.org/abs/1910.03771)  
3. Answer.AI. (2024). [ModernBERT: Efficient Transformer for Long-Sequence NLP](https://huggingface.co/answerdotai/ModernBERT-base)

---

## üì¶ Technologies

- **Langages** : Python  
- **Librairies ML/DL** : PyTorch, Transformers, Scikit-learn  
- **MLOps** : MLFlow, GitHub Actions  
- **Backend/API** : Streamlit  
- **LLM API** : Claude AI  

---

## A propos 

Projet d√©velopp√© par [David Scanu](https://www.linkedin.com/in/davidscanu14/) dans le cadre du parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) d'OpenClassrooms :  
*Projet 9 : D√©veloppez une preuve de concept*.
